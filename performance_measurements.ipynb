{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import evaluate\n",
    "from transformers import AutoModelWithHeads, AutoTokenizer\n",
    "from transformers.models.bert import BertOnnxConfig\n",
    "from transformers.onnx import OnnxConfig, validate_model_outputs, export\n",
    "\n",
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from onnxruntime import InferenceSession\n",
    "import onnxruntime\n",
    "\n",
    "\n",
    "import time\n",
    "from typing import Tuple, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Mapping, OrderedDict\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Process\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load needed skills by skilltype (span-extraction, multiple-choice, categorical, abstractive)\n",
    "def load_skills(skill_type, path=\"square_skills/impl_skills.csv\"):\n",
    "    all_skills = pd.read_csv(path)\n",
    "    skills = all_skills[all_skills[\"Type\"] == skill_type]\n",
    "    return skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onnx_model(model_onnx, model_onnx_quant, as_list=False):\n",
    "    onnx_model = onnxruntime.InferenceSession(model_onnx, providers=[\"CPUExecutionProvider\"])\n",
    "    onnx_model_quant = onnxruntime.InferenceSession(model_onnx_quant, providers=[\"CPUExecutionProvider\"])\n",
    "    \n",
    "    so = onnxruntime.SessionOptions()\n",
    "    so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    \n",
    "    onnx_model_opt = onnxruntime.InferenceSession(model_onnx, so)\n",
    "    onnx_model_quant_opt = onnxruntime.InferenceSession(model_onnx_quant, so)\n",
    "    \n",
    "    if as_list:\n",
    "        return [onnx_model, onnx_model_opt, onnx_model_quant, onnx_model_quant_opt]\n",
    "    return onnx_model, onnx_model_opt, onnx_model_quant, onnx_model_quant_opt\n",
    "\n",
    "def repo_builder(reader, adapter):\n",
    "    repo_id = f\"UKP-SQuARE/{reader}-pf-{adapter}-onnx\"\n",
    "    filename_onnx = \"model.onnx\"\n",
    "    filename_onnx_quant = \"model_quant.onnx\"\n",
    "\n",
    "    model_onnx = hf_hub_download(repo_id=repo_id, filename=filename_onnx)\n",
    "    model_onnx_quant = hf_hub_download(repo_id=repo_id, filename=filename_onnx_quant)\n",
    "\n",
    "    return model_onnx, model_onnx_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df_new, path_to_logger_file = \"logs/logger_all.csv\"):\n",
    "    if os.path.exists(path_to_logger_file):\n",
    "        df_fin = pd.concat([pd.read_csv(path_to_logger_file), df_new])\n",
    "        df_fin.to_csv(path_to_logger_file,index=False)\n",
    "    else: \n",
    "        df_new.to_csv(path_to_logger_file,index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Function Extractive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference extractive_qa models\n",
    "# base model\n",
    "\n",
    "def base_predict(\n",
    "            model, input, tokenizer, preprocessing_kwargs, model_kwargs, batch_size=1, disable_gpu=True, output_features=False\n",
    "    ) -> Union[dict, Tuple[dict, dict]]:\n",
    "        \"\"\"\n",
    "        Inference on the input.\n",
    "        Args:\n",
    "         request: the request with the input and optional kwargs\n",
    "         output_features: return the features of the input.\n",
    "            Necessary if, e.g., attention mask is needed for post-processing.\n",
    "        Returns:\n",
    "             The model outputs and optionally the input features\n",
    "        \"\"\"\n",
    "\n",
    "        all_predictions = []\n",
    "        preprocessing_kwargs[\"padding\"] = preprocessing_kwargs.get(\n",
    "            \"padding\", True\n",
    "        )\n",
    "        preprocessing_kwargs[\"truncation\"] = preprocessing_kwargs.get(\n",
    "            \"truncation\", True\n",
    "        )\n",
    "        model.to(\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available() and not disable_gpu\n",
    "            else \"cpu\"\n",
    "        )\n",
    "\n",
    "        features = tokenizer(\n",
    "            input, return_tensors=\"pt\", **preprocessing_kwargs\n",
    "        )\n",
    "\n",
    "        for start_idx in range(0, len(input), batch_size):\n",
    "            with torch.no_grad():\n",
    "                input_features = {\n",
    "                    k: features[k][start_idx: start_idx + batch_size]\n",
    "                    for k in features.keys()\n",
    "                }\n",
    "                predictions = model(**input_features, **model_kwargs)\n",
    "                all_predictions.append(predictions)\n",
    "\n",
    "        keys = all_predictions[0].keys()\n",
    "        final_prediction = {}\n",
    "        for key in keys:\n",
    "            # HuggingFace outputs for \"attentions\" and more is\n",
    "            # returned as tuple of tensors\n",
    "            # Tuple of tuples only exists for \"past_key_values\"\n",
    "            # which is only relevant for generation.\n",
    "            # Generation should NOT use this function\n",
    "            if isinstance(all_predictions[0][key], tuple):\n",
    "                tuple_of_lists = list(\n",
    "                    zip(\n",
    "                        *[\n",
    "                            [\n",
    "                                torch.stack(p).cpu()\n",
    "                                if isinstance(p, tuple)\n",
    "                                else p.cpu()\n",
    "                                for p in tpl[key]\n",
    "                            ]\n",
    "                            for tpl in all_predictions\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                final_prediction[key] = tuple(torch.cat(l) for l in tuple_of_lists)\n",
    "            else:\n",
    "                final_prediction[key] = torch.cat(\n",
    "                    [p[key].cpu() for p in all_predictions]\n",
    "                )\n",
    "        if output_features:\n",
    "            return final_prediction, features\n",
    "\n",
    "        return final_prediction\n",
    "\n",
    "def base_qa(model, tokenizer, input, preprocessing_kwargs, task_kwargs, model_kwargs):\n",
    "    \"\"\"\n",
    "    Span-based question answering for a given question and context.\n",
    "    We expect the input to use the (question, context) format for the text pairs.\n",
    "    Args:\n",
    "        request: the prediction request\n",
    "    \"\"\"    \n",
    "    preprocessing_kwargs[\"truncation\"] = \"only_second\"\n",
    "    features = tokenizer(\n",
    "        input, return_tensors=\"pt\", **preprocessing_kwargs\n",
    "    )\n",
    "    predictions, features = base_predict(model, input, tokenizer, preprocessing_kwargs, model_kwargs, output_features=True)\n",
    "\n",
    "    task_outputs = {\n",
    "        \"answers\": [],\n",
    "        \"attributions\": [],\n",
    "        \"adversarial\": {\n",
    "            \"indices\": [],\n",
    "        },  # for hotflip, input_reduction and topk\n",
    "    }\n",
    "\n",
    "    for idx, (start, end, (_, context)) in enumerate(\n",
    "            zip(predictions[\"start_logits\"], predictions[\"end_logits\"], input)\n",
    "    ):\n",
    "        # Ensure padded tokens & question tokens cannot\n",
    "        # belong to the set of candidate answers.\n",
    "        question_tokens = np.abs(np.array([s != 1 for s in features.sequence_ids(idx)]) - 1)\n",
    "        # Unmask CLS token for \"no answer\"\n",
    "        question_tokens[0] = 1\n",
    "        undesired_tokens = question_tokens & features[\"attention_mask\"][idx].numpy()\n",
    "\n",
    "        # Generate mask\n",
    "        undesired_tokens_mask = undesired_tokens == 0.0\n",
    "\n",
    "        # Make sure non-context indexes in the tensor cannot\n",
    "        # contribute to the softmax\n",
    "        start = np.where(undesired_tokens_mask, -10000.0, start)\n",
    "        end = np.where(undesired_tokens_mask, -10000.0, end)\n",
    "\n",
    "        start = np.exp(start - np.log(np.sum(np.exp(start), axis=-1, keepdims=True)))\n",
    "        end = np.exp(end - np.log(np.sum(np.exp(end), axis=-1, keepdims=True)))\n",
    "\n",
    "        # Get score for \"no answer\" then mask for decoding step (CLS token\n",
    "        no_answer_score = (start[0] * end[0]).item()\n",
    "        start[0] = end[0] = 0.0\n",
    "\n",
    "        starts, ends, scores = decode(\n",
    "            start,\n",
    "            end,\n",
    "            task_kwargs.get(\"topk\", 1),\n",
    "            task_kwargs.get(\"max_answer_len\", 128),\n",
    "            undesired_tokens,\n",
    "        )\n",
    "\n",
    "        enc = features[idx]\n",
    "        original_ans_start = enc.token_to_word(starts[0])\n",
    "        original_ans_end = enc.token_to_word(ends[0])\n",
    "        answers = [\n",
    "            {\n",
    "                \"score\": score.item(),\n",
    "                \"start\": enc.word_to_chars(enc.token_to_word(s), sequence_index=1)[0],\n",
    "                \"end\": enc.word_to_chars(enc.token_to_word(e), sequence_index=1)[1],\n",
    "                \"answer\": context[\n",
    "                            enc.word_to_chars(enc.token_to_word(s), sequence_index=1)[0]: enc.word_to_chars(\n",
    "                                enc.token_to_word(e), sequence_index=1\n",
    "                            )[1]\n",
    "                            ],\n",
    "            }\n",
    "            for s, e, score in zip(starts, ends, scores)\n",
    "        ]\n",
    "        if task_kwargs.get(\"show_null_answers\", True):\n",
    "            answers.append({\"score\": no_answer_score, \"start\": 0, \"end\": 0, \"answer\": \"\"})\n",
    "        answers = sorted(answers, key=lambda x: x[\"score\"], reverse=True)[: task_kwargs.get(\"topk\", 1)]\n",
    "        task_outputs[\"answers\"].append(answers)\n",
    "\n",
    "    return predictions, task_outputs, original_ans_start, original_ans_end\n",
    "\n",
    "def decode(\n",
    "            start_: np.ndarray,\n",
    "            end_: np.ndarray,\n",
    "            topk: int,\n",
    "            max_answer_len: int,\n",
    "            undesired_tokens_: np.ndarray,\n",
    "    ) -> Tuple:\n",
    "    \"\"\"\n",
    "    Take the output of any :obj:`ModelForQuestionAnswering` and\n",
    "        will generate probabilities for each span to be the\n",
    "        actual answer.\n",
    "    In addition, it filters out some unwanted/impossible cases\n",
    "    like answer len being greater than max_answer_len or\n",
    "    answer end position being before the starting position.\n",
    "    The method supports output the k-best answer through\n",
    "    the topk argument.\n",
    "    Args:\n",
    "        start_ (:obj:`np.ndarray`): Individual start\n",
    "            probabilities for each token.\n",
    "        end (:obj:`np.ndarray`): Individual end_ probabilities\n",
    "            for each token.\n",
    "        topk (:obj:`int`): Indicates how many possible answer\n",
    "            span(s) to extract from the model output.\n",
    "        max_answer_len (:obj:`int`): Maximum size of the answer\n",
    "            to extract from the model\"s output.\n",
    "        undesired_tokens_ (:obj:`np.ndarray`): Mask determining\n",
    "            tokens that can be part of the answer\n",
    "    \"\"\"\n",
    "    # Ensure we have batch axis\n",
    "    if start_.ndim == 1:\n",
    "        start_ = start_[None]\n",
    "\n",
    "    if end_.ndim == 1:\n",
    "        end_ = end_[None]\n",
    "\n",
    "    # Compute the score of each tuple(start_, end_) to be the real answer\n",
    "    outer = np.matmul(np.expand_dims(start_, -1), np.expand_dims(end_, 1))\n",
    "\n",
    "    # Remove candidate with end_ < start_ and end_ - start_ > max_answer_len\n",
    "    candidates = np.tril(np.triu(outer), max_answer_len - 1)\n",
    "\n",
    "    #  Inspired by Chen & al. (https://github.com/facebookresearch/DrQA)\n",
    "    scores_flat = candidates.flatten()\n",
    "    if topk == 1:\n",
    "        idx_sort = [np.argmax(scores_flat)]\n",
    "    elif len(scores_flat) < topk:\n",
    "        idx_sort = np.argsort(-scores_flat)\n",
    "    else:\n",
    "        idx = np.argpartition(-scores_flat, topk)[0:topk]\n",
    "        idx_sort = idx[np.argsort(-scores_flat[idx])]\n",
    "\n",
    "    starts_, ends_ = np.unravel_index(idx_sort, candidates.shape)[1:]\n",
    "    desired_spans = np.isin(starts_, undesired_tokens_.nonzero()) & np.isin(\n",
    "        ends_, undesired_tokens_.nonzero()\n",
    "    )\n",
    "    starts_ = starts_[desired_spans]\n",
    "    ends_ = ends_[desired_spans]\n",
    "    scores_ = candidates[0, starts_, ends_]\n",
    "\n",
    "    return starts_, ends_, scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from SQuARE ONNX QA Pipeline (note: some features like explainability and attack mode have been removed)\n",
    "def question_answering(model_qa, tokenizer, input, preprocessing_kwargs, task_kwargs, model_kwargs):\n",
    "    \"\"\"\n",
    "    Span-based question answering for a given question and context.\n",
    "    We expect the input to use the (question, context) format for the text pairs.\n",
    "    Args:\n",
    "        request: the prediction request\n",
    "    \"\"\"    \n",
    "    preprocessing_kwargs[\"truncation\"] = \"only_second\"\n",
    "\n",
    "    features = tokenizer(\n",
    "        input, return_tensors=\"np\", **preprocessing_kwargs\n",
    "    )\n",
    "    onnx_inputs = {key: np.array(features[key], dtype=np.int64) for key in features}\n",
    "    \n",
    "    predictions_onnx = model_qa.run(input_feed=onnx_inputs, output_names=None)\n",
    "    predictions = {\n",
    "        \"start_logits\": predictions_onnx[0],\n",
    "        \"end_logits\": predictions_onnx[1]\n",
    "    }\n",
    "\n",
    "    task_outputs = {\n",
    "        \"answers\": [],\n",
    "        \"attributions\": [],\n",
    "        \"adversarial\": {\n",
    "            \"indices\": [],\n",
    "        },  # for hotflip, input_reduction and topk\n",
    "    }\n",
    "\n",
    "    for idx, (start, end, (_, context)) in enumerate(\n",
    "            zip(predictions[\"start_logits\"], predictions[\"end_logits\"], input)\n",
    "    ):\n",
    "        # Ensure padded tokens & question tokens cannot\n",
    "        # belong to the set of candidate answers.\n",
    "        question_tokens = np.abs(np.array([s != 1 for s in features.sequence_ids(idx)]) - 1)\n",
    "        # Unmask CLS token for \"no answer\"\n",
    "        question_tokens[0] = 1\n",
    "        undesired_tokens = question_tokens & features[\"attention_mask\"][idx]\n",
    "\n",
    "        # Generate mask\n",
    "        undesired_tokens_mask = undesired_tokens == 0.0\n",
    "\n",
    "        # Make sure non-context indexes in the tensor cannot\n",
    "        # contribute to the softmax\n",
    "        start = np.where(undesired_tokens_mask, -10000.0, start)\n",
    "        end = np.where(undesired_tokens_mask, -10000.0, end)\n",
    "\n",
    "        start = np.exp(start - np.log(np.sum(np.exp(start), axis=-1, keepdims=True)))\n",
    "        end = np.exp(end - np.log(np.sum(np.exp(end), axis=-1, keepdims=True)))\n",
    "\n",
    "        # Get score for \"no answer\" then mask for decoding step (CLS token\n",
    "        no_answer_score = (start[0] * end[0]).item()\n",
    "        start[0] = end[0] = 0.0\n",
    "\n",
    "        starts, ends, scores = decode(\n",
    "            start,\n",
    "            end,\n",
    "            task_kwargs.get(\"topk\", 1),\n",
    "            task_kwargs.get(\"max_answer_len\", 128),\n",
    "            undesired_tokens,\n",
    "        )\n",
    "\n",
    "        enc = features[idx]\n",
    "        original_ans_start = enc.token_to_word(starts[0])\n",
    "        original_ans_end = enc.token_to_word(ends[0])\n",
    "        answers = [\n",
    "            {\n",
    "                \"score\": score.item(),\n",
    "                \"start\": enc.word_to_chars(enc.token_to_word(s), sequence_index=1)[0],\n",
    "                \"end\": enc.word_to_chars(enc.token_to_word(e), sequence_index=1)[1],\n",
    "                \"answer\": context[\n",
    "                            enc.word_to_chars(enc.token_to_word(s), sequence_index=1)[0]: enc.word_to_chars(\n",
    "                                enc.token_to_word(e), sequence_index=1\n",
    "                            )[1]\n",
    "                            ],\n",
    "            }\n",
    "            for s, e, score in zip(starts, ends, scores)\n",
    "        ]\n",
    "        if task_kwargs.get(\"show_null_answers\", True):\n",
    "            answers.append({\"score\": no_answer_score, \"start\": 0, \"end\": 0, \"answer\": \"\"})\n",
    "        answers = sorted(answers, key=lambda x: x[\"score\"], reverse=True)[: task_kwargs.get(\"topk\", 1)]\n",
    "        task_outputs[\"answers\"].append(answers)\n",
    "\n",
    "    return predictions, task_outputs, original_ans_start, original_ans_end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Function Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_base_inference(model, tokenizer, question, context):\n",
    "    \n",
    "    raw_input = [[context, question]]\n",
    "    inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    outputs = model(**inputs)\n",
    "    answer_idx = torch.argmax(outputs.logits)\n",
    "    \n",
    "    return bool(answer_idx), outputs.logits[0]\n",
    "\n",
    "def categorical_onnx_inference(onnx_model, tokenizer, question, context):\n",
    "\n",
    "    inputs = tokenizer(question, context, padding=True, truncation=True, return_tensors=\"np\")\n",
    "    inputs = {key: np.array(inputs[key], dtype=np.int64) for key in inputs}\n",
    "\n",
    "    outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\n",
    "\n",
    "    return bool(np.argmax(outputs[0][0])), outputs[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Function Multiple Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_base_inference(model, tokenizer, question, context, choices):\n",
    "    outputs = []\n",
    "    raw_input = [[context, question + \" \" + choice] for choice in choices]\n",
    "    inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    answer_logits = outputs.logits\n",
    "    answer_idx = torch.argmax(answer_logits)\n",
    "    answer = choices[answer_idx]\n",
    "\n",
    "    return answer, answer_logits\n",
    "\n",
    "def mc_onnx_inference(onnx_model, tokenizer, context, question, choices):\n",
    "\n",
    "    raw_input = [[context, question + \" \" + choice] for choice in choices]\n",
    "    inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"np\")\n",
    "\n",
    "    inputs['input_ids'] =  np.expand_dims(inputs['input_ids'], axis=0)\n",
    "    inputs['attention_mask'] =  np.expand_dims(inputs['attention_mask'], axis=0)\n",
    "    if \"token_type_ids\" in inputs: #roberta does not use this\n",
    "        inputs['token_type_ids'] = np.expand_dims(inputs['token_type_ids'], axis=0)\n",
    "    \n",
    "    outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\n",
    "\n",
    "    answer_logits = outputs[0]\n",
    "    answer_idx = np.argmax(answer_logits)\n",
    "    answer = choices[answer_idx]\n",
    "    \n",
    "    return answer, outputs[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Inference Time "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extractive qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = pd.read_csv(\"square_skills/impl_skills.csv\")\n",
    "skill = \"span-extraction\"\n",
    "skills = load_skills(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_kwargs = {\"padding\": True, \"truncation\": True}\n",
    "task_kwargs = {\"show_null_answers\": False, \"topk\": 1, \"max_answer_len\": 128}\n",
    "model_kwargs = {\"\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_torch(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        model(**inputs)\n",
    "\n",
    "def run_onnx(qa_model, onnx_inputs):\n",
    "    qa_model.run(output_names=[\"start_logits\", \"end_logits\"], input_feed=dict(onnx_inputs))   \n",
    "\n",
    "def get_time_duration(func, model, inputs): \n",
    "    st= time.time()\n",
    "    func(model, inputs)\n",
    "    et = time.time()\n",
    "    return 1000 * (et - st)\n",
    "\n",
    "def save_df(df_new, path_to_logger_file = \"logger_all.csv\"):\n",
    "\n",
    "    if os.path.exists(path_to_logger_file):\n",
    "        df_fin = pd.concat([pd.read_csv(path_to_logger_file), df_new])\n",
    "        df_fin.to_csv(path_to_logger_file,index=False)\n",
    "    else: \n",
    "        df_new.to_csv(path_to_logger_file,index=False)\n",
    "\n",
    "def measure_time(perf_type, tokenizer, question, context, model):\n",
    "    if perf_type == \"base\":\n",
    "        inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True)\n",
    "        mode = run_torch\n",
    "        # time_once = get_time_duration(run_torch, model, inputs)\n",
    "\n",
    "    elif perf_type == \"seq_length\":\n",
    "        inputs = tokenizer(question, context, return_tensors=\"np\", truncation=True)\n",
    "        inputs = {key: np.array(inputs[key], dtype=np.int64) for key in inputs}\n",
    "        mode = run_onnx\n",
    "        # time_once = get_time_duration(run_onnx, model, inputs) \n",
    "    \n",
    "    time_once = get_time_duration(mode, model, inputs) \n",
    "\n",
    "    return time_once\n",
    "\n",
    "def performance_log(reader, adapter, perf_type, name, model, tokenizer, data, data_intervall = 1): #TODO add truncacte\n",
    "    df = pd.DataFrame(columns=[\"reader\", \"adapter\", \"model_name\", \"time once (ms)\", \"seq_length\", \"context\", \"question\", \"data_id\"])\n",
    "    \n",
    "    if adapter == \"drop\":\n",
    "        context_name = \"passage\"\n",
    "        id_name = \"query_id\"\n",
    "    else:\n",
    "        context_name = \"context\"\n",
    "        id_name = \"id\"\n",
    "\n",
    "    for i in range(0, len(data[context_name]), data_intervall):\n",
    "        context = data[context_name][i]\n",
    "        question = data[\"question\"][i]\n",
    "        time_duration = measure_time(perf_type, tokenizer, question, context, model)\n",
    "        \n",
    "        seq_length = len(context.split()) # TODO -> reduce stopwords? Real Tokenization?\n",
    "\n",
    "        df.loc[len(df)] = [reader, adapter, name, time_duration, seq_length, context, question, data[id_name][i]]\n",
    "        \n",
    "        print(\"Model: {}, Input Length {}: {:.3f} ms\".format(name, seq_length, time_duration))\n",
    "    save_df(df, path_to_logger_file=\"inference_time_extractive_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased drop\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m: \n\u001b[0;32m---> 12\u001b[0m     data \u001b[39m=\u001b[39m load_dataset(data_set_name, split\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalidation[:\u001b[39;49m\u001b[39m{\u001b[39;49;00mruns\u001b[39m}\u001b[39;49;00m\u001b[39m]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded dataset: \u001b[39m\u001b[39m{\u001b[39;00mdata_set_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(reader)\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/load.py:1718\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m ignore_verifications \u001b[39m=\u001b[39m ignore_verifications \u001b[39mor\u001b[39;00m save_infos\n\u001b[1;32m   1717\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 1718\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   1719\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   1720\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1721\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1722\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1723\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1724\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   1725\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1726\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1727\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1728\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   1729\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   1730\u001b[0m )\n\u001b[1;32m   1732\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/load.py:1488\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1487\u001b[0m     download_config\u001b[39m.\u001b[39muse_auth_token \u001b[39m=\u001b[39m use_auth_token\n\u001b[0;32m-> 1488\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1489\u001b[0m     path,\n\u001b[1;32m   1490\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1491\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1492\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1493\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1494\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1495\u001b[0m )\n\u001b[1;32m   1497\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m builder_cls \u001b[39m=\u001b[39m import_main_class(dataset_module\u001b[39m.\u001b[39mmodule_path)\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/load.py:1187\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   1186\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39min\u001b[39;00m [sibling\u001b[39m.\u001b[39mrfilename \u001b[39mfor\u001b[39;00m sibling \u001b[39min\u001b[39;00m dataset_info\u001b[39m.\u001b[39msiblings]:\n\u001b[0;32m-> 1187\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1188\u001b[0m         path,\n\u001b[1;32m   1189\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1190\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1191\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1192\u001b[0m         dynamic_modules_path\u001b[39m=\u001b[39;49mdynamic_modules_path,\n\u001b[1;32m   1193\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m   1194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1195\u001b[0m     \u001b[39mreturn\u001b[39;00m HubDatasetModuleFactoryWithoutScript(\n\u001b[1;32m   1196\u001b[0m         path,\n\u001b[1;32m   1197\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         download_mode\u001b[39m=\u001b[39mdownload_mode,\n\u001b[1;32m   1202\u001b[0m     )\u001b[39m.\u001b[39mget_module()\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/load.py:902\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_module\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DatasetModule:\n\u001b[1;32m    901\u001b[0m     \u001b[39m# get script and other files\u001b[39;00m\n\u001b[0;32m--> 902\u001b[0m     local_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_loading_script()\n\u001b[1;32m    903\u001b[0m     dataset_infos_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_dataset_infos_file()\n\u001b[1;32m    904\u001b[0m     dataset_readme_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_dataset_readme_file()\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/load.py:870\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithScript.download_loading_script\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39mif\u001b[39;00m download_config\u001b[39m.\u001b[39mdownload_desc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     download_config\u001b[39m.\u001b[39mdownload_desc \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDownloading builder script\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 870\u001b[0m \u001b[39mreturn\u001b[39;00m cached_path(file_path, download_config\u001b[39m=\u001b[39;49mdownload_config)\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/utils/file_utils.py:183\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     url_or_filename \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    182\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    184\u001b[0m         url_or_filename,\n\u001b[1;32m    185\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    186\u001b[0m         force_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mforce_download,\n\u001b[1;32m    187\u001b[0m         proxies\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    188\u001b[0m         resume_download\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mresume_download,\n\u001b[1;32m    189\u001b[0m         user_agent\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muser_agent,\n\u001b[1;32m    190\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mlocal_files_only,\n\u001b[1;32m    191\u001b[0m         use_etag\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_etag,\n\u001b[1;32m    192\u001b[0m         max_retries\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    193\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49muse_auth_token,\n\u001b[1;32m    194\u001b[0m         ignore_url_params\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mignore_url_params,\n\u001b[1;32m    195\u001b[0m         download_desc\u001b[39m=\u001b[39;49mdownload_config\u001b[39m.\u001b[39;49mdownload_desc,\n\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    198\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/utils/file_utils.py:476\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token, ignore_url_params, download_desc)\u001b[0m\n\u001b[1;32m    474\u001b[0m     connected \u001b[39m=\u001b[39m ftp_head(url)\n\u001b[1;32m    475\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 476\u001b[0m     response \u001b[39m=\u001b[39m http_head(\n\u001b[1;32m    477\u001b[0m         url,\n\u001b[1;32m    478\u001b[0m         allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    479\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    480\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m    481\u001b[0m         max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    482\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    483\u001b[0m     )\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:  \u001b[39m# ok\u001b[39;00m\n\u001b[1;32m    485\u001b[0m         etag \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m use_etag \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/utils/file_utils.py:390\u001b[0m, in \u001b[0;36mhttp_head\u001b[0;34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[0m\n\u001b[1;32m    388\u001b[0m headers \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(headers) \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    389\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m get_datasets_user_agent(user_agent\u001b[39m=\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39muser-agent\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 390\u001b[0m response \u001b[39m=\u001b[39m _request_with_retry(\n\u001b[1;32m    391\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    392\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    393\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    394\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    395\u001b[0m     cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    396\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49mallow_redirects,\n\u001b[1;32m    397\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    398\u001b[0m     max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    399\u001b[0m )\n\u001b[1;32m    400\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/datasets/utils/file_utils.py:319\u001b[0m, in \u001b[0;36m_request_with_retry\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[1;32m    317\u001b[0m tries \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(), url\u001b[39m=\u001b[39;49murl, timeout\u001b[39m=\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    320\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectTimeout, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mConnectionError) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1045\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1046\u001b[0m         (\n\u001b[1;32m   1047\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1053\u001b[0m     )\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m    360\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39msocket_options\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runs = 100\n",
    "\n",
    "for i in range(5):\n",
    "    for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "        print(\"Loading: {} {}\".format(reader, adapter))\n",
    "\n",
    "        #load adapter specific dataset\n",
    "        data_set_name = adapter\n",
    "        if data_set_name in [\"newsqa\", \"hotpotqa\"]:\n",
    "            continue\n",
    "        else: \n",
    "            data = load_dataset(data_set_name, split=f\"validation[:{runs}]\")\n",
    "            print(f\"Loaded dataset: {data_set_name}\")\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "        default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "        adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "        default_model.active_adapters = adapter_name\n",
    "        # eval base\n",
    "        performance_log(reader , adapter, \"base\", \"Base\", default_model, tokenizer, data)\n",
    "\n",
    "        #load quant model\n",
    "        quantized_base_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "        performance_log(reader , adapter, \"base\", \"Base Quant\", quantized_base_model, tokenizer, data)\n",
    "\n",
    "\n",
    "        #load onnx models\n",
    "        model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "        onnx_models_list = load_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "        onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"ONNX Quantized\", \"ONNX-OPT Quantized\"]\n",
    "\n",
    "        # eval onnx models\n",
    "        for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "            performance_log(reader , adapter, \"seq_length\", onnx_model_name, onnx_model, tokenizer, data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = pd.read_csv(\"square_skills/impl_skills.csv\")\n",
    "skill = \"categorical\"\n",
    "skills = load_skills(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_duration(func, model, tokenizer, question, context): \n",
    "    st= time.time()\n",
    "    func(model, tokenizer, question, context)\n",
    "    et = time.time()\n",
    "    return 1000 * (et - st)\n",
    "\n",
    "def save_df(df_new, path_to_logger_file = \"logger_all.csv\"):\n",
    "    if os.path.exists(path_to_logger_file):\n",
    "        df_fin = pd.concat([pd.read_csv(path_to_logger_file), df_new])\n",
    "        df_fin.to_csv(path_to_logger_file,index=False)\n",
    "    else: \n",
    "        df_new.to_csv(path_to_logger_file,index=False)\n",
    "\n",
    "def performance_log(adapter, reader, func, name, model, tokenizer, data, data_set_name, data_intervall = 0): \n",
    "    df = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"time once (ms)\", \"average_time 50 times (ms)\", \"seq_length\", \"context\", \"question\", \"data_id\", \"data_set_name\"])\n",
    "    \n",
    "    for i in range(0, len(data[\"passage\"]), data_intervall):\n",
    "        context = data[\"passage\"][i]\n",
    "        question = data[\"question\"][i]\n",
    "        time_duration = get_time_duration(func, model, tokenizer, question, context)\n",
    "        \n",
    "        seq_length = len(context.split()) # TODO -> reduce stopwords\n",
    "        \n",
    "        df.loc[len(df)] = [adapter, reader, name, time_duration, \"\", seq_length, context, question, i, data_set_name]\n",
    "        \n",
    "        print(\"Model: {}, Input Length {}: {:.3f} ms\".format(name, seq_length, time_duration))\n",
    "    save_df(df, path_to_logger_file=\"inference_time_categorical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset boolq (/Users/michaelhermann/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3115.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 217: 308.926 ms\n",
      "Model: Base, Input Length 191: 215.285 ms\n",
      "Model: Base, Input Length 54: 119.329 ms\n",
      "Model: Base, Input Length 85: 110.199 ms\n",
      "Model: Base, Input Length 47: 91.601 ms\n",
      "Model: Base, Input Length 55: 84.536 ms\n",
      "Model: Base, Input Length 94: 109.555 ms\n",
      "Model: Base, Input Length 110: 102.167 ms\n",
      "Model: Base, Input Length 14: 47.015 ms\n",
      "Model: Base, Input Length 85: 87.096 ms\n",
      "Model: Base, Input Length 138: 135.540 ms\n",
      "Model: Base, Input Length 85: 116.758 ms\n",
      "Model: Base, Input Length 97: 113.000 ms\n",
      "Model: Base, Input Length 90: 111.234 ms\n",
      "Model: Base, Input Length 116: 117.523 ms\n",
      "Model: Base, Input Length 55: 73.665 ms\n",
      "Model: Base, Input Length 113: 120.170 ms\n",
      "Model: Base, Input Length 49: 56.421 ms\n",
      "Model: Base, Input Length 116: 105.916 ms\n",
      "Model: Base, Input Length 46: 67.538 ms\n",
      "Model: Base, Input Length 125: 123.035 ms\n",
      "Model: Base, Input Length 160: 218.278 ms\n",
      "Model: Base, Input Length 43: 68.123 ms\n",
      "Model: Base, Input Length 53: 66.496 ms\n",
      "Model: Base, Input Length 111: 133.810 ms\n",
      "Model: Base, Input Length 80: 80.190 ms\n",
      "Model: Base, Input Length 90: 102.011 ms\n",
      "Model: Base, Input Length 190: 154.342 ms\n",
      "Model: Base, Input Length 50: 62.394 ms\n",
      "Model: Base, Input Length 92: 92.071 ms\n",
      "Model: Base, Input Length 96: 116.077 ms\n",
      "Model: Base, Input Length 45: 56.278 ms\n",
      "Model: Base, Input Length 71: 68.524 ms\n",
      "Model: Base, Input Length 79: 74.325 ms\n",
      "Model: Base, Input Length 89: 78.054 ms\n",
      "Model: Base, Input Length 110: 106.240 ms\n",
      "Model: Base, Input Length 82: 118.408 ms\n",
      "Model: Base, Input Length 142: 130.793 ms\n",
      "Model: Base, Input Length 140: 163.361 ms\n",
      "Model: Base, Input Length 31: 50.448 ms\n",
      "Model: Base, Input Length 189: 187.649 ms\n",
      "Model: Base, Input Length 123: 106.448 ms\n",
      "Model: Base, Input Length 100: 107.321 ms\n",
      "Model: Base, Input Length 36: 51.395 ms\n",
      "Model: Base, Input Length 68: 82.657 ms\n",
      "Model: Base, Input Length 72: 73.646 ms\n",
      "Model: Base, Input Length 84: 86.261 ms\n",
      "Model: Base, Input Length 126: 119.613 ms\n",
      "Model: Base, Input Length 147: 125.348 ms\n",
      "Model: Base, Input Length 78: 73.244 ms\n",
      "Model: Base, Input Length 35: 69.039 ms\n",
      "Model: Base, Input Length 96: 104.171 ms\n",
      "Model: Base, Input Length 147: 146.099 ms\n",
      "Model: Base, Input Length 138: 137.282 ms\n",
      "Model: Base, Input Length 48: 61.712 ms\n",
      "Model: Base, Input Length 591: 477.376 ms\n",
      "Model: Base, Input Length 86: 94.831 ms\n",
      "Model: Base, Input Length 39: 61.995 ms\n",
      "Model: Base, Input Length 64: 100.144 ms\n",
      "Model: Base, Input Length 52: 62.555 ms\n",
      "Model: Base, Input Length 104: 132.879 ms\n",
      "Model: Base, Input Length 30: 57.196 ms\n",
      "Model: Base, Input Length 107: 93.524 ms\n",
      "Model: Base, Input Length 89: 95.541 ms\n",
      "Model: Base, Input Length 32: 49.930 ms\n",
      "Model: Base, Input Length 47: 56.428 ms\n",
      "Model: Base, Input Length 75: 94.478 ms\n",
      "Model: Base, Input Length 24: 55.055 ms\n",
      "Model: Base, Input Length 100: 120.320 ms\n",
      "Model: Base, Input Length 110: 155.485 ms\n",
      "Model: Base, Input Length 59: 67.950 ms\n",
      "Model: Base, Input Length 130: 108.226 ms\n",
      "Model: Base, Input Length 106: 113.448 ms\n",
      "Model: Base, Input Length 39: 50.151 ms\n",
      "Model: Base, Input Length 66: 73.221 ms\n",
      "Model: Base, Input Length 105: 133.340 ms\n",
      "Model: Base, Input Length 103: 98.724 ms\n",
      "Model: Base, Input Length 33: 56.933 ms\n",
      "Model: Base, Input Length 122: 147.463 ms\n",
      "Model: Base, Input Length 60: 77.344 ms\n",
      "Model: Base, Input Length 40: 53.607 ms\n",
      "Model: Base, Input Length 63: 82.426 ms\n",
      "Model: Base, Input Length 158: 165.812 ms\n",
      "Model: Base, Input Length 123: 151.805 ms\n",
      "Model: Base, Input Length 110: 111.255 ms\n",
      "Model: Base, Input Length 145: 153.633 ms\n",
      "Model: Base, Input Length 50: 72.167 ms\n",
      "Model: Base, Input Length 46: 62.154 ms\n",
      "Model: Base, Input Length 32: 41.403 ms\n",
      "Model: Base, Input Length 74: 84.192 ms\n",
      "Model: Base, Input Length 68: 103.053 ms\n",
      "Model: Base, Input Length 89: 98.843 ms\n",
      "Model: Base, Input Length 55: 56.714 ms\n",
      "Model: Base, Input Length 46: 54.240 ms\n",
      "Model: Base, Input Length 20: 37.181 ms\n",
      "Model: Base, Input Length 37: 62.097 ms\n",
      "Model: Base, Input Length 85: 88.197 ms\n",
      "Model: Base, Input Length 122: 117.351 ms\n",
      "Model: Base, Input Length 80: 69.614 ms\n",
      "Model: Base, Input Length 176: 154.117 ms\n",
      "Model: Base, Input Length 141: 125.931 ms\n",
      "Model: Base, Input Length 83: 78.958 ms\n",
      "Model: Base, Input Length 231: 223.942 ms\n",
      "Model: Base, Input Length 125: 106.425 ms\n",
      "Model: Base, Input Length 202: 155.637 ms\n",
      "Model: Base, Input Length 44: 50.450 ms\n",
      "Model: Base, Input Length 15: 45.842 ms\n",
      "Model: Base, Input Length 90: 162.010 ms\n",
      "Model: Base, Input Length 62: 91.716 ms\n",
      "Model: Base, Input Length 114: 160.540 ms\n",
      "Model: Base, Input Length 153: 170.489 ms\n",
      "Model: Base, Input Length 112: 130.490 ms\n",
      "Model: Base, Input Length 57: 78.976 ms\n",
      "Model: Base, Input Length 106: 117.432 ms\n",
      "Model: Base, Input Length 92: 160.254 ms\n",
      "Model: Base, Input Length 86: 144.168 ms\n",
      "Model: Base, Input Length 45: 78.847 ms\n",
      "Model: Base, Input Length 110: 167.780 ms\n",
      "Model: Base, Input Length 73: 102.699 ms\n",
      "Model: Base, Input Length 121: 140.251 ms\n",
      "Model: Base, Input Length 159: 154.312 ms\n",
      "Model: Base, Input Length 51: 91.847 ms\n",
      "Model: Base, Input Length 94: 103.076 ms\n",
      "Model: Base, Input Length 70: 90.260 ms\n",
      "Model: Base, Input Length 92: 105.384 ms\n",
      "Model: Base, Input Length 55: 83.291 ms\n",
      "Model: Base, Input Length 31: 61.562 ms\n",
      "Model: Base, Input Length 39: 83.000 ms\n",
      "Model: Base, Input Length 104: 125.357 ms\n",
      "Model: Base, Input Length 249: 313.558 ms\n",
      "Model: Base, Input Length 80: 139.313 ms\n",
      "Model: Base, Input Length 142: 231.986 ms\n",
      "Model: Base, Input Length 203: 234.842 ms\n",
      "Model: Base, Input Length 97: 130.748 ms\n",
      "Model: Base, Input Length 147: 207.369 ms\n",
      "Model: Base, Input Length 42: 78.757 ms\n",
      "Model: Base, Input Length 154: 170.756 ms\n",
      "Model: Base, Input Length 192: 170.099 ms\n",
      "Model: Base, Input Length 78: 88.620 ms\n",
      "Model: Base, Input Length 274: 282.465 ms\n",
      "Model: Base, Input Length 72: 82.763 ms\n",
      "Model: Base, Input Length 65: 109.792 ms\n",
      "Model: Base, Input Length 57: 117.157 ms\n",
      "Model: Base, Input Length 96: 194.880 ms\n",
      "Model: Base, Input Length 66: 113.644 ms\n",
      "Model: Base, Input Length 37: 74.039 ms\n",
      "Model: Base, Input Length 40: 71.923 ms\n",
      "Model: Base, Input Length 124: 149.271 ms\n",
      "Model: Base, Input Length 19: 44.341 ms\n",
      "Model: Base, Input Length 203: 207.807 ms\n",
      "Model: Base, Input Length 56: 69.236 ms\n",
      "Model: Base, Input Length 97: 110.696 ms\n",
      "Model: Base, Input Length 82: 115.922 ms\n",
      "Model: Base, Input Length 79: 104.209 ms\n",
      "Model: Base, Input Length 74: 115.734 ms\n",
      "Model: Base, Input Length 143: 142.495 ms\n",
      "Model: Base, Input Length 52: 84.917 ms\n",
      "Model: Base, Input Length 157: 173.392 ms\n",
      "Model: Base, Input Length 113: 139.119 ms\n",
      "Model: Base, Input Length 163: 153.161 ms\n",
      "Model: Base, Input Length 71: 102.234 ms\n",
      "Model: Base, Input Length 76: 120.172 ms\n",
      "Model: Base, Input Length 24: 63.322 ms\n",
      "Model: Base, Input Length 137: 161.186 ms\n",
      "Model: Base, Input Length 63: 88.593 ms\n",
      "Model: Base, Input Length 102: 98.968 ms\n",
      "Model: Base, Input Length 52: 62.318 ms\n",
      "Model: Base, Input Length 76: 84.126 ms\n",
      "Model: Base, Input Length 89: 148.895 ms\n",
      "Model: Base, Input Length 75: 94.527 ms\n",
      "Model: Base, Input Length 57: 68.283 ms\n",
      "Model: Base, Input Length 95: 107.842 ms\n",
      "Model: Base, Input Length 79: 102.164 ms\n",
      "Model: Base, Input Length 162: 230.893 ms\n",
      "Model: Base, Input Length 49: 72.847 ms\n",
      "Model: Base, Input Length 39: 57.184 ms\n",
      "Model: Base, Input Length 117: 115.285 ms\n",
      "Model: Base, Input Length 188: 166.274 ms\n",
      "Model: Base, Input Length 131: 121.175 ms\n",
      "Model: Base, Input Length 59: 73.571 ms\n",
      "Model: Base, Input Length 55: 62.695 ms\n",
      "Model: Base, Input Length 43: 62.513 ms\n",
      "Model: Base, Input Length 91: 99.548 ms\n",
      "Model: Base, Input Length 35: 54.598 ms\n",
      "Model: Base, Input Length 78: 89.160 ms\n",
      "Model: Base, Input Length 90: 107.994 ms\n",
      "Model: Base, Input Length 65: 72.652 ms\n",
      "Model: Base, Input Length 22: 57.083 ms\n",
      "Model: Base, Input Length 156: 174.047 ms\n",
      "Model: Base, Input Length 84: 109.994 ms\n",
      "Model: Base, Input Length 93: 119.330 ms\n",
      "Model: Base, Input Length 71: 161.763 ms\n",
      "Model: Base, Input Length 90: 131.888 ms\n",
      "Model: Base, Input Length 106: 131.388 ms\n",
      "Model: Base, Input Length 126: 124.167 ms\n",
      "Model: Base, Input Length 386: 486.590 ms\n",
      "Model: Base, Input Length 155: 193.377 ms\n",
      "Model: Base, Input Length 37: 65.541 ms\n",
      "Model: Base, Input Length 65: 89.073 ms\n",
      "Model: Base, Input Length 71: 106.438 ms\n",
      "Model: Base, Input Length 320: 354.943 ms\n",
      "Model: Base, Input Length 130: 154.736 ms\n",
      "Model: Base, Input Length 43: 61.518 ms\n",
      "Model: Base, Input Length 94: 103.093 ms\n",
      "Model: Base, Input Length 98: 111.041 ms\n",
      "Model: Base, Input Length 66: 78.319 ms\n",
      "Model: Base, Input Length 122: 136.881 ms\n",
      "Model: Base, Input Length 49: 77.161 ms\n",
      "Model: Base, Input Length 119: 139.589 ms\n",
      "Model: Base, Input Length 117: 143.307 ms\n",
      "Model: Base, Input Length 79: 120.615 ms\n",
      "Model: Base, Input Length 92: 139.055 ms\n",
      "Model: Base, Input Length 60: 108.286 ms\n",
      "Model: Base, Input Length 246: 300.492 ms\n",
      "Model: Base, Input Length 42: 89.712 ms\n",
      "Model: Base, Input Length 41: 64.354 ms\n",
      "Model: Base, Input Length 88: 106.663 ms\n",
      "Model: Base, Input Length 46: 65.140 ms\n",
      "Model: Base, Input Length 86: 108.067 ms\n",
      "Model: Base, Input Length 97: 122.591 ms\n",
      "Model: Base, Input Length 136: 170.363 ms\n",
      "Model: Base, Input Length 133: 145.594 ms\n",
      "Model: Base, Input Length 142: 134.692 ms\n",
      "Model: Base, Input Length 86: 160.743 ms\n",
      "Model: Base, Input Length 110: 159.089 ms\n",
      "Model: Base, Input Length 216: 319.704 ms\n",
      "Model: Base, Input Length 54: 127.187 ms\n",
      "Model: Base, Input Length 64: 86.369 ms\n",
      "Model: Base, Input Length 40: 60.689 ms\n",
      "Model: Base, Input Length 76: 83.050 ms\n",
      "Model: Base, Input Length 67: 70.773 ms\n",
      "Model: Base, Input Length 80: 87.714 ms\n",
      "Model: Base, Input Length 67: 67.829 ms\n",
      "Model: Base, Input Length 79: 90.280 ms\n",
      "Model: Base, Input Length 43: 59.597 ms\n",
      "Model: Base, Input Length 194: 255.804 ms\n",
      "Model: Base, Input Length 31: 89.572 ms\n",
      "Model: Base, Input Length 107: 161.962 ms\n",
      "Model: Base, Input Length 55: 93.037 ms\n",
      "Model: Base, Input Length 58: 97.486 ms\n",
      "Model: Base, Input Length 67: 129.710 ms\n",
      "Model: Base, Input Length 158: 263.449 ms\n",
      "Model: Base, Input Length 39: 62.865 ms\n",
      "Model: Base, Input Length 45: 61.842 ms\n",
      "Model: Base, Input Length 100: 152.184 ms\n",
      "Model: Base, Input Length 125: 177.451 ms\n",
      "Model: Base, Input Length 75: 88.007 ms\n",
      "Model: Base, Input Length 61: 83.377 ms\n",
      "Model: Base, Input Length 159: 160.565 ms\n",
      "Model: Base, Input Length 97: 135.954 ms\n",
      "Model: Base Quantized, Input Length 217: 340.720 ms\n",
      "Model: Base Quantized, Input Length 191: 248.452 ms\n",
      "Model: Base Quantized, Input Length 54: 88.541 ms\n",
      "Model: Base Quantized, Input Length 85: 113.605 ms\n",
      "Model: Base Quantized, Input Length 47: 107.659 ms\n",
      "Model: Base Quantized, Input Length 55: 105.666 ms\n",
      "Model: Base Quantized, Input Length 94: 107.278 ms\n",
      "Model: Base Quantized, Input Length 110: 132.424 ms\n",
      "Model: Base Quantized, Input Length 14: 52.803 ms\n",
      "Model: Base Quantized, Input Length 85: 99.457 ms\n",
      "Model: Base Quantized, Input Length 138: 131.338 ms\n",
      "Model: Base Quantized, Input Length 85: 96.964 ms\n",
      "Model: Base Quantized, Input Length 97: 122.924 ms\n",
      "Model: Base Quantized, Input Length 90: 113.433 ms\n",
      "Model: Base Quantized, Input Length 116: 126.698 ms\n",
      "Model: Base Quantized, Input Length 55: 73.122 ms\n",
      "Model: Base Quantized, Input Length 113: 114.226 ms\n",
      "Model: Base Quantized, Input Length 49: 69.857 ms\n",
      "Model: Base Quantized, Input Length 116: 120.931 ms\n",
      "Model: Base Quantized, Input Length 46: 93.944 ms\n",
      "Model: Base Quantized, Input Length 125: 154.932 ms\n",
      "Model: Base Quantized, Input Length 160: 166.976 ms\n",
      "Model: Base Quantized, Input Length 43: 65.665 ms\n",
      "Model: Base Quantized, Input Length 53: 77.991 ms\n",
      "Model: Base Quantized, Input Length 111: 118.414 ms\n",
      "Model: Base Quantized, Input Length 80: 89.803 ms\n",
      "Model: Base Quantized, Input Length 90: 109.176 ms\n",
      "Model: Base Quantized, Input Length 190: 187.534 ms\n",
      "Model: Base Quantized, Input Length 50: 99.726 ms\n",
      "Model: Base Quantized, Input Length 92: 112.041 ms\n",
      "Model: Base Quantized, Input Length 96: 131.058 ms\n",
      "Model: Base Quantized, Input Length 45: 83.172 ms\n",
      "Model: Base Quantized, Input Length 71: 87.472 ms\n",
      "Model: Base Quantized, Input Length 79: 127.797 ms\n",
      "Model: Base Quantized, Input Length 89: 127.075 ms\n",
      "Model: Base Quantized, Input Length 110: 170.992 ms\n",
      "Model: Base Quantized, Input Length 82: 108.718 ms\n",
      "Model: Base Quantized, Input Length 142: 157.239 ms\n",
      "Model: Base Quantized, Input Length 140: 190.787 ms\n",
      "Model: Base Quantized, Input Length 31: 73.521 ms\n",
      "Model: Base Quantized, Input Length 189: 239.303 ms\n",
      "Model: Base Quantized, Input Length 123: 130.468 ms\n",
      "Model: Base Quantized, Input Length 100: 142.079 ms\n",
      "Model: Base Quantized, Input Length 36: 70.243 ms\n",
      "Model: Base Quantized, Input Length 68: 82.689 ms\n",
      "Model: Base Quantized, Input Length 72: 81.187 ms\n",
      "Model: Base Quantized, Input Length 84: 100.477 ms\n",
      "Model: Base Quantized, Input Length 126: 151.024 ms\n",
      "Model: Base Quantized, Input Length 147: 144.013 ms\n",
      "Model: Base Quantized, Input Length 78: 98.797 ms\n",
      "Model: Base Quantized, Input Length 35: 59.192 ms\n",
      "Model: Base Quantized, Input Length 96: 115.497 ms\n",
      "Model: Base Quantized, Input Length 147: 190.581 ms\n",
      "Model: Base Quantized, Input Length 138: 141.341 ms\n",
      "Model: Base Quantized, Input Length 48: 75.420 ms\n",
      "Model: Base Quantized, Input Length 591: 423.432 ms\n",
      "Model: Base Quantized, Input Length 86: 127.146 ms\n",
      "Model: Base Quantized, Input Length 39: 77.371 ms\n",
      "Model: Base Quantized, Input Length 64: 106.317 ms\n",
      "Model: Base Quantized, Input Length 52: 85.810 ms\n",
      "Model: Base Quantized, Input Length 104: 177.127 ms\n",
      "Model: Base Quantized, Input Length 30: 59.690 ms\n",
      "Model: Base Quantized, Input Length 107: 112.265 ms\n",
      "Model: Base Quantized, Input Length 89: 104.905 ms\n",
      "Model: Base Quantized, Input Length 32: 75.532 ms\n",
      "Model: Base Quantized, Input Length 47: 85.583 ms\n",
      "Model: Base Quantized, Input Length 75: 97.630 ms\n",
      "Model: Base Quantized, Input Length 24: 62.472 ms\n",
      "Model: Base Quantized, Input Length 100: 140.490 ms\n",
      "Model: Base Quantized, Input Length 110: 174.370 ms\n",
      "Model: Base Quantized, Input Length 59: 88.287 ms\n",
      "Model: Base Quantized, Input Length 130: 123.169 ms\n",
      "Model: Base Quantized, Input Length 106: 125.431 ms\n",
      "Model: Base Quantized, Input Length 39: 84.937 ms\n",
      "Model: Base Quantized, Input Length 66: 111.969 ms\n",
      "Model: Base Quantized, Input Length 105: 174.863 ms\n",
      "Model: Base Quantized, Input Length 103: 163.593 ms\n",
      "Model: Base Quantized, Input Length 33: 88.435 ms\n",
      "Model: Base Quantized, Input Length 122: 156.030 ms\n",
      "Model: Base Quantized, Input Length 60: 81.316 ms\n",
      "Model: Base Quantized, Input Length 40: 94.372 ms\n",
      "Model: Base Quantized, Input Length 63: 116.966 ms\n",
      "Model: Base Quantized, Input Length 158: 208.766 ms\n",
      "Model: Base Quantized, Input Length 123: 161.482 ms\n",
      "Model: Base Quantized, Input Length 110: 129.702 ms\n",
      "Model: Base Quantized, Input Length 145: 201.873 ms\n",
      "Model: Base Quantized, Input Length 50: 89.914 ms\n",
      "Model: Base Quantized, Input Length 46: 76.518 ms\n",
      "Model: Base Quantized, Input Length 32: 60.533 ms\n",
      "Model: Base Quantized, Input Length 74: 104.788 ms\n",
      "Model: Base Quantized, Input Length 68: 111.852 ms\n",
      "Model: Base Quantized, Input Length 89: 105.521 ms\n",
      "Model: Base Quantized, Input Length 55: 82.169 ms\n",
      "Model: Base Quantized, Input Length 46: 76.852 ms\n",
      "Model: Base Quantized, Input Length 20: 51.144 ms\n",
      "Model: Base Quantized, Input Length 37: 70.713 ms\n",
      "Model: Base Quantized, Input Length 85: 112.753 ms\n",
      "Model: Base Quantized, Input Length 122: 149.897 ms\n",
      "Model: Base Quantized, Input Length 80: 123.219 ms\n",
      "Model: Base Quantized, Input Length 176: 189.209 ms\n",
      "Model: Base Quantized, Input Length 141: 168.072 ms\n",
      "Model: Base Quantized, Input Length 83: 101.617 ms\n",
      "Model: Base Quantized, Input Length 231: 216.580 ms\n",
      "Model: Base Quantized, Input Length 125: 144.602 ms\n",
      "Model: Base Quantized, Input Length 202: 181.254 ms\n",
      "Model: Base Quantized, Input Length 44: 71.533 ms\n",
      "Model: Base Quantized, Input Length 15: 53.162 ms\n",
      "Model: Base Quantized, Input Length 90: 132.999 ms\n",
      "Model: Base Quantized, Input Length 62: 85.338 ms\n",
      "Model: Base Quantized, Input Length 114: 133.562 ms\n",
      "Model: Base Quantized, Input Length 153: 156.519 ms\n",
      "Model: Base Quantized, Input Length 112: 122.108 ms\n",
      "Model: Base Quantized, Input Length 57: 83.582 ms\n",
      "Model: Base Quantized, Input Length 106: 117.176 ms\n",
      "Model: Base Quantized, Input Length 92: 120.595 ms\n",
      "Model: Base Quantized, Input Length 86: 112.492 ms\n",
      "Model: Base Quantized, Input Length 45: 77.147 ms\n",
      "Model: Base Quantized, Input Length 110: 135.082 ms\n",
      "Model: Base Quantized, Input Length 73: 113.989 ms\n",
      "Model: Base Quantized, Input Length 121: 154.862 ms\n",
      "Model: Base Quantized, Input Length 159: 193.673 ms\n",
      "Model: Base Quantized, Input Length 51: 102.295 ms\n",
      "Model: Base Quantized, Input Length 94: 150.561 ms\n",
      "Model: Base Quantized, Input Length 70: 103.727 ms\n",
      "Model: Base Quantized, Input Length 92: 122.299 ms\n",
      "Model: Base Quantized, Input Length 55: 112.498 ms\n",
      "Model: Base Quantized, Input Length 31: 83.073 ms\n",
      "Model: Base Quantized, Input Length 39: 94.390 ms\n",
      "Model: Base Quantized, Input Length 104: 119.297 ms\n",
      "Model: Base Quantized, Input Length 249: 267.253 ms\n",
      "Model: Base Quantized, Input Length 80: 113.833 ms\n",
      "Model: Base Quantized, Input Length 142: 191.979 ms\n",
      "Model: Base Quantized, Input Length 203: 177.721 ms\n",
      "Model: Base Quantized, Input Length 97: 112.096 ms\n",
      "Model: Base Quantized, Input Length 147: 143.614 ms\n",
      "Model: Base Quantized, Input Length 42: 75.852 ms\n",
      "Model: Base Quantized, Input Length 154: 149.534 ms\n",
      "Model: Base Quantized, Input Length 192: 168.306 ms\n",
      "Model: Base Quantized, Input Length 78: 95.828 ms\n",
      "Model: Base Quantized, Input Length 274: 268.062 ms\n",
      "Model: Base Quantized, Input Length 72: 85.867 ms\n",
      "Model: Base Quantized, Input Length 65: 92.181 ms\n",
      "Model: Base Quantized, Input Length 57: 74.428 ms\n",
      "Model: Base Quantized, Input Length 96: 107.148 ms\n",
      "Model: Base Quantized, Input Length 66: 86.604 ms\n",
      "Model: Base Quantized, Input Length 37: 74.190 ms\n",
      "Model: Base Quantized, Input Length 40: 71.499 ms\n",
      "Model: Base Quantized, Input Length 124: 132.509 ms\n",
      "Model: Base Quantized, Input Length 19: 54.151 ms\n",
      "Model: Base Quantized, Input Length 203: 177.347 ms\n",
      "Model: Base Quantized, Input Length 56: 70.195 ms\n",
      "Model: Base Quantized, Input Length 97: 105.318 ms\n",
      "Model: Base Quantized, Input Length 82: 119.757 ms\n",
      "Model: Base Quantized, Input Length 79: 92.626 ms\n",
      "Model: Base Quantized, Input Length 74: 92.803 ms\n",
      "Model: Base Quantized, Input Length 143: 129.354 ms\n",
      "Model: Base Quantized, Input Length 52: 83.249 ms\n",
      "Model: Base Quantized, Input Length 157: 166.721 ms\n",
      "Model: Base Quantized, Input Length 113: 117.454 ms\n",
      "Model: Base Quantized, Input Length 163: 152.043 ms\n",
      "Model: Base Quantized, Input Length 71: 89.972 ms\n",
      "Model: Base Quantized, Input Length 76: 92.474 ms\n",
      "Model: Base Quantized, Input Length 24: 62.773 ms\n",
      "Model: Base Quantized, Input Length 137: 164.565 ms\n",
      "Model: Base Quantized, Input Length 63: 99.405 ms\n",
      "Model: Base Quantized, Input Length 102: 106.201 ms\n",
      "Model: Base Quantized, Input Length 52: 74.885 ms\n",
      "Model: Base Quantized, Input Length 76: 92.320 ms\n",
      "Model: Base Quantized, Input Length 89: 120.089 ms\n",
      "Model: Base Quantized, Input Length 75: 95.405 ms\n",
      "Model: Base Quantized, Input Length 57: 72.779 ms\n",
      "Model: Base Quantized, Input Length 95: 147.321 ms\n",
      "Model: Base Quantized, Input Length 79: 117.357 ms\n",
      "Model: Base Quantized, Input Length 162: 242.241 ms\n",
      "Model: Base Quantized, Input Length 49: 71.865 ms\n",
      "Model: Base Quantized, Input Length 39: 64.339 ms\n",
      "Model: Base Quantized, Input Length 117: 161.546 ms\n",
      "Model: Base Quantized, Input Length 188: 237.366 ms\n",
      "Model: Base Quantized, Input Length 131: 180.744 ms\n",
      "Model: Base Quantized, Input Length 59: 85.244 ms\n",
      "Model: Base Quantized, Input Length 55: 82.521 ms\n",
      "Model: Base Quantized, Input Length 43: 87.761 ms\n",
      "Model: Base Quantized, Input Length 91: 132.817 ms\n",
      "Model: Base Quantized, Input Length 35: 82.607 ms\n",
      "Model: Base Quantized, Input Length 78: 114.194 ms\n",
      "Model: Base Quantized, Input Length 90: 119.461 ms\n",
      "Model: Base Quantized, Input Length 65: 99.455 ms\n",
      "Model: Base Quantized, Input Length 22: 72.405 ms\n",
      "Model: Base Quantized, Input Length 156: 221.860 ms\n",
      "Model: Base Quantized, Input Length 84: 139.896 ms\n",
      "Model: Base Quantized, Input Length 93: 125.441 ms\n",
      "Model: Base Quantized, Input Length 71: 121.874 ms\n",
      "Model: Base Quantized, Input Length 90: 119.949 ms\n",
      "Model: Base Quantized, Input Length 106: 112.390 ms\n",
      "Model: Base Quantized, Input Length 126: 183.444 ms\n",
      "Model: Base Quantized, Input Length 386: 428.853 ms\n",
      "Model: Base Quantized, Input Length 155: 163.353 ms\n",
      "Model: Base Quantized, Input Length 37: 71.077 ms\n",
      "Model: Base Quantized, Input Length 65: 79.715 ms\n",
      "Model: Base Quantized, Input Length 71: 95.637 ms\n",
      "Model: Base Quantized, Input Length 320: 404.011 ms\n",
      "Model: Base Quantized, Input Length 130: 159.513 ms\n",
      "Model: Base Quantized, Input Length 43: 98.608 ms\n",
      "Model: Base Quantized, Input Length 94: 102.239 ms\n",
      "Model: Base Quantized, Input Length 98: 105.954 ms\n",
      "Model: Base Quantized, Input Length 66: 87.227 ms\n",
      "Model: Base Quantized, Input Length 122: 191.385 ms\n",
      "Model: Base Quantized, Input Length 49: 92.733 ms\n",
      "Model: Base Quantized, Input Length 119: 155.588 ms\n",
      "Model: Base Quantized, Input Length 117: 123.462 ms\n",
      "Model: Base Quantized, Input Length 79: 118.414 ms\n",
      "Model: Base Quantized, Input Length 92: 118.367 ms\n",
      "Model: Base Quantized, Input Length 60: 99.664 ms\n",
      "Model: Base Quantized, Input Length 246: 233.680 ms\n",
      "Model: Base Quantized, Input Length 42: 74.276 ms\n",
      "Model: Base Quantized, Input Length 41: 73.991 ms\n",
      "Model: Base Quantized, Input Length 88: 119.780 ms\n",
      "Model: Base Quantized, Input Length 46: 81.496 ms\n",
      "Model: Base Quantized, Input Length 86: 125.231 ms\n",
      "Model: Base Quantized, Input Length 97: 121.909 ms\n",
      "Model: Base Quantized, Input Length 136: 186.888 ms\n",
      "Model: Base Quantized, Input Length 133: 170.713 ms\n",
      "Model: Base Quantized, Input Length 142: 165.220 ms\n",
      "Model: Base Quantized, Input Length 86: 142.180 ms\n",
      "Model: Base Quantized, Input Length 110: 148.011 ms\n",
      "Model: Base Quantized, Input Length 216: 302.465 ms\n",
      "Model: Base Quantized, Input Length 54: 96.469 ms\n",
      "Model: Base Quantized, Input Length 64: 88.611 ms\n",
      "Model: Base Quantized, Input Length 40: 87.041 ms\n",
      "Model: Base Quantized, Input Length 76: 94.481 ms\n",
      "Model: Base Quantized, Input Length 67: 84.944 ms\n",
      "Model: Base Quantized, Input Length 80: 104.672 ms\n",
      "Model: Base Quantized, Input Length 67: 99.230 ms\n",
      "Model: Base Quantized, Input Length 79: 111.164 ms\n",
      "Model: Base Quantized, Input Length 43: 77.517 ms\n",
      "Model: Base Quantized, Input Length 194: 247.215 ms\n",
      "Model: Base Quantized, Input Length 31: 81.890 ms\n",
      "Model: Base Quantized, Input Length 107: 140.275 ms\n",
      "Model: Base Quantized, Input Length 55: 79.217 ms\n",
      "Model: Base Quantized, Input Length 58: 89.614 ms\n",
      "Model: Base Quantized, Input Length 67: 103.195 ms\n",
      "Model: Base Quantized, Input Length 158: 271.093 ms\n",
      "Model: Base Quantized, Input Length 39: 71.823 ms\n",
      "Model: Base Quantized, Input Length 45: 63.553 ms\n",
      "Model: Base Quantized, Input Length 100: 106.108 ms\n",
      "Model: Base Quantized, Input Length 125: 139.599 ms\n",
      "Model: Base Quantized, Input Length 75: 106.768 ms\n",
      "Model: Base Quantized, Input Length 61: 105.234 ms\n",
      "Model: Base Quantized, Input Length 159: 200.223 ms\n",
      "Model: Base Quantized, Input Length 97: 132.743 ms\n",
      "Model: ONNX, Input Length 217: 121.440 ms\n",
      "Model: ONNX, Input Length 191: 108.878 ms\n",
      "Model: ONNX, Input Length 54: 37.489 ms\n",
      "Model: ONNX, Input Length 85: 56.360 ms\n",
      "Model: ONNX, Input Length 47: 64.512 ms\n",
      "Model: ONNX, Input Length 55: 57.996 ms\n",
      "Model: ONNX, Input Length 94: 76.289 ms\n",
      "Model: ONNX, Input Length 110: 62.138 ms\n",
      "Model: ONNX, Input Length 14: 20.697 ms\n",
      "Model: ONNX, Input Length 85: 50.402 ms\n",
      "Model: ONNX, Input Length 138: 84.246 ms\n",
      "Model: ONNX, Input Length 85: 54.215 ms\n",
      "Model: ONNX, Input Length 97: 56.812 ms\n",
      "Model: ONNX, Input Length 90: 59.639 ms\n",
      "Model: ONNX, Input Length 116: 77.765 ms\n",
      "Model: ONNX, Input Length 55: 40.999 ms\n",
      "Model: ONNX, Input Length 113: 76.743 ms\n",
      "Model: ONNX, Input Length 49: 31.027 ms\n",
      "Model: ONNX, Input Length 116: 65.530 ms\n",
      "Model: ONNX, Input Length 46: 39.065 ms\n",
      "Model: ONNX, Input Length 125: 76.148 ms\n",
      "Model: ONNX, Input Length 160: 88.253 ms\n",
      "Model: ONNX, Input Length 43: 41.953 ms\n",
      "Model: ONNX, Input Length 53: 45.767 ms\n",
      "Model: ONNX, Input Length 111: 90.270 ms\n",
      "Model: ONNX, Input Length 80: 63.558 ms\n",
      "Model: ONNX, Input Length 90: 73.878 ms\n",
      "Model: ONNX, Input Length 190: 112.208 ms\n",
      "Model: ONNX, Input Length 50: 46.126 ms\n",
      "Model: ONNX, Input Length 92: 58.820 ms\n",
      "Model: ONNX, Input Length 96: 71.601 ms\n",
      "Model: ONNX, Input Length 45: 42.312 ms\n",
      "Model: ONNX, Input Length 71: 48.432 ms\n",
      "Model: ONNX, Input Length 79: 43.980 ms\n",
      "Model: ONNX, Input Length 89: 47.226 ms\n",
      "Model: ONNX, Input Length 110: 58.993 ms\n",
      "Model: ONNX, Input Length 82: 50.095 ms\n",
      "Model: ONNX, Input Length 142: 77.149 ms\n",
      "Model: ONNX, Input Length 140: 86.381 ms\n",
      "Model: ONNX, Input Length 31: 25.741 ms\n",
      "Model: ONNX, Input Length 189: 114.212 ms\n",
      "Model: ONNX, Input Length 123: 65.193 ms\n",
      "Model: ONNX, Input Length 100: 61.112 ms\n",
      "Model: ONNX, Input Length 36: 30.909 ms\n",
      "Model: ONNX, Input Length 68: 41.923 ms\n",
      "Model: ONNX, Input Length 72: 42.475 ms\n",
      "Model: ONNX, Input Length 84: 45.919 ms\n",
      "Model: ONNX, Input Length 126: 64.488 ms\n",
      "Model: ONNX, Input Length 147: 75.807 ms\n",
      "Model: ONNX, Input Length 78: 45.282 ms\n",
      "Model: ONNX, Input Length 35: 28.394 ms\n",
      "Model: ONNX, Input Length 96: 48.541 ms\n",
      "Model: ONNX, Input Length 147: 71.342 ms\n",
      "Model: ONNX, Input Length 138: 78.979 ms\n",
      "Model: ONNX, Input Length 48: 40.575 ms\n",
      "Model: ONNX, Input Length 591: 223.461 ms\n",
      "Model: ONNX, Input Length 86: 53.688 ms\n",
      "Model: ONNX, Input Length 39: 33.971 ms\n",
      "Model: ONNX, Input Length 64: 43.157 ms\n",
      "Model: ONNX, Input Length 52: 40.269 ms\n",
      "Model: ONNX, Input Length 104: 69.729 ms\n",
      "Model: ONNX, Input Length 30: 26.478 ms\n",
      "Model: ONNX, Input Length 107: 56.653 ms\n",
      "Model: ONNX, Input Length 89: 46.943 ms\n",
      "Model: ONNX, Input Length 32: 25.958 ms\n",
      "Model: ONNX, Input Length 47: 34.020 ms\n",
      "Model: ONNX, Input Length 75: 48.403 ms\n",
      "Model: ONNX, Input Length 24: 27.304 ms\n",
      "Model: ONNX, Input Length 100: 62.303 ms\n",
      "Model: ONNX, Input Length 110: 69.168 ms\n",
      "Model: ONNX, Input Length 59: 38.911 ms\n",
      "Model: ONNX, Input Length 130: 61.716 ms\n",
      "Model: ONNX, Input Length 106: 59.883 ms\n",
      "Model: ONNX, Input Length 39: 28.932 ms\n",
      "Model: ONNX, Input Length 66: 40.574 ms\n",
      "Model: ONNX, Input Length 105: 55.395 ms\n",
      "Model: ONNX, Input Length 103: 47.950 ms\n",
      "Model: ONNX, Input Length 33: 30.659 ms\n",
      "Model: ONNX, Input Length 122: 69.048 ms\n",
      "Model: ONNX, Input Length 60: 37.524 ms\n",
      "Model: ONNX, Input Length 40: 33.078 ms\n",
      "Model: ONNX, Input Length 63: 39.706 ms\n",
      "Model: ONNX, Input Length 158: 79.166 ms\n",
      "Model: ONNX, Input Length 123: 70.019 ms\n",
      "Model: ONNX, Input Length 110: 55.957 ms\n",
      "Model: ONNX, Input Length 145: 75.833 ms\n",
      "Model: ONNX, Input Length 50: 33.997 ms\n",
      "Model: ONNX, Input Length 46: 36.032 ms\n",
      "Model: ONNX, Input Length 32: 24.559 ms\n",
      "Model: ONNX, Input Length 74: 53.102 ms\n",
      "Model: ONNX, Input Length 68: 53.645 ms\n",
      "Model: ONNX, Input Length 89: 46.490 ms\n",
      "Model: ONNX, Input Length 55: 35.054 ms\n",
      "Model: ONNX, Input Length 46: 36.783 ms\n",
      "Model: ONNX, Input Length 20: 19.949 ms\n",
      "Model: ONNX, Input Length 37: 29.119 ms\n",
      "Model: ONNX, Input Length 85: 45.679 ms\n",
      "Model: ONNX, Input Length 122: 67.212 ms\n",
      "Model: ONNX, Input Length 80: 43.546 ms\n",
      "Model: ONNX, Input Length 176: 88.020 ms\n",
      "Model: ONNX, Input Length 141: 70.911 ms\n",
      "Model: ONNX, Input Length 83: 48.164 ms\n",
      "Model: ONNX, Input Length 231: 114.190 ms\n",
      "Model: ONNX, Input Length 125: 63.997 ms\n",
      "Model: ONNX, Input Length 202: 94.196 ms\n",
      "Model: ONNX, Input Length 44: 30.594 ms\n",
      "Model: ONNX, Input Length 15: 20.995 ms\n",
      "Model: ONNX, Input Length 90: 57.420 ms\n",
      "Model: ONNX, Input Length 62: 42.115 ms\n",
      "Model: ONNX, Input Length 114: 75.833 ms\n",
      "Model: ONNX, Input Length 153: 110.893 ms\n",
      "Model: ONNX, Input Length 112: 71.712 ms\n",
      "Model: ONNX, Input Length 57: 44.955 ms\n",
      "Model: ONNX, Input Length 106: 61.107 ms\n",
      "Model: ONNX, Input Length 92: 55.080 ms\n",
      "Model: ONNX, Input Length 86: 52.084 ms\n",
      "Model: ONNX, Input Length 45: 35.413 ms\n",
      "Model: ONNX, Input Length 110: 76.350 ms\n",
      "Model: ONNX, Input Length 73: 52.740 ms\n",
      "Model: ONNX, Input Length 121: 66.414 ms\n",
      "Model: ONNX, Input Length 159: 90.952 ms\n",
      "Model: ONNX, Input Length 51: 49.554 ms\n",
      "Model: ONNX, Input Length 94: 51.767 ms\n",
      "Model: ONNX, Input Length 70: 51.910 ms\n",
      "Model: ONNX, Input Length 92: 50.025 ms\n",
      "Model: ONNX, Input Length 55: 45.009 ms\n",
      "Model: ONNX, Input Length 31: 30.187 ms\n",
      "Model: ONNX, Input Length 39: 29.194 ms\n",
      "Model: ONNX, Input Length 104: 61.201 ms\n",
      "Model: ONNX, Input Length 249: 166.746 ms\n",
      "Model: ONNX, Input Length 80: 54.740 ms\n",
      "Model: ONNX, Input Length 142: 78.186 ms\n",
      "Model: ONNX, Input Length 203: 96.660 ms\n",
      "Model: ONNX, Input Length 97: 59.195 ms\n",
      "Model: ONNX, Input Length 147: 82.363 ms\n",
      "Model: ONNX, Input Length 42: 34.835 ms\n",
      "Model: ONNX, Input Length 154: 83.830 ms\n",
      "Model: ONNX, Input Length 192: 106.711 ms\n",
      "Model: ONNX, Input Length 78: 47.972 ms\n",
      "Model: ONNX, Input Length 274: 164.265 ms\n",
      "Model: ONNX, Input Length 72: 47.302 ms\n",
      "Model: ONNX, Input Length 65: 50.338 ms\n",
      "Model: ONNX, Input Length 57: 41.878 ms\n",
      "Model: ONNX, Input Length 96: 58.531 ms\n",
      "Model: ONNX, Input Length 66: 44.039 ms\n",
      "Model: ONNX, Input Length 37: 31.341 ms\n",
      "Model: ONNX, Input Length 40: 31.368 ms\n",
      "Model: ONNX, Input Length 124: 75.343 ms\n",
      "Model: ONNX, Input Length 19: 25.765 ms\n",
      "Model: ONNX, Input Length 203: 117.950 ms\n",
      "Model: ONNX, Input Length 56: 35.019 ms\n",
      "Model: ONNX, Input Length 97: 53.397 ms\n",
      "Model: ONNX, Input Length 82: 65.274 ms\n",
      "Model: ONNX, Input Length 79: 50.637 ms\n",
      "Model: ONNX, Input Length 74: 46.761 ms\n",
      "Model: ONNX, Input Length 143: 84.851 ms\n",
      "Model: ONNX, Input Length 52: 39.191 ms\n",
      "Model: ONNX, Input Length 157: 77.334 ms\n",
      "Model: ONNX, Input Length 113: 63.430 ms\n",
      "Model: ONNX, Input Length 163: 102.046 ms\n",
      "Model: ONNX, Input Length 71: 44.656 ms\n",
      "Model: ONNX, Input Length 76: 66.848 ms\n",
      "Model: ONNX, Input Length 24: 31.764 ms\n",
      "Model: ONNX, Input Length 137: 98.720 ms\n",
      "Model: ONNX, Input Length 63: 52.725 ms\n",
      "Model: ONNX, Input Length 102: 65.322 ms\n",
      "Model: ONNX, Input Length 52: 40.369 ms\n",
      "Model: ONNX, Input Length 76: 63.409 ms\n",
      "Model: ONNX, Input Length 89: 62.542 ms\n",
      "Model: ONNX, Input Length 75: 46.251 ms\n",
      "Model: ONNX, Input Length 57: 47.229 ms\n",
      "Model: ONNX, Input Length 95: 65.148 ms\n",
      "Model: ONNX, Input Length 79: 56.473 ms\n",
      "Model: ONNX, Input Length 162: 100.672 ms\n",
      "Model: ONNX, Input Length 49: 36.602 ms\n",
      "Model: ONNX, Input Length 39: 40.365 ms\n",
      "Model: ONNX, Input Length 117: 71.226 ms\n",
      "Model: ONNX, Input Length 188: 111.711 ms\n",
      "Model: ONNX, Input Length 131: 82.035 ms\n",
      "Model: ONNX, Input Length 59: 51.298 ms\n",
      "Model: ONNX, Input Length 55: 36.616 ms\n",
      "Model: ONNX, Input Length 43: 39.229 ms\n",
      "Model: ONNX, Input Length 91: 61.871 ms\n",
      "Model: ONNX, Input Length 35: 40.055 ms\n",
      "Model: ONNX, Input Length 78: 50.800 ms\n",
      "Model: ONNX, Input Length 90: 58.727 ms\n",
      "Model: ONNX, Input Length 65: 44.653 ms\n",
      "Model: ONNX, Input Length 22: 26.316 ms\n",
      "Model: ONNX, Input Length 156: 105.649 ms\n",
      "Model: ONNX, Input Length 84: 75.647 ms\n",
      "Model: ONNX, Input Length 93: 84.900 ms\n",
      "Model: ONNX, Input Length 71: 79.265 ms\n",
      "Model: ONNX, Input Length 90: 88.792 ms\n",
      "Model: ONNX, Input Length 106: 94.857 ms\n",
      "Model: ONNX, Input Length 126: 97.009 ms\n",
      "Model: ONNX, Input Length 386: 265.794 ms\n",
      "Model: ONNX, Input Length 155: 112.324 ms\n",
      "Model: ONNX, Input Length 37: 40.057 ms\n",
      "Model: ONNX, Input Length 65: 48.537 ms\n",
      "Model: ONNX, Input Length 71: 56.454 ms\n",
      "Model: ONNX, Input Length 320: 206.365 ms\n",
      "Model: ONNX, Input Length 130: 106.144 ms\n",
      "Model: ONNX, Input Length 43: 39.322 ms\n",
      "Model: ONNX, Input Length 94: 54.596 ms\n",
      "Model: ONNX, Input Length 98: 66.990 ms\n",
      "Model: ONNX, Input Length 66: 60.662 ms\n",
      "Model: ONNX, Input Length 122: 103.086 ms\n",
      "Model: ONNX, Input Length 49: 41.237 ms\n",
      "Model: ONNX, Input Length 119: 85.000 ms\n",
      "Model: ONNX, Input Length 117: 77.230 ms\n",
      "Model: ONNX, Input Length 79: 58.839 ms\n",
      "Model: ONNX, Input Length 92: 60.248 ms\n",
      "Model: ONNX, Input Length 60: 46.389 ms\n",
      "Model: ONNX, Input Length 246: 158.031 ms\n",
      "Model: ONNX, Input Length 42: 48.682 ms\n",
      "Model: ONNX, Input Length 41: 44.229 ms\n",
      "Model: ONNX, Input Length 88: 63.606 ms\n",
      "Model: ONNX, Input Length 46: 37.746 ms\n",
      "Model: ONNX, Input Length 86: 74.372 ms\n",
      "Model: ONNX, Input Length 97: 69.381 ms\n",
      "Model: ONNX, Input Length 136: 96.148 ms\n",
      "Model: ONNX, Input Length 133: 88.990 ms\n",
      "Model: ONNX, Input Length 142: 83.263 ms\n",
      "Model: ONNX, Input Length 86: 71.001 ms\n",
      "Model: ONNX, Input Length 110: 69.575 ms\n",
      "Model: ONNX, Input Length 216: 152.694 ms\n",
      "Model: ONNX, Input Length 54: 54.915 ms\n",
      "Model: ONNX, Input Length 64: 41.708 ms\n",
      "Model: ONNX, Input Length 40: 36.920 ms\n",
      "Model: ONNX, Input Length 76: 55.561 ms\n",
      "Model: ONNX, Input Length 67: 50.564 ms\n",
      "Model: ONNX, Input Length 80: 57.418 ms\n",
      "Model: ONNX, Input Length 67: 47.096 ms\n",
      "Model: ONNX, Input Length 79: 58.748 ms\n",
      "Model: ONNX, Input Length 43: 45.016 ms\n",
      "Model: ONNX, Input Length 194: 136.604 ms\n",
      "Model: ONNX, Input Length 31: 36.663 ms\n",
      "Model: ONNX, Input Length 107: 63.108 ms\n",
      "Model: ONNX, Input Length 55: 41.391 ms\n",
      "Model: ONNX, Input Length 58: 43.886 ms\n",
      "Model: ONNX, Input Length 67: 54.044 ms\n",
      "Model: ONNX, Input Length 158: 109.456 ms\n",
      "Model: ONNX, Input Length 39: 40.098 ms\n",
      "Model: ONNX, Input Length 45: 38.778 ms\n",
      "Model: ONNX, Input Length 100: 65.666 ms\n",
      "Model: ONNX, Input Length 125: 81.642 ms\n",
      "Model: ONNX, Input Length 75: 49.737 ms\n",
      "Model: ONNX, Input Length 61: 53.056 ms\n",
      "Model: ONNX, Input Length 159: 105.127 ms\n",
      "Model: ONNX, Input Length 97: 81.724 ms\n",
      "Model: ONNX-OPT, Input Length 217: 125.942 ms\n",
      "Model: ONNX-OPT, Input Length 191: 131.716 ms\n",
      "Model: ONNX-OPT, Input Length 54: 51.140 ms\n",
      "Model: ONNX-OPT, Input Length 85: 78.369 ms\n",
      "Model: ONNX-OPT, Input Length 47: 72.783 ms\n",
      "Model: ONNX-OPT, Input Length 55: 62.426 ms\n",
      "Model: ONNX-OPT, Input Length 94: 78.652 ms\n",
      "Model: ONNX-OPT, Input Length 110: 80.829 ms\n",
      "Model: ONNX-OPT, Input Length 14: 21.885 ms\n",
      "Model: ONNX-OPT, Input Length 85: 54.787 ms\n",
      "Model: ONNX-OPT, Input Length 138: 78.658 ms\n",
      "Model: ONNX-OPT, Input Length 85: 74.371 ms\n",
      "Model: ONNX-OPT, Input Length 97: 83.225 ms\n",
      "Model: ONNX-OPT, Input Length 90: 78.825 ms\n",
      "Model: ONNX-OPT, Input Length 116: 84.511 ms\n",
      "Model: ONNX-OPT, Input Length 55: 48.667 ms\n",
      "Model: ONNX-OPT, Input Length 113: 86.578 ms\n",
      "Model: ONNX-OPT, Input Length 49: 41.823 ms\n",
      "Model: ONNX-OPT, Input Length 116: 80.999 ms\n",
      "Model: ONNX-OPT, Input Length 46: 47.051 ms\n",
      "Model: ONNX-OPT, Input Length 125: 88.921 ms\n",
      "Model: ONNX-OPT, Input Length 160: 85.563 ms\n",
      "Model: ONNX-OPT, Input Length 43: 36.418 ms\n",
      "Model: ONNX-OPT, Input Length 53: 47.296 ms\n",
      "Model: ONNX-OPT, Input Length 111: 74.799 ms\n",
      "Model: ONNX-OPT, Input Length 80: 65.453 ms\n",
      "Model: ONNX-OPT, Input Length 90: 82.358 ms\n",
      "Model: ONNX-OPT, Input Length 190: 127.238 ms\n",
      "Model: ONNX-OPT, Input Length 50: 54.681 ms\n",
      "Model: ONNX-OPT, Input Length 92: 72.494 ms\n",
      "Model: ONNX-OPT, Input Length 96: 84.397 ms\n",
      "Model: ONNX-OPT, Input Length 45: 47.338 ms\n",
      "Model: ONNX-OPT, Input Length 71: 59.821 ms\n",
      "Model: ONNX-OPT, Input Length 79: 68.950 ms\n",
      "Model: ONNX-OPT, Input Length 89: 86.375 ms\n",
      "Model: ONNX-OPT, Input Length 110: 102.451 ms\n",
      "Model: ONNX-OPT, Input Length 82: 86.819 ms\n",
      "Model: ONNX-OPT, Input Length 142: 121.294 ms\n",
      "Model: ONNX-OPT, Input Length 140: 139.033 ms\n",
      "Model: ONNX-OPT, Input Length 31: 36.904 ms\n",
      "Model: ONNX-OPT, Input Length 189: 166.163 ms\n",
      "Model: ONNX-OPT, Input Length 123: 94.595 ms\n",
      "Model: ONNX-OPT, Input Length 100: 91.586 ms\n",
      "Model: ONNX-OPT, Input Length 36: 42.844 ms\n",
      "Model: ONNX-OPT, Input Length 68: 61.082 ms\n",
      "Model: ONNX-OPT, Input Length 72: 52.340 ms\n",
      "Model: ONNX-OPT, Input Length 84: 58.776 ms\n",
      "Model: ONNX-OPT, Input Length 126: 94.967 ms\n",
      "Model: ONNX-OPT, Input Length 147: 84.340 ms\n",
      "Model: ONNX-OPT, Input Length 78: 53.539 ms\n",
      "Model: ONNX-OPT, Input Length 35: 32.416 ms\n",
      "Model: ONNX-OPT, Input Length 96: 53.946 ms\n",
      "Model: ONNX-OPT, Input Length 147: 84.056 ms\n",
      "Model: ONNX-OPT, Input Length 138: 82.230 ms\n",
      "Model: ONNX-OPT, Input Length 48: 43.277 ms\n",
      "Model: ONNX-OPT, Input Length 591: 248.725 ms\n",
      "Model: ONNX-OPT, Input Length 86: 60.521 ms\n",
      "Model: ONNX-OPT, Input Length 39: 34.248 ms\n",
      "Model: ONNX-OPT, Input Length 64: 48.293 ms\n",
      "Model: ONNX-OPT, Input Length 52: 44.986 ms\n",
      "Model: ONNX-OPT, Input Length 104: 80.064 ms\n",
      "Model: ONNX-OPT, Input Length 30: 27.466 ms\n",
      "Model: ONNX-OPT, Input Length 107: 67.172 ms\n",
      "Model: ONNX-OPT, Input Length 89: 55.313 ms\n",
      "Model: ONNX-OPT, Input Length 32: 29.841 ms\n",
      "Model: ONNX-OPT, Input Length 47: 40.256 ms\n",
      "Model: ONNX-OPT, Input Length 75: 51.075 ms\n",
      "Model: ONNX-OPT, Input Length 24: 27.228 ms\n",
      "Model: ONNX-OPT, Input Length 100: 53.706 ms\n",
      "Model: ONNX-OPT, Input Length 110: 83.302 ms\n",
      "Model: ONNX-OPT, Input Length 59: 42.086 ms\n",
      "Model: ONNX-OPT, Input Length 130: 72.824 ms\n",
      "Model: ONNX-OPT, Input Length 106: 69.823 ms\n",
      "Model: ONNX-OPT, Input Length 39: 33.940 ms\n",
      "Model: ONNX-OPT, Input Length 66: 43.454 ms\n",
      "Model: ONNX-OPT, Input Length 105: 63.192 ms\n",
      "Model: ONNX-OPT, Input Length 103: 54.292 ms\n",
      "Model: ONNX-OPT, Input Length 33: 38.075 ms\n",
      "Model: ONNX-OPT, Input Length 122: 82.316 ms\n",
      "Model: ONNX-OPT, Input Length 60: 43.843 ms\n",
      "Model: ONNX-OPT, Input Length 40: 48.168 ms\n",
      "Model: ONNX-OPT, Input Length 63: 65.613 ms\n",
      "Model: ONNX-OPT, Input Length 158: 118.617 ms\n",
      "Model: ONNX-OPT, Input Length 123: 92.006 ms\n",
      "Model: ONNX-OPT, Input Length 110: 79.918 ms\n",
      "Model: ONNX-OPT, Input Length 145: 102.887 ms\n",
      "Model: ONNX-OPT, Input Length 50: 41.945 ms\n",
      "Model: ONNX-OPT, Input Length 46: 44.253 ms\n",
      "Model: ONNX-OPT, Input Length 32: 28.745 ms\n",
      "Model: ONNX-OPT, Input Length 74: 58.038 ms\n",
      "Model: ONNX-OPT, Input Length 68: 59.440 ms\n",
      "Model: ONNX-OPT, Input Length 89: 62.265 ms\n",
      "Model: ONNX-OPT, Input Length 55: 49.148 ms\n",
      "Model: ONNX-OPT, Input Length 46: 43.781 ms\n",
      "Model: ONNX-OPT, Input Length 20: 22.906 ms\n",
      "Model: ONNX-OPT, Input Length 37: 37.112 ms\n",
      "Model: ONNX-OPT, Input Length 85: 54.623 ms\n",
      "Model: ONNX-OPT, Input Length 122: 80.380 ms\n",
      "Model: ONNX-OPT, Input Length 80: 52.007 ms\n",
      "Model: ONNX-OPT, Input Length 176: 132.072 ms\n",
      "Model: ONNX-OPT, Input Length 141: 86.411 ms\n",
      "Model: ONNX-OPT, Input Length 83: 54.567 ms\n",
      "Model: ONNX-OPT, Input Length 231: 156.575 ms\n",
      "Model: ONNX-OPT, Input Length 125: 86.904 ms\n",
      "Model: ONNX-OPT, Input Length 202: 120.292 ms\n",
      "Model: ONNX-OPT, Input Length 44: 52.202 ms\n",
      "Model: ONNX-OPT, Input Length 15: 28.431 ms\n",
      "Model: ONNX-OPT, Input Length 90: 90.009 ms\n",
      "Model: ONNX-OPT, Input Length 62: 65.875 ms\n",
      "Model: ONNX-OPT, Input Length 114: 107.534 ms\n",
      "Model: ONNX-OPT, Input Length 153: 133.159 ms\n",
      "Model: ONNX-OPT, Input Length 112: 112.116 ms\n",
      "Model: ONNX-OPT, Input Length 57: 66.562 ms\n",
      "Model: ONNX-OPT, Input Length 106: 92.050 ms\n",
      "Model: ONNX-OPT, Input Length 92: 80.010 ms\n",
      "Model: ONNX-OPT, Input Length 86: 80.982 ms\n",
      "Model: ONNX-OPT, Input Length 45: 48.875 ms\n",
      "Model: ONNX-OPT, Input Length 110: 104.475 ms\n",
      "Model: ONNX-OPT, Input Length 73: 74.649 ms\n",
      "Model: ONNX-OPT, Input Length 121: 92.753 ms\n",
      "Model: ONNX-OPT, Input Length 159: 119.604 ms\n",
      "Model: ONNX-OPT, Input Length 51: 71.115 ms\n",
      "Model: ONNX-OPT, Input Length 94: 74.544 ms\n",
      "Model: ONNX-OPT, Input Length 70: 57.585 ms\n",
      "Model: ONNX-OPT, Input Length 92: 54.959 ms\n",
      "Model: ONNX-OPT, Input Length 55: 43.618 ms\n",
      "Model: ONNX-OPT, Input Length 31: 27.880 ms\n",
      "Model: ONNX-OPT, Input Length 39: 39.075 ms\n",
      "Model: ONNX-OPT, Input Length 104: 77.811 ms\n",
      "Model: ONNX-OPT, Input Length 249: 207.281 ms\n",
      "Model: ONNX-OPT, Input Length 80: 81.183 ms\n",
      "Model: ONNX-OPT, Input Length 142: 114.962 ms\n",
      "Model: ONNX-OPT, Input Length 203: 117.209 ms\n",
      "Model: ONNX-OPT, Input Length 97: 67.865 ms\n",
      "Model: ONNX-OPT, Input Length 147: 110.050 ms\n",
      "Model: ONNX-OPT, Input Length 42: 46.213 ms\n",
      "Model: ONNX-OPT, Input Length 154: 113.427 ms\n",
      "Model: ONNX-OPT, Input Length 192: 110.352 ms\n",
      "Model: ONNX-OPT, Input Length 78: 73.166 ms\n",
      "Model: ONNX-OPT, Input Length 274: 222.022 ms\n",
      "Model: ONNX-OPT, Input Length 72: 64.668 ms\n",
      "Model: ONNX-OPT, Input Length 65: 70.609 ms\n",
      "Model: ONNX-OPT, Input Length 57: 54.509 ms\n",
      "Model: ONNX-OPT, Input Length 96: 78.344 ms\n",
      "Model: ONNX-OPT, Input Length 66: 61.210 ms\n",
      "Model: ONNX-OPT, Input Length 37: 35.940 ms\n",
      "Model: ONNX-OPT, Input Length 40: 41.541 ms\n",
      "Model: ONNX-OPT, Input Length 124: 101.160 ms\n",
      "Model: ONNX-OPT, Input Length 19: 31.490 ms\n",
      "Model: ONNX-OPT, Input Length 203: 150.761 ms\n",
      "Model: ONNX-OPT, Input Length 56: 53.923 ms\n",
      "Model: ONNX-OPT, Input Length 97: 69.637 ms\n",
      "Model: ONNX-OPT, Input Length 82: 79.195 ms\n",
      "Model: ONNX-OPT, Input Length 79: 69.568 ms\n",
      "Model: ONNX-OPT, Input Length 74: 67.840 ms\n",
      "Model: ONNX-OPT, Input Length 143: 95.987 ms\n",
      "Model: ONNX-OPT, Input Length 52: 62.038 ms\n",
      "Model: ONNX-OPT, Input Length 157: 114.236 ms\n",
      "Model: ONNX-OPT, Input Length 113: 90.371 ms\n",
      "Model: ONNX-OPT, Input Length 163: 119.504 ms\n",
      "Model: ONNX-OPT, Input Length 71: 62.564 ms\n",
      "Model: ONNX-OPT, Input Length 76: 69.401 ms\n",
      "Model: ONNX-OPT, Input Length 24: 37.440 ms\n",
      "Model: ONNX-OPT, Input Length 137: 117.523 ms\n",
      "Model: ONNX-OPT, Input Length 63: 68.146 ms\n",
      "Model: ONNX-OPT, Input Length 102: 79.508 ms\n",
      "Model: ONNX-OPT, Input Length 52: 50.593 ms\n",
      "Model: ONNX-OPT, Input Length 76: 63.716 ms\n",
      "Model: ONNX-OPT, Input Length 89: 79.814 ms\n",
      "Model: ONNX-OPT, Input Length 75: 58.573 ms\n",
      "Model: ONNX-OPT, Input Length 57: 42.335 ms\n",
      "Model: ONNX-OPT, Input Length 95: 68.151 ms\n",
      "Model: ONNX-OPT, Input Length 79: 55.000 ms\n",
      "Model: ONNX-OPT, Input Length 162: 117.040 ms\n",
      "Model: ONNX-OPT, Input Length 49: 36.489 ms\n",
      "Model: ONNX-OPT, Input Length 39: 35.484 ms\n",
      "Model: ONNX-OPT, Input Length 117: 71.828 ms\n",
      "Model: ONNX-OPT, Input Length 188: 143.093 ms\n",
      "Model: ONNX-OPT, Input Length 131: 94.933 ms\n",
      "Model: ONNX-OPT, Input Length 59: 52.371 ms\n",
      "Model: ONNX-OPT, Input Length 55: 46.707 ms\n",
      "Model: ONNX-OPT, Input Length 43: 46.932 ms\n",
      "Model: ONNX-OPT, Input Length 91: 68.789 ms\n",
      "Model: ONNX-OPT, Input Length 35: 34.595 ms\n",
      "Model: ONNX-OPT, Input Length 78: 49.213 ms\n",
      "Model: ONNX-OPT, Input Length 90: 59.029 ms\n",
      "Model: ONNX-OPT, Input Length 65: 45.473 ms\n",
      "Model: ONNX-OPT, Input Length 22: 28.085 ms\n",
      "Model: ONNX-OPT, Input Length 156: 107.237 ms\n",
      "Model: ONNX-OPT, Input Length 84: 59.323 ms\n",
      "Model: ONNX-OPT, Input Length 93: 60.721 ms\n",
      "Model: ONNX-OPT, Input Length 71: 56.473 ms\n",
      "Model: ONNX-OPT, Input Length 90: 80.659 ms\n",
      "Model: ONNX-OPT, Input Length 106: 83.949 ms\n",
      "Model: ONNX-OPT, Input Length 126: 78.463 ms\n",
      "Model: ONNX-OPT, Input Length 386: 277.370 ms\n",
      "Model: ONNX-OPT, Input Length 155: 120.919 ms\n",
      "Model: ONNX-OPT, Input Length 37: 40.651 ms\n",
      "Model: ONNX-OPT, Input Length 65: 52.654 ms\n",
      "Model: ONNX-OPT, Input Length 71: 65.719 ms\n",
      "Model: ONNX-OPT, Input Length 320: 247.352 ms\n",
      "Model: ONNX-OPT, Input Length 130: 105.748 ms\n",
      "Model: ONNX-OPT, Input Length 43: 42.199 ms\n",
      "Model: ONNX-OPT, Input Length 94: 67.607 ms\n",
      "Model: ONNX-OPT, Input Length 98: 71.715 ms\n",
      "Model: ONNX-OPT, Input Length 66: 55.273 ms\n",
      "Model: ONNX-OPT, Input Length 122: 92.735 ms\n",
      "Model: ONNX-OPT, Input Length 49: 48.348 ms\n",
      "Model: ONNX-OPT, Input Length 119: 103.529 ms\n",
      "Model: ONNX-OPT, Input Length 117: 102.395 ms\n",
      "Model: ONNX-OPT, Input Length 79: 77.708 ms\n",
      "Model: ONNX-OPT, Input Length 92: 77.740 ms\n",
      "Model: ONNX-OPT, Input Length 60: 64.655 ms\n",
      "Model: ONNX-OPT, Input Length 246: 174.239 ms\n",
      "Model: ONNX-OPT, Input Length 42: 46.403 ms\n",
      "Model: ONNX-OPT, Input Length 41: 37.689 ms\n",
      "Model: ONNX-OPT, Input Length 88: 59.810 ms\n",
      "Model: ONNX-OPT, Input Length 46: 36.848 ms\n",
      "Model: ONNX-OPT, Input Length 86: 58.146 ms\n",
      "Model: ONNX-OPT, Input Length 97: 56.755 ms\n",
      "Model: ONNX-OPT, Input Length 136: 86.215 ms\n",
      "Model: ONNX-OPT, Input Length 133: 83.170 ms\n",
      "Model: ONNX-OPT, Input Length 142: 74.540 ms\n",
      "Model: ONNX-OPT, Input Length 86: 64.732 ms\n",
      "Model: ONNX-OPT, Input Length 110: 71.304 ms\n",
      "Model: ONNX-OPT, Input Length 216: 167.254 ms\n",
      "Model: ONNX-OPT, Input Length 54: 56.450 ms\n",
      "Model: ONNX-OPT, Input Length 64: 46.197 ms\n",
      "Model: ONNX-OPT, Input Length 40: 35.483 ms\n",
      "Model: ONNX-OPT, Input Length 76: 51.168 ms\n",
      "Model: ONNX-OPT, Input Length 67: 44.393 ms\n",
      "Model: ONNX-OPT, Input Length 80: 56.110 ms\n",
      "Model: ONNX-OPT, Input Length 67: 44.619 ms\n",
      "Model: ONNX-OPT, Input Length 79: 48.770 ms\n",
      "Model: ONNX-OPT, Input Length 43: 32.651 ms\n",
      "Model: ONNX-OPT, Input Length 194: 139.929 ms\n",
      "Model: ONNX-OPT, Input Length 31: 34.726 ms\n",
      "Model: ONNX-OPT, Input Length 107: 66.496 ms\n",
      "Model: ONNX-OPT, Input Length 55: 39.496 ms\n",
      "Model: ONNX-OPT, Input Length 58: 42.933 ms\n",
      "Model: ONNX-OPT, Input Length 67: 62.018 ms\n",
      "Model: ONNX-OPT, Input Length 158: 135.423 ms\n",
      "Model: ONNX-OPT, Input Length 39: 39.123 ms\n",
      "Model: ONNX-OPT, Input Length 45: 38.336 ms\n",
      "Model: ONNX-OPT, Input Length 100: 59.222 ms\n",
      "Model: ONNX-OPT, Input Length 125: 82.233 ms\n",
      "Model: ONNX-OPT, Input Length 75: 51.804 ms\n",
      "Model: ONNX-OPT, Input Length 61: 56.600 ms\n",
      "Model: ONNX-OPT, Input Length 159: 98.852 ms\n",
      "Model: ONNX-OPT, Input Length 97: 68.159 ms\n",
      "Model: ONNX Quantized, Input Length 217: 105.234 ms\n",
      "Model: ONNX Quantized, Input Length 191: 92.444 ms\n",
      "Model: ONNX Quantized, Input Length 54: 30.955 ms\n",
      "Model: ONNX Quantized, Input Length 85: 47.681 ms\n",
      "Model: ONNX Quantized, Input Length 47: 42.771 ms\n",
      "Model: ONNX Quantized, Input Length 55: 36.606 ms\n",
      "Model: ONNX Quantized, Input Length 94: 48.522 ms\n",
      "Model: ONNX Quantized, Input Length 110: 52.731 ms\n",
      "Model: ONNX Quantized, Input Length 14: 14.307 ms\n",
      "Model: ONNX Quantized, Input Length 85: 44.991 ms\n",
      "Model: ONNX Quantized, Input Length 138: 58.309 ms\n",
      "Model: ONNX Quantized, Input Length 85: 44.921 ms\n",
      "Model: ONNX Quantized, Input Length 97: 47.745 ms\n",
      "Model: ONNX Quantized, Input Length 90: 49.420 ms\n",
      "Model: ONNX Quantized, Input Length 116: 52.981 ms\n",
      "Model: ONNX Quantized, Input Length 55: 31.758 ms\n",
      "Model: ONNX Quantized, Input Length 113: 65.410 ms\n",
      "Model: ONNX Quantized, Input Length 49: 33.999 ms\n",
      "Model: ONNX Quantized, Input Length 116: 69.504 ms\n",
      "Model: ONNX Quantized, Input Length 46: 43.405 ms\n",
      "Model: ONNX Quantized, Input Length 125: 79.320 ms\n",
      "Model: ONNX Quantized, Input Length 160: 88.837 ms\n",
      "Model: ONNX Quantized, Input Length 43: 35.787 ms\n",
      "Model: ONNX Quantized, Input Length 53: 34.226 ms\n",
      "Model: ONNX Quantized, Input Length 111: 53.207 ms\n",
      "Model: ONNX Quantized, Input Length 80: 47.530 ms\n",
      "Model: ONNX Quantized, Input Length 90: 53.740 ms\n",
      "Model: ONNX Quantized, Input Length 190: 89.645 ms\n",
      "Model: ONNX Quantized, Input Length 50: 35.939 ms\n",
      "Model: ONNX Quantized, Input Length 92: 41.253 ms\n",
      "Model: ONNX Quantized, Input Length 96: 48.372 ms\n",
      "Model: ONNX Quantized, Input Length 45: 27.661 ms\n",
      "Model: ONNX Quantized, Input Length 71: 34.132 ms\n",
      "Model: ONNX Quantized, Input Length 79: 40.871 ms\n",
      "Model: ONNX Quantized, Input Length 89: 41.000 ms\n",
      "Model: ONNX Quantized, Input Length 110: 58.031 ms\n",
      "Model: ONNX Quantized, Input Length 82: 48.547 ms\n",
      "Model: ONNX Quantized, Input Length 142: 75.567 ms\n",
      "Model: ONNX Quantized, Input Length 140: 100.273 ms\n",
      "Model: ONNX Quantized, Input Length 31: 26.352 ms\n",
      "Model: ONNX Quantized, Input Length 189: 109.836 ms\n",
      "Model: ONNX Quantized, Input Length 123: 54.744 ms\n",
      "Model: ONNX Quantized, Input Length 100: 58.292 ms\n",
      "Model: ONNX Quantized, Input Length 36: 24.618 ms\n",
      "Model: ONNX Quantized, Input Length 68: 38.973 ms\n",
      "Model: ONNX Quantized, Input Length 72: 40.994 ms\n",
      "Model: ONNX Quantized, Input Length 84: 47.499 ms\n",
      "Model: ONNX Quantized, Input Length 126: 57.512 ms\n",
      "Model: ONNX Quantized, Input Length 147: 59.515 ms\n",
      "Model: ONNX Quantized, Input Length 78: 37.201 ms\n",
      "Model: ONNX Quantized, Input Length 35: 22.870 ms\n",
      "Model: ONNX Quantized, Input Length 96: 38.479 ms\n",
      "Model: ONNX Quantized, Input Length 147: 74.313 ms\n",
      "Model: ONNX Quantized, Input Length 138: 67.759 ms\n",
      "Model: ONNX Quantized, Input Length 48: 34.768 ms\n",
      "Model: ONNX Quantized, Input Length 591: 232.621 ms\n",
      "Model: ONNX Quantized, Input Length 86: 49.418 ms\n",
      "Model: ONNX Quantized, Input Length 39: 28.174 ms\n",
      "Model: ONNX Quantized, Input Length 64: 38.337 ms\n",
      "Model: ONNX Quantized, Input Length 52: 40.974 ms\n",
      "Model: ONNX Quantized, Input Length 104: 74.529 ms\n",
      "Model: ONNX Quantized, Input Length 30: 24.315 ms\n",
      "Model: ONNX Quantized, Input Length 107: 55.299 ms\n",
      "Model: ONNX Quantized, Input Length 89: 46.505 ms\n",
      "Model: ONNX Quantized, Input Length 32: 27.494 ms\n",
      "Model: ONNX Quantized, Input Length 47: 35.041 ms\n",
      "Model: ONNX Quantized, Input Length 75: 44.063 ms\n",
      "Model: ONNX Quantized, Input Length 24: 21.328 ms\n",
      "Model: ONNX Quantized, Input Length 100: 43.906 ms\n",
      "Model: ONNX Quantized, Input Length 110: 62.486 ms\n",
      "Model: ONNX Quantized, Input Length 59: 32.099 ms\n",
      "Model: ONNX Quantized, Input Length 130: 47.928 ms\n",
      "Model: ONNX Quantized, Input Length 106: 54.366 ms\n",
      "Model: ONNX Quantized, Input Length 39: 26.696 ms\n",
      "Model: ONNX Quantized, Input Length 66: 37.719 ms\n",
      "Model: ONNX Quantized, Input Length 105: 52.507 ms\n",
      "Model: ONNX Quantized, Input Length 103: 41.239 ms\n",
      "Model: ONNX Quantized, Input Length 33: 26.467 ms\n",
      "Model: ONNX Quantized, Input Length 122: 67.275 ms\n",
      "Model: ONNX Quantized, Input Length 60: 32.753 ms\n",
      "Model: ONNX Quantized, Input Length 40: 27.620 ms\n",
      "Model: ONNX Quantized, Input Length 63: 42.008 ms\n",
      "Model: ONNX Quantized, Input Length 158: 71.185 ms\n",
      "Model: ONNX Quantized, Input Length 123: 57.090 ms\n",
      "Model: ONNX Quantized, Input Length 110: 49.545 ms\n",
      "Model: ONNX Quantized, Input Length 145: 69.715 ms\n",
      "Model: ONNX Quantized, Input Length 50: 28.699 ms\n",
      "Model: ONNX Quantized, Input Length 46: 32.710 ms\n",
      "Model: ONNX Quantized, Input Length 32: 19.002 ms\n",
      "Model: ONNX Quantized, Input Length 74: 41.326 ms\n",
      "Model: ONNX Quantized, Input Length 68: 43.808 ms\n",
      "Model: ONNX Quantized, Input Length 89: 40.076 ms\n",
      "Model: ONNX Quantized, Input Length 55: 29.271 ms\n",
      "Model: ONNX Quantized, Input Length 46: 28.796 ms\n",
      "Model: ONNX Quantized, Input Length 20: 16.551 ms\n",
      "Model: ONNX Quantized, Input Length 37: 23.840 ms\n",
      "Model: ONNX Quantized, Input Length 85: 38.911 ms\n",
      "Model: ONNX Quantized, Input Length 122: 55.190 ms\n",
      "Model: ONNX Quantized, Input Length 80: 38.426 ms\n",
      "Model: ONNX Quantized, Input Length 176: 81.018 ms\n",
      "Model: ONNX Quantized, Input Length 141: 60.369 ms\n",
      "Model: ONNX Quantized, Input Length 83: 51.678 ms\n",
      "Model: ONNX Quantized, Input Length 231: 116.046 ms\n",
      "Model: ONNX Quantized, Input Length 125: 69.764 ms\n",
      "Model: ONNX Quantized, Input Length 202: 84.738 ms\n",
      "Model: ONNX Quantized, Input Length 44: 24.195 ms\n",
      "Model: ONNX Quantized, Input Length 15: 18.286 ms\n",
      "Model: ONNX Quantized, Input Length 90: 56.308 ms\n",
      "Model: ONNX Quantized, Input Length 62: 41.481 ms\n",
      "Model: ONNX Quantized, Input Length 114: 68.872 ms\n",
      "Model: ONNX Quantized, Input Length 153: 86.565 ms\n",
      "Model: ONNX Quantized, Input Length 112: 71.975 ms\n",
      "Model: ONNX Quantized, Input Length 57: 45.234 ms\n",
      "Model: ONNX Quantized, Input Length 106: 61.113 ms\n",
      "Model: ONNX Quantized, Input Length 92: 57.772 ms\n",
      "Model: ONNX Quantized, Input Length 86: 59.513 ms\n",
      "Model: ONNX Quantized, Input Length 45: 35.649 ms\n",
      "Model: ONNX Quantized, Input Length 110: 50.543 ms\n",
      "Model: ONNX Quantized, Input Length 73: 40.256 ms\n",
      "Model: ONNX Quantized, Input Length 121: 65.467 ms\n",
      "Model: ONNX Quantized, Input Length 159: 73.510 ms\n",
      "Model: ONNX Quantized, Input Length 51: 40.642 ms\n",
      "Model: ONNX Quantized, Input Length 94: 38.706 ms\n",
      "Model: ONNX Quantized, Input Length 70: 33.945 ms\n",
      "Model: ONNX Quantized, Input Length 92: 43.655 ms\n",
      "Model: ONNX Quantized, Input Length 55: 33.682 ms\n",
      "Model: ONNX Quantized, Input Length 31: 18.568 ms\n",
      "Model: ONNX Quantized, Input Length 39: 30.871 ms\n",
      "Model: ONNX Quantized, Input Length 104: 58.903 ms\n",
      "Model: ONNX Quantized, Input Length 249: 162.110 ms\n",
      "Model: ONNX Quantized, Input Length 80: 56.862 ms\n",
      "Model: ONNX Quantized, Input Length 142: 86.400 ms\n",
      "Model: ONNX Quantized, Input Length 203: 99.379 ms\n",
      "Model: ONNX Quantized, Input Length 97: 55.435 ms\n",
      "Model: ONNX Quantized, Input Length 147: 71.406 ms\n",
      "Model: ONNX Quantized, Input Length 42: 24.395 ms\n",
      "Model: ONNX Quantized, Input Length 154: 72.836 ms\n",
      "Model: ONNX Quantized, Input Length 192: 74.619 ms\n",
      "Model: ONNX Quantized, Input Length 78: 38.947 ms\n",
      "Model: ONNX Quantized, Input Length 274: 129.930 ms\n",
      "Model: ONNX Quantized, Input Length 72: 37.244 ms\n",
      "Model: ONNX Quantized, Input Length 65: 38.348 ms\n",
      "Model: ONNX Quantized, Input Length 57: 32.193 ms\n",
      "Model: ONNX Quantized, Input Length 96: 45.478 ms\n",
      "Model: ONNX Quantized, Input Length 66: 36.431 ms\n",
      "Model: ONNX Quantized, Input Length 37: 27.417 ms\n",
      "Model: ONNX Quantized, Input Length 40: 25.850 ms\n",
      "Model: ONNX Quantized, Input Length 124: 55.181 ms\n",
      "Model: ONNX Quantized, Input Length 19: 17.433 ms\n",
      "Model: ONNX Quantized, Input Length 203: 91.161 ms\n",
      "Model: ONNX Quantized, Input Length 56: 30.728 ms\n",
      "Model: ONNX Quantized, Input Length 97: 43.997 ms\n",
      "Model: ONNX Quantized, Input Length 82: 49.043 ms\n",
      "Model: ONNX Quantized, Input Length 79: 49.524 ms\n",
      "Model: ONNX Quantized, Input Length 74: 42.505 ms\n",
      "Model: ONNX Quantized, Input Length 143: 58.907 ms\n",
      "Model: ONNX Quantized, Input Length 52: 31.453 ms\n",
      "Model: ONNX Quantized, Input Length 157: 62.368 ms\n",
      "Model: ONNX Quantized, Input Length 113: 50.866 ms\n",
      "Model: ONNX Quantized, Input Length 163: 70.841 ms\n",
      "Model: ONNX Quantized, Input Length 71: 36.847 ms\n",
      "Model: ONNX Quantized, Input Length 76: 39.251 ms\n",
      "Model: ONNX Quantized, Input Length 24: 19.026 ms\n",
      "Model: ONNX Quantized, Input Length 137: 70.731 ms\n",
      "Model: ONNX Quantized, Input Length 63: 40.265 ms\n",
      "Model: ONNX Quantized, Input Length 102: 42.793 ms\n",
      "Model: ONNX Quantized, Input Length 52: 29.876 ms\n",
      "Model: ONNX Quantized, Input Length 76: 36.817 ms\n",
      "Model: ONNX Quantized, Input Length 89: 45.602 ms\n",
      "Model: ONNX Quantized, Input Length 75: 39.997 ms\n",
      "Model: ONNX Quantized, Input Length 57: 31.517 ms\n",
      "Model: ONNX Quantized, Input Length 95: 43.123 ms\n",
      "Model: ONNX Quantized, Input Length 79: 36.547 ms\n",
      "Model: ONNX Quantized, Input Length 162: 81.794 ms\n",
      "Model: ONNX Quantized, Input Length 49: 28.176 ms\n",
      "Model: ONNX Quantized, Input Length 39: 23.195 ms\n",
      "Model: ONNX Quantized, Input Length 117: 51.678 ms\n",
      "Model: ONNX Quantized, Input Length 188: 76.083 ms\n",
      "Model: ONNX Quantized, Input Length 131: 54.621 ms\n",
      "Model: ONNX Quantized, Input Length 59: 35.118 ms\n",
      "Model: ONNX Quantized, Input Length 55: 28.208 ms\n",
      "Model: ONNX Quantized, Input Length 43: 26.913 ms\n",
      "Model: ONNX Quantized, Input Length 91: 39.925 ms\n",
      "Model: ONNX Quantized, Input Length 35: 24.692 ms\n",
      "Model: ONNX Quantized, Input Length 78: 35.761 ms\n",
      "Model: ONNX Quantized, Input Length 90: 43.693 ms\n",
      "Model: ONNX Quantized, Input Length 65: 32.825 ms\n",
      "Model: ONNX Quantized, Input Length 22: 17.700 ms\n",
      "Model: ONNX Quantized, Input Length 156: 65.757 ms\n",
      "Model: ONNX Quantized, Input Length 84: 38.305 ms\n",
      "Model: ONNX Quantized, Input Length 93: 42.048 ms\n",
      "Model: ONNX Quantized, Input Length 71: 41.589 ms\n",
      "Model: ONNX Quantized, Input Length 90: 47.670 ms\n",
      "Model: ONNX Quantized, Input Length 106: 56.519 ms\n",
      "Model: ONNX Quantized, Input Length 126: 69.586 ms\n",
      "Model: ONNX Quantized, Input Length 386: 220.254 ms\n",
      "Model: ONNX Quantized, Input Length 155: 83.388 ms\n",
      "Model: ONNX Quantized, Input Length 37: 28.841 ms\n",
      "Model: ONNX Quantized, Input Length 65: 34.805 ms\n",
      "Model: ONNX Quantized, Input Length 71: 35.754 ms\n",
      "Model: ONNX Quantized, Input Length 320: 168.437 ms\n",
      "Model: ONNX Quantized, Input Length 130: 66.965 ms\n",
      "Model: ONNX Quantized, Input Length 43: 30.785 ms\n",
      "Model: ONNX Quantized, Input Length 94: 48.077 ms\n",
      "Model: ONNX Quantized, Input Length 98: 47.206 ms\n",
      "Model: ONNX Quantized, Input Length 66: 37.661 ms\n",
      "Model: ONNX Quantized, Input Length 122: 56.883 ms\n",
      "Model: ONNX Quantized, Input Length 49: 29.941 ms\n",
      "Model: ONNX Quantized, Input Length 119: 55.259 ms\n",
      "Model: ONNX Quantized, Input Length 117: 52.659 ms\n",
      "Model: ONNX Quantized, Input Length 79: 47.080 ms\n",
      "Model: ONNX Quantized, Input Length 92: 49.584 ms\n",
      "Model: ONNX Quantized, Input Length 60: 39.136 ms\n",
      "Model: ONNX Quantized, Input Length 246: 123.083 ms\n",
      "Model: ONNX Quantized, Input Length 42: 34.504 ms\n",
      "Model: ONNX Quantized, Input Length 41: 38.016 ms\n",
      "Model: ONNX Quantized, Input Length 88: 50.084 ms\n",
      "Model: ONNX Quantized, Input Length 46: 30.681 ms\n",
      "Model: ONNX Quantized, Input Length 86: 48.064 ms\n",
      "Model: ONNX Quantized, Input Length 97: 46.705 ms\n",
      "Model: ONNX Quantized, Input Length 136: 76.825 ms\n",
      "Model: ONNX Quantized, Input Length 133: 67.934 ms\n",
      "Model: ONNX Quantized, Input Length 142: 74.753 ms\n",
      "Model: ONNX Quantized, Input Length 86: 49.498 ms\n",
      "Model: ONNX Quantized, Input Length 110: 52.217 ms\n",
      "Model: ONNX Quantized, Input Length 216: 116.227 ms\n",
      "Model: ONNX Quantized, Input Length 54: 48.064 ms\n",
      "Model: ONNX Quantized, Input Length 64: 41.498 ms\n",
      "Model: ONNX Quantized, Input Length 40: 27.645 ms\n",
      "Model: ONNX Quantized, Input Length 76: 36.780 ms\n",
      "Model: ONNX Quantized, Input Length 67: 34.743 ms\n",
      "Model: ONNX Quantized, Input Length 80: 40.220 ms\n",
      "Model: ONNX Quantized, Input Length 67: 33.885 ms\n",
      "Model: ONNX Quantized, Input Length 79: 37.129 ms\n",
      "Model: ONNX Quantized, Input Length 43: 25.190 ms\n",
      "Model: ONNX Quantized, Input Length 194: 101.247 ms\n",
      "Model: ONNX Quantized, Input Length 31: 26.031 ms\n",
      "Model: ONNX Quantized, Input Length 107: 53.066 ms\n",
      "Model: ONNX Quantized, Input Length 55: 34.670 ms\n",
      "Model: ONNX Quantized, Input Length 58: 41.044 ms\n",
      "Model: ONNX Quantized, Input Length 67: 45.984 ms\n",
      "Model: ONNX Quantized, Input Length 158: 118.916 ms\n",
      "Model: ONNX Quantized, Input Length 39: 27.631 ms\n",
      "Model: ONNX Quantized, Input Length 45: 28.213 ms\n",
      "Model: ONNX Quantized, Input Length 100: 56.675 ms\n",
      "Model: ONNX Quantized, Input Length 125: 81.333 ms\n",
      "Model: ONNX Quantized, Input Length 75: 47.656 ms\n",
      "Model: ONNX Quantized, Input Length 61: 51.952 ms\n",
      "Model: ONNX Quantized, Input Length 159: 104.724 ms\n",
      "Model: ONNX Quantized, Input Length 97: 62.863 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 217: 139.667 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 191: 122.814 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 54: 38.533 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 59.770 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 47: 54.950 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 49.228 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 64.225 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 72.174 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 19.599 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 55.720 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 138: 77.101 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 58.009 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 64.489 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 63.774 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 116: 71.666 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 41.024 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 113: 66.545 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 32.033 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 116: 62.183 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 40.614 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 70.471 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 160: 78.965 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 34.359 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 53: 36.391 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 111: 62.439 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 40.708 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 60.855 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 190: 97.079 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 50: 42.067 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 52.381 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 61.921 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 39.773 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 48.217 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 52.747 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 49.616 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 61.644 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 82: 58.143 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 73.416 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 140: 85.623 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 26.602 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 189: 119.861 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 123: 68.825 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 56.514 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 36: 25.128 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 68: 36.544 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 72: 36.833 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 84: 46.930 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 126: 61.154 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 73.466 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 46.458 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 35: 27.374 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 47.877 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 67.266 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 138: 73.424 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 48: 35.175 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 591: 204.173 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 57.471 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 30.311 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 64: 36.272 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 34.708 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 104: 61.709 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 30: 20.632 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 49.187 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 41.139 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 32: 23.443 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 47: 30.429 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 44.842 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 24: 19.501 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 40.828 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 59.782 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 59: 33.323 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 130: 52.923 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 51.674 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 24.397 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 31.858 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 105: 47.950 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 103: 42.836 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 33: 26.542 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 61.580 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 60: 38.479 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 34.379 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 63: 47.269 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 158: 79.080 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 123: 61.473 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 47.939 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 145: 67.364 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 50: 29.845 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 32.862 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 32: 20.554 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 74: 49.510 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 68: 45.662 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 41.598 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 29.021 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 28.541 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 17.538 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 27.909 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 45.085 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 72.985 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 48.563 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 176: 101.304 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 141: 76.559 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 83: 39.842 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 231: 102.994 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 52.853 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 202: 99.427 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 26.874 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 15: 16.032 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 49.010 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 38.402 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 114: 54.588 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 153: 73.120 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 63.195 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 40.757 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 49.707 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 50.066 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 53.061 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 37.516 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 61.631 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 73: 44.951 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 121: 65.636 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 159: 82.320 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 51: 49.141 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 48.380 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 70: 42.500 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 47.645 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 41.216 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 23.932 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 26.683 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 104: 48.685 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 249: 157.644 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 60.097 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 84.801 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 203: 95.066 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 61.709 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 76.271 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 42: 25.554 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 154: 74.733 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 192: 80.349 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 38.664 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 274: 136.581 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 72: 49.661 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 50.263 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 33.483 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 46.551 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 35.371 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 27.761 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 29.443 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 124: 61.393 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 20.227 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 203: 112.695 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 56: 37.123 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 54.391 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 82: 52.705 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 48.328 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 74: 48.300 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 143: 65.793 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 36.573 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 157: 87.353 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 113: 62.355 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 163: 126.375 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 49.335 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 54.273 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 24: 25.929 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 137: 90.251 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 63: 53.493 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 102: 59.206 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 37.800 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 48.148 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 61.821 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 46.912 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 39.267 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 95: 58.716 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 40.238 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 162: 81.731 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 27.722 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 22.914 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 64.244 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 188: 84.815 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 131: 53.456 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 59: 35.376 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 31.091 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 28.724 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 91: 43.116 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 35: 30.469 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 36.499 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 41.799 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 32.324 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 18.822 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 156: 71.429 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 84: 40.637 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 93: 42.476 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 40.970 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 48.833 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 53.322 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 126: 56.969 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 386: 179.628 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 155: 65.828 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 25.473 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 34.106 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 39.071 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 171.356 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 130: 88.773 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 39.083 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 53.819 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 98: 56.681 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 43.382 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 80.434 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 37.772 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 119: 70.289 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 59.076 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 53.749 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 52.700 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 60: 44.911 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 246: 140.960 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 42: 37.509 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 41: 49.141 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 88: 55.553 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 38.319 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 56.321 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 52.134 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 136: 76.872 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 133: 77.994 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 77.375 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 61.222 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 65.767 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 216: 144.802 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 54: 44.777 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 64: 39.241 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 34.210 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 50.290 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 44.390 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 44.679 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 41.887 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 50.887 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 32.523 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 194: 143.227 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 30.790 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 58.137 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 39.318 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 43.985 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 53.763 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 158: 121.810 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 29.300 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 29.302 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 52.505 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 68.230 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 41.019 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 61: 46.309 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 159: 92.937 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 52.665 ms\n",
      "Loading: roberta-base boolq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 2309.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 217: 222.542 ms\n",
      "Model: Base, Input Length 191: 203.045 ms\n",
      "Model: Base, Input Length 54: 71.490 ms\n",
      "Model: Base, Input Length 85: 115.493 ms\n",
      "Model: Base, Input Length 47: 114.893 ms\n",
      "Model: Base, Input Length 55: 100.076 ms\n",
      "Model: Base, Input Length 94: 125.194 ms\n",
      "Model: Base, Input Length 110: 131.380 ms\n",
      "Model: Base, Input Length 14: 41.098 ms\n",
      "Model: Base, Input Length 85: 87.596 ms\n",
      "Model: Base, Input Length 138: 127.965 ms\n",
      "Model: Base, Input Length 85: 89.589 ms\n",
      "Model: Base, Input Length 97: 104.654 ms\n",
      "Model: Base, Input Length 90: 106.230 ms\n",
      "Model: Base, Input Length 116: 123.246 ms\n",
      "Model: Base, Input Length 55: 65.615 ms\n",
      "Model: Base, Input Length 113: 112.935 ms\n",
      "Model: Base, Input Length 49: 58.757 ms\n",
      "Model: Base, Input Length 116: 129.689 ms\n",
      "Model: Base, Input Length 46: 63.350 ms\n",
      "Model: Base, Input Length 125: 140.565 ms\n",
      "Model: Base, Input Length 160: 148.527 ms\n",
      "Model: Base, Input Length 43: 60.254 ms\n",
      "Model: Base, Input Length 53: 70.014 ms\n",
      "Model: Base, Input Length 111: 107.595 ms\n",
      "Model: Base, Input Length 80: 80.018 ms\n",
      "Model: Base, Input Length 90: 128.721 ms\n",
      "Model: Base, Input Length 190: 166.220 ms\n",
      "Model: Base, Input Length 50: 65.438 ms\n",
      "Model: Base, Input Length 92: 83.585 ms\n",
      "Model: Base, Input Length 96: 103.880 ms\n",
      "Model: Base, Input Length 45: 64.865 ms\n",
      "Model: Base, Input Length 71: 72.593 ms\n",
      "Model: Base, Input Length 79: 81.112 ms\n",
      "Model: Base, Input Length 89: 89.692 ms\n",
      "Model: Base, Input Length 110: 117.464 ms\n",
      "Model: Base, Input Length 82: 89.536 ms\n",
      "Model: Base, Input Length 142: 134.541 ms\n",
      "Model: Base, Input Length 140: 184.987 ms\n",
      "Model: Base, Input Length 31: 57.265 ms\n",
      "Model: Base, Input Length 189: 222.155 ms\n",
      "Model: Base, Input Length 123: 117.849 ms\n",
      "Model: Base, Input Length 100: 110.730 ms\n",
      "Model: Base, Input Length 36: 52.078 ms\n",
      "Model: Base, Input Length 68: 80.019 ms\n",
      "Model: Base, Input Length 72: 71.818 ms\n",
      "Model: Base, Input Length 84: 105.446 ms\n",
      "Model: Base, Input Length 126: 134.552 ms\n",
      "Model: Base, Input Length 147: 131.704 ms\n",
      "Model: Base, Input Length 78: 82.331 ms\n",
      "Model: Base, Input Length 35: 52.994 ms\n",
      "Model: Base, Input Length 96: 88.661 ms\n",
      "Model: Base, Input Length 147: 144.726 ms\n",
      "Model: Base, Input Length 138: 133.538 ms\n",
      "Model: Base, Input Length 48: 61.563 ms\n",
      "Model: Base, Input Length 591: 445.424 ms\n",
      "Model: Base, Input Length 86: 120.334 ms\n",
      "Model: Base, Input Length 39: 63.334 ms\n",
      "Model: Base, Input Length 64: 97.424 ms\n",
      "Model: Base, Input Length 52: 95.355 ms\n",
      "Model: Base, Input Length 104: 133.660 ms\n",
      "Model: Base, Input Length 30: 52.210 ms\n",
      "Model: Base, Input Length 107: 108.972 ms\n",
      "Model: Base, Input Length 89: 88.555 ms\n",
      "Model: Base, Input Length 32: 47.541 ms\n",
      "Model: Base, Input Length 47: 56.268 ms\n",
      "Model: Base, Input Length 75: 80.756 ms\n",
      "Model: Base, Input Length 24: 44.151 ms\n",
      "Model: Base, Input Length 100: 90.131 ms\n",
      "Model: Base, Input Length 110: 136.258 ms\n",
      "Model: Base, Input Length 59: 64.848 ms\n",
      "Model: Base, Input Length 130: 116.908 ms\n",
      "Model: Base, Input Length 106: 112.228 ms\n",
      "Model: Base, Input Length 39: 54.361 ms\n",
      "Model: Base, Input Length 66: 73.224 ms\n",
      "Model: Base, Input Length 105: 109.081 ms\n",
      "Model: Base, Input Length 103: 98.687 ms\n",
      "Model: Base, Input Length 33: 60.777 ms\n",
      "Model: Base, Input Length 122: 136.919 ms\n",
      "Model: Base, Input Length 60: 64.531 ms\n",
      "Model: Base, Input Length 40: 52.477 ms\n",
      "Model: Base, Input Length 63: 78.742 ms\n",
      "Model: Base, Input Length 158: 146.394 ms\n",
      "Model: Base, Input Length 123: 113.541 ms\n",
      "Model: Base, Input Length 110: 105.891 ms\n",
      "Model: Base, Input Length 145: 162.278 ms\n",
      "Model: Base, Input Length 50: 61.919 ms\n",
      "Model: Base, Input Length 46: 82.202 ms\n",
      "Model: Base, Input Length 32: 61.869 ms\n",
      "Model: Base, Input Length 74: 93.727 ms\n",
      "Model: Base, Input Length 68: 86.685 ms\n",
      "Model: Base, Input Length 89: 91.057 ms\n",
      "Model: Base, Input Length 55: 57.305 ms\n",
      "Model: Base, Input Length 46: 60.999 ms\n",
      "Model: Base, Input Length 20: 42.446 ms\n",
      "Model: Base, Input Length 37: 59.741 ms\n",
      "Model: Base, Input Length 85: 82.976 ms\n",
      "Model: Base, Input Length 122: 126.153 ms\n",
      "Model: Base, Input Length 80: 77.603 ms\n",
      "Model: Base, Input Length 176: 182.605 ms\n",
      "Model: Base, Input Length 141: 160.453 ms\n",
      "Model: Base, Input Length 83: 106.944 ms\n",
      "Model: Base, Input Length 231: 242.859 ms\n",
      "Model: Base, Input Length 125: 126.741 ms\n",
      "Model: Base, Input Length 202: 170.696 ms\n",
      "Model: Base, Input Length 44: 52.687 ms\n",
      "Model: Base, Input Length 15: 37.004 ms\n",
      "Model: Base, Input Length 90: 104.274 ms\n",
      "Model: Base, Input Length 62: 63.761 ms\n",
      "Model: Base, Input Length 114: 118.182 ms\n",
      "Model: Base, Input Length 153: 155.335 ms\n",
      "Model: Base, Input Length 112: 108.860 ms\n",
      "Model: Base, Input Length 57: 64.466 ms\n",
      "Model: Base, Input Length 106: 93.664 ms\n",
      "Model: Base, Input Length 92: 92.629 ms\n",
      "Model: Base, Input Length 86: 92.497 ms\n",
      "Model: Base, Input Length 45: 66.371 ms\n",
      "Model: Base, Input Length 110: 111.724 ms\n",
      "Model: Base, Input Length 73: 95.900 ms\n",
      "Model: Base, Input Length 121: 115.952 ms\n",
      "Model: Base, Input Length 159: 156.478 ms\n",
      "Model: Base, Input Length 51: 145.279 ms\n",
      "Model: Base, Input Length 94: 106.640 ms\n",
      "Model: Base, Input Length 70: 78.966 ms\n",
      "Model: Base, Input Length 92: 115.990 ms\n",
      "Model: Base, Input Length 55: 87.813 ms\n",
      "Model: Base, Input Length 31: 60.451 ms\n",
      "Model: Base, Input Length 39: 75.250 ms\n",
      "Model: Base, Input Length 104: 129.917 ms\n",
      "Model: Base, Input Length 249: 314.039 ms\n",
      "Model: Base, Input Length 80: 100.297 ms\n",
      "Model: Base, Input Length 142: 161.416 ms\n",
      "Model: Base, Input Length 203: 206.202 ms\n",
      "Model: Base, Input Length 97: 108.051 ms\n",
      "Model: Base, Input Length 147: 156.734 ms\n",
      "Model: Base, Input Length 42: 66.538 ms\n",
      "Model: Base, Input Length 154: 183.179 ms\n",
      "Model: Base, Input Length 192: 229.460 ms\n",
      "Model: Base, Input Length 78: 131.904 ms\n",
      "Model: Base, Input Length 274: 353.483 ms\n",
      "Model: Base, Input Length 72: 109.435 ms\n",
      "Model: Base, Input Length 65: 108.583 ms\n",
      "Model: Base, Input Length 57: 91.455 ms\n",
      "Model: Base, Input Length 96: 117.684 ms\n",
      "Model: Base, Input Length 66: 113.078 ms\n",
      "Model: Base, Input Length 37: 71.534 ms\n",
      "Model: Base, Input Length 40: 78.976 ms\n",
      "Model: Base, Input Length 124: 186.035 ms\n",
      "Model: Base, Input Length 19: 58.453 ms\n",
      "Model: Base, Input Length 203: 232.557 ms\n",
      "Model: Base, Input Length 56: 83.583 ms\n",
      "Model: Base, Input Length 97: 132.696 ms\n",
      "Model: Base, Input Length 82: 128.116 ms\n",
      "Model: Base, Input Length 79: 98.515 ms\n",
      "Model: Base, Input Length 74: 108.337 ms\n",
      "Model: Base, Input Length 143: 147.713 ms\n",
      "Model: Base, Input Length 52: 75.366 ms\n",
      "Model: Base, Input Length 157: 150.454 ms\n",
      "Model: Base, Input Length 113: 109.858 ms\n",
      "Model: Base, Input Length 163: 204.194 ms\n",
      "Model: Base, Input Length 71: 91.590 ms\n",
      "Model: Base, Input Length 76: 96.580 ms\n",
      "Model: Base, Input Length 24: 56.903 ms\n",
      "Model: Base, Input Length 137: 156.940 ms\n",
      "Model: Base, Input Length 63: 101.312 ms\n",
      "Model: Base, Input Length 102: 113.758 ms\n",
      "Model: Base, Input Length 52: 76.179 ms\n",
      "Model: Base, Input Length 76: 90.812 ms\n",
      "Model: Base, Input Length 89: 104.322 ms\n",
      "Model: Base, Input Length 75: 87.213 ms\n",
      "Model: Base, Input Length 57: 78.840 ms\n",
      "Model: Base, Input Length 95: 111.426 ms\n",
      "Model: Base, Input Length 79: 100.609 ms\n",
      "Model: Base, Input Length 162: 177.823 ms\n",
      "Model: Base, Input Length 49: 64.570 ms\n",
      "Model: Base, Input Length 39: 59.729 ms\n",
      "Model: Base, Input Length 117: 130.845 ms\n",
      "Model: Base, Input Length 188: 167.120 ms\n",
      "Model: Base, Input Length 131: 127.524 ms\n",
      "Model: Base, Input Length 59: 76.549 ms\n",
      "Model: Base, Input Length 55: 66.113 ms\n",
      "Model: Base, Input Length 43: 56.659 ms\n",
      "Model: Base, Input Length 91: 97.597 ms\n",
      "Model: Base, Input Length 35: 62.239 ms\n",
      "Model: Base, Input Length 78: 82.229 ms\n",
      "Model: Base, Input Length 90: 96.084 ms\n",
      "Model: Base, Input Length 65: 77.337 ms\n",
      "Model: Base, Input Length 22: 50.167 ms\n",
      "Model: Base, Input Length 156: 165.002 ms\n",
      "Model: Base, Input Length 84: 98.510 ms\n",
      "Model: Base, Input Length 93: 115.224 ms\n",
      "Model: Base, Input Length 71: 90.941 ms\n",
      "Model: Base, Input Length 90: 105.894 ms\n",
      "Model: Base, Input Length 106: 120.984 ms\n",
      "Model: Base, Input Length 126: 139.500 ms\n",
      "Model: Base, Input Length 386: 404.849 ms\n",
      "Model: Base, Input Length 155: 144.532 ms\n",
      "Model: Base, Input Length 37: 59.352 ms\n",
      "Model: Base, Input Length 65: 69.577 ms\n",
      "Model: Base, Input Length 71: 86.364 ms\n",
      "Model: Base, Input Length 320: 384.507 ms\n",
      "Model: Base, Input Length 130: 134.894 ms\n",
      "Model: Base, Input Length 43: 62.141 ms\n",
      "Model: Base, Input Length 94: 98.494 ms\n",
      "Model: Base, Input Length 98: 97.948 ms\n",
      "Model: Base, Input Length 66: 78.554 ms\n",
      "Model: Base, Input Length 122: 128.991 ms\n",
      "Model: Base, Input Length 49: 62.489 ms\n",
      "Model: Base, Input Length 119: 125.728 ms\n",
      "Model: Base, Input Length 117: 113.952 ms\n",
      "Model: Base, Input Length 79: 100.892 ms\n",
      "Model: Base, Input Length 92: 93.494 ms\n",
      "Model: Base, Input Length 60: 77.827 ms\n",
      "Model: Base, Input Length 246: 243.582 ms\n",
      "Model: Base, Input Length 42: 75.880 ms\n",
      "Model: Base, Input Length 41: 60.324 ms\n",
      "Model: Base, Input Length 88: 99.497 ms\n",
      "Model: Base, Input Length 46: 61.229 ms\n",
      "Model: Base, Input Length 86: 101.633 ms\n",
      "Model: Base, Input Length 97: 103.075 ms\n",
      "Model: Base, Input Length 136: 127.956 ms\n",
      "Model: Base, Input Length 133: 133.287 ms\n",
      "Model: Base, Input Length 142: 122.958 ms\n",
      "Model: Base, Input Length 86: 112.544 ms\n",
      "Model: Base, Input Length 110: 130.027 ms\n",
      "Model: Base, Input Length 216: 220.070 ms\n",
      "Model: Base, Input Length 54: 77.852 ms\n",
      "Model: Base, Input Length 64: 67.700 ms\n",
      "Model: Base, Input Length 40: 59.738 ms\n",
      "Model: Base, Input Length 76: 89.311 ms\n",
      "Model: Base, Input Length 67: 102.489 ms\n",
      "Model: Base, Input Length 80: 102.186 ms\n",
      "Model: Base, Input Length 67: 67.824 ms\n",
      "Model: Base, Input Length 79: 80.477 ms\n",
      "Model: Base, Input Length 43: 53.876 ms\n",
      "Model: Base, Input Length 194: 242.315 ms\n",
      "Model: Base, Input Length 31: 63.466 ms\n",
      "Model: Base, Input Length 107: 106.883 ms\n",
      "Model: Base, Input Length 55: 61.747 ms\n",
      "Model: Base, Input Length 58: 71.667 ms\n",
      "Model: Base, Input Length 67: 84.464 ms\n",
      "Model: Base, Input Length 158: 200.575 ms\n",
      "Model: Base, Input Length 39: 60.156 ms\n",
      "Model: Base, Input Length 45: 56.155 ms\n",
      "Model: Base, Input Length 100: 96.934 ms\n",
      "Model: Base, Input Length 125: 131.709 ms\n",
      "Model: Base, Input Length 75: 83.715 ms\n",
      "Model: Base, Input Length 61: 82.603 ms\n",
      "Model: Base, Input Length 159: 162.836 ms\n",
      "Model: Base, Input Length 97: 101.803 ms\n",
      "Model: Base Quantized, Input Length 217: 225.745 ms\n",
      "Model: Base Quantized, Input Length 191: 257.796 ms\n",
      "Model: Base Quantized, Input Length 54: 82.289 ms\n",
      "Model: Base Quantized, Input Length 85: 109.226 ms\n",
      "Model: Base Quantized, Input Length 47: 116.054 ms\n",
      "Model: Base Quantized, Input Length 55: 93.468 ms\n",
      "Model: Base Quantized, Input Length 94: 112.126 ms\n",
      "Model: Base Quantized, Input Length 110: 121.288 ms\n",
      "Model: Base Quantized, Input Length 14: 54.333 ms\n",
      "Model: Base Quantized, Input Length 85: 97.479 ms\n",
      "Model: Base Quantized, Input Length 138: 135.388 ms\n",
      "Model: Base Quantized, Input Length 85: 106.172 ms\n",
      "Model: Base Quantized, Input Length 97: 111.490 ms\n",
      "Model: Base Quantized, Input Length 90: 118.264 ms\n",
      "Model: Base Quantized, Input Length 116: 152.547 ms\n",
      "Model: Base Quantized, Input Length 55: 81.679 ms\n",
      "Model: Base Quantized, Input Length 113: 143.718 ms\n",
      "Model: Base Quantized, Input Length 49: 74.191 ms\n",
      "Model: Base Quantized, Input Length 116: 135.653 ms\n",
      "Model: Base Quantized, Input Length 46: 81.037 ms\n",
      "Model: Base Quantized, Input Length 125: 147.900 ms\n",
      "Model: Base Quantized, Input Length 160: 167.520 ms\n",
      "Model: Base Quantized, Input Length 43: 73.374 ms\n",
      "Model: Base Quantized, Input Length 53: 78.407 ms\n",
      "Model: Base Quantized, Input Length 111: 127.586 ms\n",
      "Model: Base Quantized, Input Length 80: 90.253 ms\n",
      "Model: Base Quantized, Input Length 90: 114.434 ms\n",
      "Model: Base Quantized, Input Length 190: 175.119 ms\n",
      "Model: Base Quantized, Input Length 50: 79.338 ms\n",
      "Model: Base Quantized, Input Length 92: 102.248 ms\n",
      "Model: Base Quantized, Input Length 96: 116.987 ms\n",
      "Model: Base Quantized, Input Length 45: 80.818 ms\n",
      "Model: Base Quantized, Input Length 71: 91.581 ms\n",
      "Model: Base Quantized, Input Length 79: 103.705 ms\n",
      "Model: Base Quantized, Input Length 89: 98.014 ms\n",
      "Model: Base Quantized, Input Length 110: 122.329 ms\n",
      "Model: Base Quantized, Input Length 82: 102.862 ms\n",
      "Model: Base Quantized, Input Length 142: 148.921 ms\n",
      "Model: Base Quantized, Input Length 140: 191.040 ms\n",
      "Model: Base Quantized, Input Length 31: 65.317 ms\n",
      "Model: Base Quantized, Input Length 189: 225.638 ms\n",
      "Model: Base Quantized, Input Length 123: 125.713 ms\n",
      "Model: Base Quantized, Input Length 100: 124.172 ms\n",
      "Model: Base Quantized, Input Length 36: 61.928 ms\n",
      "Model: Base Quantized, Input Length 68: 94.327 ms\n",
      "Model: Base Quantized, Input Length 72: 92.616 ms\n",
      "Model: Base Quantized, Input Length 84: 114.860 ms\n",
      "Model: Base Quantized, Input Length 126: 152.922 ms\n",
      "Model: Base Quantized, Input Length 147: 156.968 ms\n",
      "Model: Base Quantized, Input Length 78: 105.924 ms\n",
      "Model: Base Quantized, Input Length 35: 66.377 ms\n",
      "Model: Base Quantized, Input Length 96: 106.377 ms\n",
      "Model: Base Quantized, Input Length 147: 163.261 ms\n",
      "Model: Base Quantized, Input Length 138: 144.404 ms\n",
      "Model: Base Quantized, Input Length 48: 80.332 ms\n",
      "Model: Base Quantized, Input Length 591: 466.509 ms\n",
      "Model: Base Quantized, Input Length 86: 115.906 ms\n",
      "Model: Base Quantized, Input Length 39: 70.525 ms\n",
      "Model: Base Quantized, Input Length 64: 97.349 ms\n",
      "Model: Base Quantized, Input Length 52: 93.465 ms\n",
      "Model: Base Quantized, Input Length 104: 158.184 ms\n",
      "Model: Base Quantized, Input Length 30: 69.214 ms\n",
      "Model: Base Quantized, Input Length 107: 121.293 ms\n",
      "Model: Base Quantized, Input Length 89: 101.351 ms\n",
      "Model: Base Quantized, Input Length 32: 63.928 ms\n",
      "Model: Base Quantized, Input Length 47: 73.342 ms\n",
      "Model: Base Quantized, Input Length 75: 105.771 ms\n",
      "Model: Base Quantized, Input Length 24: 56.962 ms\n",
      "Model: Base Quantized, Input Length 100: 108.698 ms\n",
      "Model: Base Quantized, Input Length 110: 145.495 ms\n",
      "Model: Base Quantized, Input Length 59: 76.375 ms\n",
      "Model: Base Quantized, Input Length 130: 127.100 ms\n",
      "Model: Base Quantized, Input Length 106: 126.354 ms\n",
      "Model: Base Quantized, Input Length 39: 67.471 ms\n",
      "Model: Base Quantized, Input Length 66: 84.859 ms\n",
      "Model: Base Quantized, Input Length 105: 116.794 ms\n",
      "Model: Base Quantized, Input Length 103: 115.689 ms\n",
      "Model: Base Quantized, Input Length 33: 68.872 ms\n",
      "Model: Base Quantized, Input Length 122: 155.570 ms\n",
      "Model: Base Quantized, Input Length 60: 78.918 ms\n",
      "Model: Base Quantized, Input Length 40: 66.692 ms\n",
      "Model: Base Quantized, Input Length 63: 96.754 ms\n",
      "Model: Base Quantized, Input Length 158: 164.368 ms\n",
      "Model: Base Quantized, Input Length 123: 135.453 ms\n",
      "Model: Base Quantized, Input Length 110: 128.820 ms\n",
      "Model: Base Quantized, Input Length 145: 183.054 ms\n",
      "Model: Base Quantized, Input Length 50: 75.197 ms\n",
      "Model: Base Quantized, Input Length 46: 77.924 ms\n",
      "Model: Base Quantized, Input Length 32: 63.314 ms\n",
      "Model: Base Quantized, Input Length 74: 136.456 ms\n",
      "Model: Base Quantized, Input Length 68: 107.175 ms\n",
      "Model: Base Quantized, Input Length 89: 120.380 ms\n",
      "Model: Base Quantized, Input Length 55: 74.907 ms\n",
      "Model: Base Quantized, Input Length 46: 83.011 ms\n",
      "Model: Base Quantized, Input Length 20: 51.238 ms\n",
      "Model: Base Quantized, Input Length 37: 66.238 ms\n",
      "Model: Base Quantized, Input Length 85: 101.704 ms\n",
      "Model: Base Quantized, Input Length 122: 138.568 ms\n",
      "Model: Base Quantized, Input Length 80: 97.090 ms\n",
      "Model: Base Quantized, Input Length 176: 186.831 ms\n",
      "Model: Base Quantized, Input Length 141: 146.434 ms\n",
      "Model: Base Quantized, Input Length 83: 101.350 ms\n",
      "Model: Base Quantized, Input Length 231: 247.343 ms\n",
      "Model: Base Quantized, Input Length 125: 129.974 ms\n",
      "Model: Base Quantized, Input Length 202: 195.667 ms\n",
      "Model: Base Quantized, Input Length 44: 69.424 ms\n",
      "Model: Base Quantized, Input Length 15: 53.362 ms\n",
      "Model: Base Quantized, Input Length 90: 119.220 ms\n",
      "Model: Base Quantized, Input Length 62: 80.888 ms\n",
      "Model: Base Quantized, Input Length 114: 134.276 ms\n",
      "Model: Base Quantized, Input Length 153: 184.721 ms\n",
      "Model: Base Quantized, Input Length 112: 140.452 ms\n",
      "Model: Base Quantized, Input Length 57: 83.677 ms\n",
      "Model: Base Quantized, Input Length 106: 118.014 ms\n",
      "Model: Base Quantized, Input Length 92: 117.966 ms\n",
      "Model: Base Quantized, Input Length 86: 115.539 ms\n",
      "Model: Base Quantized, Input Length 45: 77.134 ms\n",
      "Model: Base Quantized, Input Length 110: 132.284 ms\n",
      "Model: Base Quantized, Input Length 73: 96.422 ms\n",
      "Model: Base Quantized, Input Length 121: 130.777 ms\n",
      "Model: Base Quantized, Input Length 159: 172.341 ms\n",
      "Model: Base Quantized, Input Length 51: 147.005 ms\n",
      "Model: Base Quantized, Input Length 94: 110.367 ms\n",
      "Model: Base Quantized, Input Length 70: 83.983 ms\n",
      "Model: Base Quantized, Input Length 92: 103.995 ms\n",
      "Model: Base Quantized, Input Length 55: 84.249 ms\n",
      "Model: Base Quantized, Input Length 31: 64.272 ms\n",
      "Model: Base Quantized, Input Length 39: 71.368 ms\n",
      "Model: Base Quantized, Input Length 104: 121.563 ms\n",
      "Model: Base Quantized, Input Length 249: 297.522 ms\n",
      "Model: Base Quantized, Input Length 80: 111.704 ms\n",
      "Model: Base Quantized, Input Length 142: 160.909 ms\n",
      "Model: Base Quantized, Input Length 203: 204.595 ms\n",
      "Model: Base Quantized, Input Length 97: 111.778 ms\n",
      "Model: Base Quantized, Input Length 147: 175.944 ms\n",
      "Model: Base Quantized, Input Length 42: 70.860 ms\n",
      "Model: Base Quantized, Input Length 154: 162.226 ms\n",
      "Model: Base Quantized, Input Length 192: 187.079 ms\n",
      "Model: Base Quantized, Input Length 78: 104.723 ms\n",
      "Model: Base Quantized, Input Length 274: 308.268 ms\n",
      "Model: Base Quantized, Input Length 72: 98.945 ms\n",
      "Model: Base Quantized, Input Length 65: 100.068 ms\n",
      "Model: Base Quantized, Input Length 57: 80.986 ms\n",
      "Model: Base Quantized, Input Length 96: 122.253 ms\n",
      "Model: Base Quantized, Input Length 66: 107.163 ms\n",
      "Model: Base Quantized, Input Length 37: 70.812 ms\n",
      "Model: Base Quantized, Input Length 40: 72.203 ms\n",
      "Model: Base Quantized, Input Length 124: 144.036 ms\n",
      "Model: Base Quantized, Input Length 19: 53.945 ms\n",
      "Model: Base Quantized, Input Length 203: 206.859 ms\n",
      "Model: Base Quantized, Input Length 56: 81.011 ms\n",
      "Model: Base Quantized, Input Length 97: 109.015 ms\n",
      "Model: Base Quantized, Input Length 82: 122.501 ms\n",
      "Model: Base Quantized, Input Length 79: 102.757 ms\n",
      "Model: Base Quantized, Input Length 74: 107.435 ms\n",
      "Model: Base Quantized, Input Length 143: 139.698 ms\n",
      "Model: Base Quantized, Input Length 52: 84.558 ms\n",
      "Model: Base Quantized, Input Length 157: 160.234 ms\n",
      "Model: Base Quantized, Input Length 113: 134.559 ms\n",
      "Model: Base Quantized, Input Length 163: 178.945 ms\n",
      "Model: Base Quantized, Input Length 71: 100.368 ms\n",
      "Model: Base Quantized, Input Length 76: 109.662 ms\n",
      "Model: Base Quantized, Input Length 24: 62.755 ms\n",
      "Model: Base Quantized, Input Length 137: 168.826 ms\n",
      "Model: Base Quantized, Input Length 63: 117.406 ms\n",
      "Model: Base Quantized, Input Length 102: 120.889 ms\n",
      "Model: Base Quantized, Input Length 52: 72.412 ms\n",
      "Model: Base Quantized, Input Length 76: 94.923 ms\n",
      "Model: Base Quantized, Input Length 89: 124.323 ms\n",
      "Model: Base Quantized, Input Length 75: 98.874 ms\n",
      "Model: Base Quantized, Input Length 57: 81.529 ms\n",
      "Model: Base Quantized, Input Length 95: 136.243 ms\n",
      "Model: Base Quantized, Input Length 79: 117.943 ms\n",
      "Model: Base Quantized, Input Length 162: 207.283 ms\n",
      "Model: Base Quantized, Input Length 49: 82.248 ms\n",
      "Model: Base Quantized, Input Length 39: 63.541 ms\n",
      "Model: Base Quantized, Input Length 117: 125.059 ms\n",
      "Model: Base Quantized, Input Length 188: 230.986 ms\n",
      "Model: Base Quantized, Input Length 131: 184.802 ms\n",
      "Model: Base Quantized, Input Length 59: 125.511 ms\n",
      "Model: Base Quantized, Input Length 55: 94.376 ms\n",
      "Model: Base Quantized, Input Length 43: 92.400 ms\n",
      "Model: Base Quantized, Input Length 91: 154.260 ms\n",
      "Model: Base Quantized, Input Length 35: 90.508 ms\n",
      "Model: Base Quantized, Input Length 78: 110.597 ms\n",
      "Model: Base Quantized, Input Length 90: 140.783 ms\n",
      "Model: Base Quantized, Input Length 65: 109.451 ms\n",
      "Model: Base Quantized, Input Length 22: 71.636 ms\n",
      "Model: Base Quantized, Input Length 156: 220.023 ms\n",
      "Model: Base Quantized, Input Length 84: 135.353 ms\n",
      "Model: Base Quantized, Input Length 93: 159.836 ms\n",
      "Model: Base Quantized, Input Length 71: 140.919 ms\n",
      "Model: Base Quantized, Input Length 90: 152.523 ms\n",
      "Model: Base Quantized, Input Length 106: 168.375 ms\n",
      "Model: Base Quantized, Input Length 126: 187.017 ms\n",
      "Model: Base Quantized, Input Length 386: 513.332 ms\n",
      "Model: Base Quantized, Input Length 155: 233.393 ms\n",
      "Model: Base Quantized, Input Length 37: 84.919 ms\n",
      "Model: Base Quantized, Input Length 65: 98.989 ms\n",
      "Model: Base Quantized, Input Length 71: 123.754 ms\n",
      "Model: Base Quantized, Input Length 320: 451.446 ms\n",
      "Model: Base Quantized, Input Length 130: 191.907 ms\n",
      "Model: Base Quantized, Input Length 43: 96.920 ms\n",
      "Model: Base Quantized, Input Length 94: 145.426 ms\n",
      "Model: Base Quantized, Input Length 98: 151.521 ms\n",
      "Model: Base Quantized, Input Length 66: 121.063 ms\n",
      "Model: Base Quantized, Input Length 122: 196.179 ms\n",
      "Model: Base Quantized, Input Length 49: 99.361 ms\n",
      "Model: Base Quantized, Input Length 119: 164.388 ms\n",
      "Model: Base Quantized, Input Length 117: 159.883 ms\n",
      "Model: Base Quantized, Input Length 79: 138.550 ms\n",
      "Model: Base Quantized, Input Length 92: 138.380 ms\n",
      "Model: Base Quantized, Input Length 60: 110.655 ms\n",
      "Model: Base Quantized, Input Length 246: 308.192 ms\n",
      "Model: Base Quantized, Input Length 42: 97.266 ms\n",
      "Model: Base Quantized, Input Length 41: 97.208 ms\n",
      "Model: Base Quantized, Input Length 88: 155.596 ms\n",
      "Model: Base Quantized, Input Length 46: 95.707 ms\n",
      "Model: Base Quantized, Input Length 86: 151.375 ms\n",
      "Model: Base Quantized, Input Length 97: 144.851 ms\n",
      "Model: Base Quantized, Input Length 136: 209.474 ms\n",
      "Model: Base Quantized, Input Length 133: 193.200 ms\n",
      "Model: Base Quantized, Input Length 142: 195.703 ms\n",
      "Model: Base Quantized, Input Length 86: 153.756 ms\n",
      "Model: Base Quantized, Input Length 110: 176.571 ms\n",
      "Model: Base Quantized, Input Length 216: 435.863 ms\n",
      "Model: Base Quantized, Input Length 54: 141.609 ms\n",
      "Model: Base Quantized, Input Length 64: 117.265 ms\n",
      "Model: Base Quantized, Input Length 40: 101.787 ms\n",
      "Model: Base Quantized, Input Length 76: 137.731 ms\n",
      "Model: Base Quantized, Input Length 67: 128.082 ms\n",
      "Model: Base Quantized, Input Length 80: 137.784 ms\n",
      "Model: Base Quantized, Input Length 67: 109.022 ms\n",
      "Model: Base Quantized, Input Length 79: 119.181 ms\n",
      "Model: Base Quantized, Input Length 43: 77.585 ms\n",
      "Model: Base Quantized, Input Length 194: 302.594 ms\n",
      "Model: Base Quantized, Input Length 31: 86.350 ms\n",
      "Model: Base Quantized, Input Length 107: 157.110 ms\n",
      "Model: Base Quantized, Input Length 55: 94.893 ms\n",
      "Model: Base Quantized, Input Length 58: 109.868 ms\n",
      "Model: Base Quantized, Input Length 67: 139.520 ms\n",
      "Model: Base Quantized, Input Length 158: 261.404 ms\n",
      "Model: Base Quantized, Input Length 39: 81.896 ms\n",
      "Model: Base Quantized, Input Length 45: 80.061 ms\n",
      "Model: Base Quantized, Input Length 100: 128.748 ms\n",
      "Model: Base Quantized, Input Length 125: 157.825 ms\n",
      "Model: Base Quantized, Input Length 75: 106.901 ms\n",
      "Model: Base Quantized, Input Length 61: 110.978 ms\n",
      "Model: Base Quantized, Input Length 159: 187.305 ms\n",
      "Model: Base Quantized, Input Length 97: 134.188 ms\n",
      "Model: ONNX, Input Length 217: 115.742 ms\n",
      "Model: ONNX, Input Length 191: 119.153 ms\n",
      "Model: ONNX, Input Length 54: 38.729 ms\n",
      "Model: ONNX, Input Length 85: 61.561 ms\n",
      "Model: ONNX, Input Length 47: 60.444 ms\n",
      "Model: ONNX, Input Length 55: 58.713 ms\n",
      "Model: ONNX, Input Length 94: 64.448 ms\n",
      "Model: ONNX, Input Length 110: 70.158 ms\n",
      "Model: ONNX, Input Length 14: 25.007 ms\n",
      "Model: ONNX, Input Length 85: 55.177 ms\n",
      "Model: ONNX, Input Length 138: 76.200 ms\n",
      "Model: ONNX, Input Length 85: 54.517 ms\n",
      "Model: ONNX, Input Length 97: 56.781 ms\n",
      "Model: ONNX, Input Length 90: 63.321 ms\n",
      "Model: ONNX, Input Length 116: 80.133 ms\n",
      "Model: ONNX, Input Length 55: 47.138 ms\n",
      "Model: ONNX, Input Length 113: 71.981 ms\n",
      "Model: ONNX, Input Length 49: 40.390 ms\n",
      "Model: ONNX, Input Length 116: 81.962 ms\n",
      "Model: ONNX, Input Length 46: 42.886 ms\n",
      "Model: ONNX, Input Length 125: 86.931 ms\n",
      "Model: ONNX, Input Length 160: 102.486 ms\n",
      "Model: ONNX, Input Length 43: 48.764 ms\n",
      "Model: ONNX, Input Length 53: 48.502 ms\n",
      "Model: ONNX, Input Length 111: 79.693 ms\n",
      "Model: ONNX, Input Length 80: 66.705 ms\n",
      "Model: ONNX, Input Length 90: 79.577 ms\n",
      "Model: ONNX, Input Length 190: 120.732 ms\n",
      "Model: ONNX, Input Length 50: 52.010 ms\n",
      "Model: ONNX, Input Length 92: 66.334 ms\n",
      "Model: ONNX, Input Length 96: 73.851 ms\n",
      "Model: ONNX, Input Length 45: 40.746 ms\n",
      "Model: ONNX, Input Length 71: 58.879 ms\n",
      "Model: ONNX, Input Length 79: 65.966 ms\n",
      "Model: ONNX, Input Length 89: 66.143 ms\n",
      "Model: ONNX, Input Length 110: 83.824 ms\n",
      "Model: ONNX, Input Length 82: 69.240 ms\n",
      "Model: ONNX, Input Length 142: 100.255 ms\n",
      "Model: ONNX, Input Length 140: 124.572 ms\n",
      "Model: ONNX, Input Length 31: 34.205 ms\n",
      "Model: ONNX, Input Length 189: 145.366 ms\n",
      "Model: ONNX, Input Length 123: 82.127 ms\n",
      "Model: ONNX, Input Length 100: 70.796 ms\n",
      "Model: ONNX, Input Length 36: 34.012 ms\n",
      "Model: ONNX, Input Length 68: 54.554 ms\n",
      "Model: ONNX, Input Length 72: 48.694 ms\n",
      "Model: ONNX, Input Length 84: 63.584 ms\n",
      "Model: ONNX, Input Length 126: 93.859 ms\n",
      "Model: ONNX, Input Length 147: 84.978 ms\n",
      "Model: ONNX, Input Length 78: 59.866 ms\n",
      "Model: ONNX, Input Length 35: 33.171 ms\n",
      "Model: ONNX, Input Length 96: 66.690 ms\n",
      "Model: ONNX, Input Length 147: 96.413 ms\n",
      "Model: ONNX, Input Length 138: 85.406 ms\n",
      "Model: ONNX, Input Length 48: 44.933 ms\n",
      "Model: ONNX, Input Length 591: 272.268 ms\n",
      "Model: ONNX, Input Length 86: 70.522 ms\n",
      "Model: ONNX, Input Length 39: 35.532 ms\n",
      "Model: ONNX, Input Length 64: 48.383 ms\n",
      "Model: ONNX, Input Length 52: 50.240 ms\n",
      "Model: ONNX, Input Length 104: 85.697 ms\n",
      "Model: ONNX, Input Length 30: 29.692 ms\n",
      "Model: ONNX, Input Length 107: 65.573 ms\n",
      "Model: ONNX, Input Length 89: 55.418 ms\n",
      "Model: ONNX, Input Length 32: 31.540 ms\n",
      "Model: ONNX, Input Length 47: 38.618 ms\n",
      "Model: ONNX, Input Length 75: 56.665 ms\n",
      "Model: ONNX, Input Length 24: 27.202 ms\n",
      "Model: ONNX, Input Length 100: 60.524 ms\n",
      "Model: ONNX, Input Length 110: 80.547 ms\n",
      "Model: ONNX, Input Length 59: 43.352 ms\n",
      "Model: ONNX, Input Length 130: 70.560 ms\n",
      "Model: ONNX, Input Length 106: 64.662 ms\n",
      "Model: ONNX, Input Length 39: 32.352 ms\n",
      "Model: ONNX, Input Length 66: 54.798 ms\n",
      "Model: ONNX, Input Length 105: 66.914 ms\n",
      "Model: ONNX, Input Length 103: 60.145 ms\n",
      "Model: ONNX, Input Length 33: 34.711 ms\n",
      "Model: ONNX, Input Length 122: 86.846 ms\n",
      "Model: ONNX, Input Length 60: 43.895 ms\n",
      "Model: ONNX, Input Length 40: 34.947 ms\n",
      "Model: ONNX, Input Length 63: 47.532 ms\n",
      "Model: ONNX, Input Length 158: 94.999 ms\n",
      "Model: ONNX, Input Length 123: 77.503 ms\n",
      "Model: ONNX, Input Length 110: 69.180 ms\n",
      "Model: ONNX, Input Length 145: 102.474 ms\n",
      "Model: ONNX, Input Length 50: 36.573 ms\n",
      "Model: ONNX, Input Length 46: 40.276 ms\n",
      "Model: ONNX, Input Length 32: 27.984 ms\n",
      "Model: ONNX, Input Length 74: 55.292 ms\n",
      "Model: ONNX, Input Length 68: 48.211 ms\n",
      "Model: ONNX, Input Length 89: 55.346 ms\n",
      "Model: ONNX, Input Length 55: 37.369 ms\n",
      "Model: ONNX, Input Length 46: 41.553 ms\n",
      "Model: ONNX, Input Length 20: 24.631 ms\n",
      "Model: ONNX, Input Length 37: 34.473 ms\n",
      "Model: ONNX, Input Length 85: 49.962 ms\n",
      "Model: ONNX, Input Length 122: 80.390 ms\n",
      "Model: ONNX, Input Length 80: 48.719 ms\n",
      "Model: ONNX, Input Length 176: 107.700 ms\n",
      "Model: ONNX, Input Length 141: 83.491 ms\n",
      "Model: ONNX, Input Length 83: 58.064 ms\n",
      "Model: ONNX, Input Length 231: 149.910 ms\n",
      "Model: ONNX, Input Length 125: 67.746 ms\n",
      "Model: ONNX, Input Length 202: 114.425 ms\n",
      "Model: ONNX, Input Length 44: 35.918 ms\n",
      "Model: ONNX, Input Length 15: 22.585 ms\n",
      "Model: ONNX, Input Length 90: 63.746 ms\n",
      "Model: ONNX, Input Length 62: 45.704 ms\n",
      "Model: ONNX, Input Length 114: 82.218 ms\n",
      "Model: ONNX, Input Length 153: 99.471 ms\n",
      "Model: ONNX, Input Length 112: 73.965 ms\n",
      "Model: ONNX, Input Length 57: 48.746 ms\n",
      "Model: ONNX, Input Length 106: 67.376 ms\n",
      "Model: ONNX, Input Length 92: 61.740 ms\n",
      "Model: ONNX, Input Length 86: 58.462 ms\n",
      "Model: ONNX, Input Length 45: 44.940 ms\n",
      "Model: ONNX, Input Length 110: 72.017 ms\n",
      "Model: ONNX, Input Length 73: 53.573 ms\n",
      "Model: ONNX, Input Length 121: 76.220 ms\n",
      "Model: ONNX, Input Length 159: 97.572 ms\n",
      "Model: ONNX, Input Length 51: 81.464 ms\n",
      "Model: ONNX, Input Length 94: 69.021 ms\n",
      "Model: ONNX, Input Length 70: 57.452 ms\n",
      "Model: ONNX, Input Length 92: 70.934 ms\n",
      "Model: ONNX, Input Length 55: 56.592 ms\n",
      "Model: ONNX, Input Length 31: 38.630 ms\n",
      "Model: ONNX, Input Length 39: 44.188 ms\n",
      "Model: ONNX, Input Length 104: 78.604 ms\n",
      "Model: ONNX, Input Length 249: 190.208 ms\n",
      "Model: ONNX, Input Length 80: 64.976 ms\n",
      "Model: ONNX, Input Length 142: 100.929 ms\n",
      "Model: ONNX, Input Length 203: 117.170 ms\n",
      "Model: ONNX, Input Length 97: 71.018 ms\n",
      "Model: ONNX, Input Length 147: 98.658 ms\n",
      "Model: ONNX, Input Length 42: 38.988 ms\n",
      "Model: ONNX, Input Length 154: 108.731 ms\n",
      "Model: ONNX, Input Length 192: 110.453 ms\n",
      "Model: ONNX, Input Length 78: 58.199 ms\n",
      "Model: ONNX, Input Length 274: 175.027 ms\n",
      "Model: ONNX, Input Length 72: 67.826 ms\n",
      "Model: ONNX, Input Length 65: 68.346 ms\n",
      "Model: ONNX, Input Length 57: 52.979 ms\n",
      "Model: ONNX, Input Length 96: 75.424 ms\n",
      "Model: ONNX, Input Length 66: 62.860 ms\n",
      "Model: ONNX, Input Length 37: 43.962 ms\n",
      "Model: ONNX, Input Length 40: 41.925 ms\n",
      "Model: ONNX, Input Length 124: 99.824 ms\n",
      "Model: ONNX, Input Length 19: 28.811 ms\n",
      "Model: ONNX, Input Length 203: 126.379 ms\n",
      "Model: ONNX, Input Length 56: 41.223 ms\n",
      "Model: ONNX, Input Length 97: 67.565 ms\n",
      "Model: ONNX, Input Length 82: 69.715 ms\n",
      "Model: ONNX, Input Length 79: 62.507 ms\n",
      "Model: ONNX, Input Length 74: 77.113 ms\n",
      "Model: ONNX, Input Length 143: 103.463 ms\n",
      "Model: ONNX, Input Length 52: 54.817 ms\n",
      "Model: ONNX, Input Length 157: 101.111 ms\n",
      "Model: ONNX, Input Length 113: 81.253 ms\n",
      "Model: ONNX, Input Length 163: 108.176 ms\n",
      "Model: ONNX, Input Length 71: 60.044 ms\n",
      "Model: ONNX, Input Length 76: 62.664 ms\n",
      "Model: ONNX, Input Length 24: 33.910 ms\n",
      "Model: ONNX, Input Length 137: 99.185 ms\n",
      "Model: ONNX, Input Length 63: 68.557 ms\n",
      "Model: ONNX, Input Length 102: 69.514 ms\n",
      "Model: ONNX, Input Length 52: 48.044 ms\n",
      "Model: ONNX, Input Length 76: 58.565 ms\n",
      "Model: ONNX, Input Length 89: 72.806 ms\n",
      "Model: ONNX, Input Length 75: 61.984 ms\n",
      "Model: ONNX, Input Length 57: 46.361 ms\n",
      "Model: ONNX, Input Length 95: 77.652 ms\n",
      "Model: ONNX, Input Length 79: 66.372 ms\n",
      "Model: ONNX, Input Length 162: 115.041 ms\n",
      "Model: ONNX, Input Length 49: 46.465 ms\n",
      "Model: ONNX, Input Length 39: 36.427 ms\n",
      "Model: ONNX, Input Length 117: 79.943 ms\n",
      "Model: ONNX, Input Length 188: 119.364 ms\n",
      "Model: ONNX, Input Length 131: 81.137 ms\n",
      "Model: ONNX, Input Length 59: 50.947 ms\n",
      "Model: ONNX, Input Length 55: 48.219 ms\n",
      "Model: ONNX, Input Length 43: 46.212 ms\n",
      "Model: ONNX, Input Length 91: 68.393 ms\n",
      "Model: ONNX, Input Length 35: 44.127 ms\n",
      "Model: ONNX, Input Length 78: 62.926 ms\n",
      "Model: ONNX, Input Length 90: 71.258 ms\n",
      "Model: ONNX, Input Length 65: 52.141 ms\n",
      "Model: ONNX, Input Length 22: 30.473 ms\n",
      "Model: ONNX, Input Length 156: 106.722 ms\n",
      "Model: ONNX, Input Length 84: 66.114 ms\n",
      "Model: ONNX, Input Length 93: 78.409 ms\n",
      "Model: ONNX, Input Length 71: 62.071 ms\n",
      "Model: ONNX, Input Length 90: 84.380 ms\n",
      "Model: ONNX, Input Length 106: 86.389 ms\n",
      "Model: ONNX, Input Length 126: 83.524 ms\n",
      "Model: ONNX, Input Length 386: 245.569 ms\n",
      "Model: ONNX, Input Length 155: 104.661 ms\n",
      "Model: ONNX, Input Length 37: 35.055 ms\n",
      "Model: ONNX, Input Length 65: 53.541 ms\n",
      "Model: ONNX, Input Length 71: 56.062 ms\n",
      "Model: ONNX, Input Length 320: 229.953 ms\n",
      "Model: ONNX, Input Length 130: 95.355 ms\n",
      "Model: ONNX, Input Length 43: 50.809 ms\n",
      "Model: ONNX, Input Length 94: 76.664 ms\n",
      "Model: ONNX, Input Length 98: 77.167 ms\n",
      "Model: ONNX, Input Length 66: 66.089 ms\n",
      "Model: ONNX, Input Length 122: 104.270 ms\n",
      "Model: ONNX, Input Length 49: 54.091 ms\n",
      "Model: ONNX, Input Length 119: 97.356 ms\n",
      "Model: ONNX, Input Length 117: 89.797 ms\n",
      "Model: ONNX, Input Length 79: 63.369 ms\n",
      "Model: ONNX, Input Length 92: 69.622 ms\n",
      "Model: ONNX, Input Length 60: 55.988 ms\n",
      "Model: ONNX, Input Length 246: 146.505 ms\n",
      "Model: ONNX, Input Length 42: 49.191 ms\n",
      "Model: ONNX, Input Length 41: 45.518 ms\n",
      "Model: ONNX, Input Length 88: 63.067 ms\n",
      "Model: ONNX, Input Length 46: 41.068 ms\n",
      "Model: ONNX, Input Length 86: 69.165 ms\n",
      "Model: ONNX, Input Length 97: 66.928 ms\n",
      "Model: ONNX, Input Length 136: 88.150 ms\n",
      "Model: ONNX, Input Length 133: 88.583 ms\n",
      "Model: ONNX, Input Length 142: 85.938 ms\n",
      "Model: ONNX, Input Length 86: 72.790 ms\n",
      "Model: ONNX, Input Length 110: 77.974 ms\n",
      "Model: ONNX, Input Length 216: 142.353 ms\n",
      "Model: ONNX, Input Length 54: 58.156 ms\n",
      "Model: ONNX, Input Length 64: 51.818 ms\n",
      "Model: ONNX, Input Length 40: 41.400 ms\n",
      "Model: ONNX, Input Length 76: 63.162 ms\n",
      "Model: ONNX, Input Length 67: 56.920 ms\n",
      "Model: ONNX, Input Length 80: 72.697 ms\n",
      "Model: ONNX, Input Length 67: 53.212 ms\n",
      "Model: ONNX, Input Length 79: 53.360 ms\n",
      "Model: ONNX, Input Length 43: 35.539 ms\n",
      "Model: ONNX, Input Length 194: 158.226 ms\n",
      "Model: ONNX, Input Length 31: 41.707 ms\n",
      "Model: ONNX, Input Length 107: 82.214 ms\n",
      "Model: ONNX, Input Length 55: 46.272 ms\n",
      "Model: ONNX, Input Length 58: 49.741 ms\n",
      "Model: ONNX, Input Length 67: 60.781 ms\n",
      "Model: ONNX, Input Length 158: 122.755 ms\n",
      "Model: ONNX, Input Length 39: 38.372 ms\n",
      "Model: ONNX, Input Length 45: 43.994 ms\n",
      "Model: ONNX, Input Length 100: 76.776 ms\n",
      "Model: ONNX, Input Length 125: 105.028 ms\n",
      "Model: ONNX, Input Length 75: 65.623 ms\n",
      "Model: ONNX, Input Length 61: 62.264 ms\n",
      "Model: ONNX, Input Length 159: 132.010 ms\n",
      "Model: ONNX, Input Length 97: 85.306 ms\n",
      "Model: ONNX-OPT, Input Length 217: 148.196 ms\n",
      "Model: ONNX-OPT, Input Length 191: 129.674 ms\n",
      "Model: ONNX-OPT, Input Length 54: 40.974 ms\n",
      "Model: ONNX-OPT, Input Length 85: 64.871 ms\n",
      "Model: ONNX-OPT, Input Length 47: 60.712 ms\n",
      "Model: ONNX-OPT, Input Length 55: 48.461 ms\n",
      "Model: ONNX-OPT, Input Length 94: 66.858 ms\n",
      "Model: ONNX-OPT, Input Length 110: 88.557 ms\n",
      "Model: ONNX-OPT, Input Length 14: 25.516 ms\n",
      "Model: ONNX-OPT, Input Length 85: 74.990 ms\n",
      "Model: ONNX-OPT, Input Length 138: 102.945 ms\n",
      "Model: ONNX-OPT, Input Length 85: 72.541 ms\n",
      "Model: ONNX-OPT, Input Length 97: 84.134 ms\n",
      "Model: ONNX-OPT, Input Length 90: 68.222 ms\n",
      "Model: ONNX-OPT, Input Length 116: 85.136 ms\n",
      "Model: ONNX-OPT, Input Length 55: 48.598 ms\n",
      "Model: ONNX-OPT, Input Length 113: 86.431 ms\n",
      "Model: ONNX-OPT, Input Length 49: 48.077 ms\n",
      "Model: ONNX-OPT, Input Length 116: 95.741 ms\n",
      "Model: ONNX-OPT, Input Length 46: 49.940 ms\n",
      "Model: ONNX-OPT, Input Length 125: 99.603 ms\n",
      "Model: ONNX-OPT, Input Length 160: 114.676 ms\n",
      "Model: ONNX-OPT, Input Length 43: 47.272 ms\n",
      "Model: ONNX-OPT, Input Length 53: 50.258 ms\n",
      "Model: ONNX-OPT, Input Length 111: 74.552 ms\n",
      "Model: ONNX-OPT, Input Length 80: 58.237 ms\n",
      "Model: ONNX-OPT, Input Length 90: 69.038 ms\n",
      "Model: ONNX-OPT, Input Length 190: 115.976 ms\n",
      "Model: ONNX-OPT, Input Length 50: 48.794 ms\n",
      "Model: ONNX-OPT, Input Length 92: 60.290 ms\n",
      "Model: ONNX-OPT, Input Length 96: 64.738 ms\n",
      "Model: ONNX-OPT, Input Length 45: 43.899 ms\n",
      "Model: ONNX-OPT, Input Length 71: 51.874 ms\n",
      "Model: ONNX-OPT, Input Length 79: 65.333 ms\n",
      "Model: ONNX-OPT, Input Length 89: 59.499 ms\n",
      "Model: ONNX-OPT, Input Length 110: 74.350 ms\n",
      "Model: ONNX-OPT, Input Length 82: 61.687 ms\n",
      "Model: ONNX-OPT, Input Length 142: 85.630 ms\n",
      "Model: ONNX-OPT, Input Length 140: 106.318 ms\n",
      "Model: ONNX-OPT, Input Length 31: 33.318 ms\n",
      "Model: ONNX-OPT, Input Length 189: 138.257 ms\n",
      "Model: ONNX-OPT, Input Length 123: 76.270 ms\n",
      "Model: ONNX-OPT, Input Length 100: 68.907 ms\n",
      "Model: ONNX-OPT, Input Length 36: 33.210 ms\n",
      "Model: ONNX-OPT, Input Length 68: 56.047 ms\n",
      "Model: ONNX-OPT, Input Length 72: 54.821 ms\n",
      "Model: ONNX-OPT, Input Length 84: 67.977 ms\n",
      "Model: ONNX-OPT, Input Length 126: 85.806 ms\n",
      "Model: ONNX-OPT, Input Length 147: 91.323 ms\n",
      "Model: ONNX-OPT, Input Length 78: 56.267 ms\n",
      "Model: ONNX-OPT, Input Length 35: 35.950 ms\n",
      "Model: ONNX-OPT, Input Length 96: 61.150 ms\n",
      "Model: ONNX-OPT, Input Length 147: 96.949 ms\n",
      "Model: ONNX-OPT, Input Length 138: 87.083 ms\n",
      "Model: ONNX-OPT, Input Length 48: 44.915 ms\n",
      "Model: ONNX-OPT, Input Length 591: 273.234 ms\n",
      "Model: ONNX-OPT, Input Length 86: 69.536 ms\n",
      "Model: ONNX-OPT, Input Length 39: 38.725 ms\n",
      "Model: ONNX-OPT, Input Length 64: 53.938 ms\n",
      "Model: ONNX-OPT, Input Length 52: 58.833 ms\n",
      "Model: ONNX-OPT, Input Length 104: 91.565 ms\n",
      "Model: ONNX-OPT, Input Length 30: 31.806 ms\n",
      "Model: ONNX-OPT, Input Length 107: 72.739 ms\n",
      "Model: ONNX-OPT, Input Length 89: 59.866 ms\n",
      "Model: ONNX-OPT, Input Length 32: 32.852 ms\n",
      "Model: ONNX-OPT, Input Length 47: 50.000 ms\n",
      "Model: ONNX-OPT, Input Length 75: 74.967 ms\n",
      "Model: ONNX-OPT, Input Length 24: 34.144 ms\n",
      "Model: ONNX-OPT, Input Length 100: 67.553 ms\n",
      "Model: ONNX-OPT, Input Length 110: 90.627 ms\n",
      "Model: ONNX-OPT, Input Length 59: 50.384 ms\n",
      "Model: ONNX-OPT, Input Length 130: 77.128 ms\n",
      "Model: ONNX-OPT, Input Length 106: 72.020 ms\n",
      "Model: ONNX-OPT, Input Length 39: 36.902 ms\n",
      "Model: ONNX-OPT, Input Length 66: 55.206 ms\n",
      "Model: ONNX-OPT, Input Length 105: 72.115 ms\n",
      "Model: ONNX-OPT, Input Length 103: 62.866 ms\n",
      "Model: ONNX-OPT, Input Length 33: 41.974 ms\n",
      "Model: ONNX-OPT, Input Length 122: 92.038 ms\n",
      "Model: ONNX-OPT, Input Length 60: 48.237 ms\n",
      "Model: ONNX-OPT, Input Length 40: 36.215 ms\n",
      "Model: ONNX-OPT, Input Length 63: 58.329 ms\n",
      "Model: ONNX-OPT, Input Length 158: 104.999 ms\n",
      "Model: ONNX-OPT, Input Length 123: 82.244 ms\n",
      "Model: ONNX-OPT, Input Length 110: 72.629 ms\n",
      "Model: ONNX-OPT, Input Length 145: 110.581 ms\n",
      "Model: ONNX-OPT, Input Length 50: 43.184 ms\n",
      "Model: ONNX-OPT, Input Length 46: 49.659 ms\n",
      "Model: ONNX-OPT, Input Length 32: 31.540 ms\n",
      "Model: ONNX-OPT, Input Length 74: 61.187 ms\n",
      "Model: ONNX-OPT, Input Length 68: 64.232 ms\n",
      "Model: ONNX-OPT, Input Length 89: 66.953 ms\n",
      "Model: ONNX-OPT, Input Length 55: 42.648 ms\n",
      "Model: ONNX-OPT, Input Length 46: 46.649 ms\n",
      "Model: ONNX-OPT, Input Length 20: 26.725 ms\n",
      "Model: ONNX-OPT, Input Length 37: 40.529 ms\n",
      "Model: ONNX-OPT, Input Length 85: 58.076 ms\n",
      "Model: ONNX-OPT, Input Length 122: 87.247 ms\n",
      "Model: ONNX-OPT, Input Length 80: 57.855 ms\n",
      "Model: ONNX-OPT, Input Length 176: 114.124 ms\n",
      "Model: ONNX-OPT, Input Length 141: 90.026 ms\n",
      "Model: ONNX-OPT, Input Length 83: 59.693 ms\n",
      "Model: ONNX-OPT, Input Length 231: 151.267 ms\n",
      "Model: ONNX-OPT, Input Length 125: 82.537 ms\n",
      "Model: ONNX-OPT, Input Length 202: 120.691 ms\n",
      "Model: ONNX-OPT, Input Length 44: 40.474 ms\n",
      "Model: ONNX-OPT, Input Length 15: 26.419 ms\n",
      "Model: ONNX-OPT, Input Length 90: 68.733 ms\n",
      "Model: ONNX-OPT, Input Length 62: 51.015 ms\n",
      "Model: ONNX-OPT, Input Length 114: 85.447 ms\n",
      "Model: ONNX-OPT, Input Length 153: 106.827 ms\n",
      "Model: ONNX-OPT, Input Length 112: 74.283 ms\n",
      "Model: ONNX-OPT, Input Length 57: 53.440 ms\n",
      "Model: ONNX-OPT, Input Length 106: 68.871 ms\n",
      "Model: ONNX-OPT, Input Length 92: 64.592 ms\n",
      "Model: ONNX-OPT, Input Length 86: 64.409 ms\n",
      "Model: ONNX-OPT, Input Length 45: 43.082 ms\n",
      "Model: ONNX-OPT, Input Length 110: 76.486 ms\n",
      "Model: ONNX-OPT, Input Length 73: 56.359 ms\n",
      "Model: ONNX-OPT, Input Length 121: 80.071 ms\n",
      "Model: ONNX-OPT, Input Length 159: 102.770 ms\n",
      "Model: ONNX-OPT, Input Length 51: 86.881 ms\n",
      "Model: ONNX-OPT, Input Length 94: 65.434 ms\n",
      "Model: ONNX-OPT, Input Length 70: 52.750 ms\n",
      "Model: ONNX-OPT, Input Length 92: 60.039 ms\n",
      "Model: ONNX-OPT, Input Length 55: 51.177 ms\n",
      "Model: ONNX-OPT, Input Length 31: 31.205 ms\n",
      "Model: ONNX-OPT, Input Length 39: 38.349 ms\n",
      "Model: ONNX-OPT, Input Length 104: 67.240 ms\n",
      "Model: ONNX-OPT, Input Length 249: 173.929 ms\n",
      "Model: ONNX-OPT, Input Length 80: 62.426 ms\n",
      "Model: ONNX-OPT, Input Length 142: 96.084 ms\n",
      "Model: ONNX-OPT, Input Length 203: 117.455 ms\n",
      "Model: ONNX-OPT, Input Length 97: 62.909 ms\n",
      "Model: ONNX-OPT, Input Length 147: 107.921 ms\n",
      "Model: ONNX-OPT, Input Length 42: 34.758 ms\n",
      "Model: ONNX-OPT, Input Length 154: 100.414 ms\n",
      "Model: ONNX-OPT, Input Length 192: 111.540 ms\n",
      "Model: ONNX-OPT, Input Length 78: 59.126 ms\n",
      "Model: ONNX-OPT, Input Length 274: 179.373 ms\n",
      "Model: ONNX-OPT, Input Length 72: 56.498 ms\n",
      "Model: ONNX-OPT, Input Length 65: 66.503 ms\n",
      "Model: ONNX-OPT, Input Length 57: 45.878 ms\n",
      "Model: ONNX-OPT, Input Length 96: 68.331 ms\n",
      "Model: ONNX-OPT, Input Length 66: 55.824 ms\n",
      "Model: ONNX-OPT, Input Length 37: 38.685 ms\n",
      "Model: ONNX-OPT, Input Length 40: 41.180 ms\n",
      "Model: ONNX-OPT, Input Length 124: 92.835 ms\n",
      "Model: ONNX-OPT, Input Length 19: 29.672 ms\n",
      "Model: ONNX-OPT, Input Length 203: 129.894 ms\n",
      "Model: ONNX-OPT, Input Length 56: 41.755 ms\n",
      "Model: ONNX-OPT, Input Length 97: 65.277 ms\n",
      "Model: ONNX-OPT, Input Length 82: 69.161 ms\n",
      "Model: ONNX-OPT, Input Length 79: 55.787 ms\n",
      "Model: ONNX-OPT, Input Length 74: 60.563 ms\n",
      "Model: ONNX-OPT, Input Length 143: 87.832 ms\n",
      "Model: ONNX-OPT, Input Length 52: 51.556 ms\n",
      "Model: ONNX-OPT, Input Length 157: 108.812 ms\n",
      "Model: ONNX-OPT, Input Length 113: 80.073 ms\n",
      "Model: ONNX-OPT, Input Length 163: 102.355 ms\n",
      "Model: ONNX-OPT, Input Length 71: 56.335 ms\n",
      "Model: ONNX-OPT, Input Length 76: 61.576 ms\n",
      "Model: ONNX-OPT, Input Length 24: 33.290 ms\n",
      "Model: ONNX-OPT, Input Length 137: 97.824 ms\n",
      "Model: ONNX-OPT, Input Length 63: 66.056 ms\n",
      "Model: ONNX-OPT, Input Length 102: 63.337 ms\n",
      "Model: ONNX-OPT, Input Length 52: 42.323 ms\n",
      "Model: ONNX-OPT, Input Length 76: 56.029 ms\n",
      "Model: ONNX-OPT, Input Length 89: 68.194 ms\n",
      "Model: ONNX-OPT, Input Length 75: 64.513 ms\n",
      "Model: ONNX-OPT, Input Length 57: 45.396 ms\n",
      "Model: ONNX-OPT, Input Length 95: 71.066 ms\n",
      "Model: ONNX-OPT, Input Length 79: 58.691 ms\n",
      "Model: ONNX-OPT, Input Length 162: 107.265 ms\n",
      "Model: ONNX-OPT, Input Length 49: 41.964 ms\n",
      "Model: ONNX-OPT, Input Length 39: 36.515 ms\n",
      "Model: ONNX-OPT, Input Length 117: 72.713 ms\n",
      "Model: ONNX-OPT, Input Length 188: 123.882 ms\n",
      "Model: ONNX-OPT, Input Length 131: 81.383 ms\n",
      "Model: ONNX-OPT, Input Length 59: 48.223 ms\n",
      "Model: ONNX-OPT, Input Length 55: 41.308 ms\n",
      "Model: ONNX-OPT, Input Length 43: 37.940 ms\n",
      "Model: ONNX-OPT, Input Length 91: 62.473 ms\n",
      "Model: ONNX-OPT, Input Length 35: 38.944 ms\n",
      "Model: ONNX-OPT, Input Length 78: 52.672 ms\n",
      "Model: ONNX-OPT, Input Length 90: 66.688 ms\n",
      "Model: ONNX-OPT, Input Length 65: 47.371 ms\n",
      "Model: ONNX-OPT, Input Length 22: 26.874 ms\n",
      "Model: ONNX-OPT, Input Length 156: 94.140 ms\n",
      "Model: ONNX-OPT, Input Length 84: 59.899 ms\n",
      "Model: ONNX-OPT, Input Length 93: 65.018 ms\n",
      "Model: ONNX-OPT, Input Length 71: 60.005 ms\n",
      "Model: ONNX-OPT, Input Length 90: 68.958 ms\n",
      "Model: ONNX-OPT, Input Length 106: 74.076 ms\n",
      "Model: ONNX-OPT, Input Length 126: 78.910 ms\n",
      "Model: ONNX-OPT, Input Length 386: 241.049 ms\n",
      "Model: ONNX-OPT, Input Length 155: 96.405 ms\n",
      "Model: ONNX-OPT, Input Length 37: 36.554 ms\n",
      "Model: ONNX-OPT, Input Length 65: 48.560 ms\n",
      "Model: ONNX-OPT, Input Length 71: 53.837 ms\n",
      "Model: ONNX-OPT, Input Length 320: 233.385 ms\n",
      "Model: ONNX-OPT, Input Length 130: 90.682 ms\n",
      "Model: ONNX-OPT, Input Length 43: 42.479 ms\n",
      "Model: ONNX-OPT, Input Length 94: 63.221 ms\n",
      "Model: ONNX-OPT, Input Length 98: 64.802 ms\n",
      "Model: ONNX-OPT, Input Length 66: 50.499 ms\n",
      "Model: ONNX-OPT, Input Length 122: 84.429 ms\n",
      "Model: ONNX-OPT, Input Length 49: 41.440 ms\n",
      "Model: ONNX-OPT, Input Length 119: 79.167 ms\n",
      "Model: ONNX-OPT, Input Length 117: 79.610 ms\n",
      "Model: ONNX-OPT, Input Length 79: 59.463 ms\n",
      "Model: ONNX-OPT, Input Length 92: 59.184 ms\n",
      "Model: ONNX-OPT, Input Length 60: 49.782 ms\n",
      "Model: ONNX-OPT, Input Length 246: 151.643 ms\n",
      "Model: ONNX-OPT, Input Length 42: 47.420 ms\n",
      "Model: ONNX-OPT, Input Length 41: 44.141 ms\n",
      "Model: ONNX-OPT, Input Length 88: 68.513 ms\n",
      "Model: ONNX-OPT, Input Length 46: 37.037 ms\n",
      "Model: ONNX-OPT, Input Length 86: 63.945 ms\n",
      "Model: ONNX-OPT, Input Length 97: 61.452 ms\n",
      "Model: ONNX-OPT, Input Length 136: 87.270 ms\n",
      "Model: ONNX-OPT, Input Length 133: 154.121 ms\n",
      "Model: ONNX-OPT, Input Length 142: 93.416 ms\n",
      "Model: ONNX-OPT, Input Length 86: 86.100 ms\n",
      "Model: ONNX-OPT, Input Length 110: 85.238 ms\n",
      "Model: ONNX-OPT, Input Length 216: 167.674 ms\n",
      "Model: ONNX-OPT, Input Length 54: 57.162 ms\n",
      "Model: ONNX-OPT, Input Length 64: 51.101 ms\n",
      "Model: ONNX-OPT, Input Length 40: 38.931 ms\n",
      "Model: ONNX-OPT, Input Length 76: 59.967 ms\n",
      "Model: ONNX-OPT, Input Length 67: 54.396 ms\n",
      "Model: ONNX-OPT, Input Length 80: 64.240 ms\n",
      "Model: ONNX-OPT, Input Length 67: 51.296 ms\n",
      "Model: ONNX-OPT, Input Length 79: 56.122 ms\n",
      "Model: ONNX-OPT, Input Length 43: 37.977 ms\n",
      "Model: ONNX-OPT, Input Length 194: 163.330 ms\n",
      "Model: ONNX-OPT, Input Length 31: 39.224 ms\n",
      "Model: ONNX-OPT, Input Length 107: 70.687 ms\n",
      "Model: ONNX-OPT, Input Length 55: 41.025 ms\n",
      "Model: ONNX-OPT, Input Length 58: 47.700 ms\n",
      "Model: ONNX-OPT, Input Length 67: 74.158 ms\n",
      "Model: ONNX-OPT, Input Length 158: 128.376 ms\n",
      "Model: ONNX-OPT, Input Length 39: 42.727 ms\n",
      "Model: ONNX-OPT, Input Length 45: 36.274 ms\n",
      "Model: ONNX-OPT, Input Length 100: 63.864 ms\n",
      "Model: ONNX-OPT, Input Length 125: 87.278 ms\n",
      "Model: ONNX-OPT, Input Length 75: 50.436 ms\n",
      "Model: ONNX-OPT, Input Length 61: 57.074 ms\n",
      "Model: ONNX-OPT, Input Length 159: 112.672 ms\n",
      "Model: ONNX-OPT, Input Length 97: 70.168 ms\n",
      "Model: ONNX Quantized, Input Length 217: 100.046 ms\n",
      "Model: ONNX Quantized, Input Length 191: 100.095 ms\n",
      "Model: ONNX Quantized, Input Length 54: 34.403 ms\n",
      "Model: ONNX Quantized, Input Length 85: 57.128 ms\n",
      "Model: ONNX Quantized, Input Length 47: 56.272 ms\n",
      "Model: ONNX Quantized, Input Length 55: 47.146 ms\n",
      "Model: ONNX Quantized, Input Length 94: 58.562 ms\n",
      "Model: ONNX Quantized, Input Length 110: 65.328 ms\n",
      "Model: ONNX Quantized, Input Length 14: 18.057 ms\n",
      "Model: ONNX Quantized, Input Length 85: 55.651 ms\n",
      "Model: ONNX Quantized, Input Length 138: 73.213 ms\n",
      "Model: ONNX Quantized, Input Length 85: 46.465 ms\n",
      "Model: ONNX Quantized, Input Length 97: 51.765 ms\n",
      "Model: ONNX Quantized, Input Length 90: 51.859 ms\n",
      "Model: ONNX Quantized, Input Length 116: 61.687 ms\n",
      "Model: ONNX Quantized, Input Length 55: 35.967 ms\n",
      "Model: ONNX Quantized, Input Length 113: 56.350 ms\n",
      "Model: ONNX Quantized, Input Length 49: 29.007 ms\n",
      "Model: ONNX Quantized, Input Length 116: 56.662 ms\n",
      "Model: ONNX Quantized, Input Length 46: 36.624 ms\n",
      "Model: ONNX Quantized, Input Length 125: 70.013 ms\n",
      "Model: ONNX Quantized, Input Length 160: 77.981 ms\n",
      "Model: ONNX Quantized, Input Length 43: 33.897 ms\n",
      "Model: ONNX Quantized, Input Length 53: 35.003 ms\n",
      "Model: ONNX Quantized, Input Length 111: 55.921 ms\n",
      "Model: ONNX Quantized, Input Length 80: 43.132 ms\n",
      "Model: ONNX Quantized, Input Length 90: 49.525 ms\n",
      "Model: ONNX Quantized, Input Length 190: 80.986 ms\n",
      "Model: ONNX Quantized, Input Length 50: 35.735 ms\n",
      "Model: ONNX Quantized, Input Length 92: 44.705 ms\n",
      "Model: ONNX Quantized, Input Length 96: 50.919 ms\n",
      "Model: ONNX Quantized, Input Length 45: 34.215 ms\n",
      "Model: ONNX Quantized, Input Length 71: 53.886 ms\n",
      "Model: ONNX Quantized, Input Length 79: 45.728 ms\n",
      "Model: ONNX Quantized, Input Length 89: 45.030 ms\n",
      "Model: ONNX Quantized, Input Length 110: 55.783 ms\n",
      "Model: ONNX Quantized, Input Length 82: 45.539 ms\n",
      "Model: ONNX Quantized, Input Length 142: 66.412 ms\n",
      "Model: ONNX Quantized, Input Length 140: 90.042 ms\n",
      "Model: ONNX Quantized, Input Length 31: 24.980 ms\n",
      "Model: ONNX Quantized, Input Length 189: 126.530 ms\n",
      "Model: ONNX Quantized, Input Length 123: 59.199 ms\n",
      "Model: ONNX Quantized, Input Length 100: 55.397 ms\n",
      "Model: ONNX Quantized, Input Length 36: 25.809 ms\n",
      "Model: ONNX Quantized, Input Length 68: 43.415 ms\n",
      "Model: ONNX Quantized, Input Length 72: 41.605 ms\n",
      "Model: ONNX Quantized, Input Length 84: 47.164 ms\n",
      "Model: ONNX Quantized, Input Length 126: 63.427 ms\n",
      "Model: ONNX Quantized, Input Length 147: 67.376 ms\n",
      "Model: ONNX Quantized, Input Length 78: 46.965 ms\n",
      "Model: ONNX Quantized, Input Length 35: 25.118 ms\n",
      "Model: ONNX Quantized, Input Length 96: 46.103 ms\n",
      "Model: ONNX Quantized, Input Length 147: 82.303 ms\n",
      "Model: ONNX Quantized, Input Length 138: 66.967 ms\n",
      "Model: ONNX Quantized, Input Length 48: 34.663 ms\n",
      "Model: ONNX Quantized, Input Length 591: 225.779 ms\n",
      "Model: ONNX Quantized, Input Length 86: 47.540 ms\n",
      "Model: ONNX Quantized, Input Length 39: 27.223 ms\n",
      "Model: ONNX Quantized, Input Length 64: 40.460 ms\n",
      "Model: ONNX Quantized, Input Length 52: 41.964 ms\n",
      "Model: ONNX Quantized, Input Length 104: 67.458 ms\n",
      "Model: ONNX Quantized, Input Length 30: 24.773 ms\n",
      "Model: ONNX Quantized, Input Length 107: 54.459 ms\n",
      "Model: ONNX Quantized, Input Length 89: 43.216 ms\n",
      "Model: ONNX Quantized, Input Length 32: 25.028 ms\n",
      "Model: ONNX Quantized, Input Length 47: 37.933 ms\n",
      "Model: ONNX Quantized, Input Length 75: 51.154 ms\n",
      "Model: ONNX Quantized, Input Length 24: 21.118 ms\n",
      "Model: ONNX Quantized, Input Length 100: 45.492 ms\n",
      "Model: ONNX Quantized, Input Length 110: 63.992 ms\n",
      "Model: ONNX Quantized, Input Length 59: 36.564 ms\n",
      "Model: ONNX Quantized, Input Length 130: 55.680 ms\n",
      "Model: ONNX Quantized, Input Length 106: 53.653 ms\n",
      "Model: ONNX Quantized, Input Length 39: 27.480 ms\n",
      "Model: ONNX Quantized, Input Length 66: 38.278 ms\n",
      "Model: ONNX Quantized, Input Length 105: 59.268 ms\n",
      "Model: ONNX Quantized, Input Length 103: 46.668 ms\n",
      "Model: ONNX Quantized, Input Length 33: 30.847 ms\n",
      "Model: ONNX Quantized, Input Length 122: 66.320 ms\n",
      "Model: ONNX Quantized, Input Length 60: 37.509 ms\n",
      "Model: ONNX Quantized, Input Length 40: 30.459 ms\n",
      "Model: ONNX Quantized, Input Length 63: 39.723 ms\n",
      "Model: ONNX Quantized, Input Length 158: 75.160 ms\n",
      "Model: ONNX Quantized, Input Length 123: 65.009 ms\n",
      "Model: ONNX Quantized, Input Length 110: 57.199 ms\n",
      "Model: ONNX Quantized, Input Length 145: 82.722 ms\n",
      "Model: ONNX Quantized, Input Length 50: 33.501 ms\n",
      "Model: ONNX Quantized, Input Length 46: 36.147 ms\n",
      "Model: ONNX Quantized, Input Length 32: 21.785 ms\n",
      "Model: ONNX Quantized, Input Length 74: 48.811 ms\n",
      "Model: ONNX Quantized, Input Length 68: 40.831 ms\n",
      "Model: ONNX Quantized, Input Length 89: 45.877 ms\n",
      "Model: ONNX Quantized, Input Length 55: 32.609 ms\n",
      "Model: ONNX Quantized, Input Length 46: 33.452 ms\n",
      "Model: ONNX Quantized, Input Length 20: 18.966 ms\n",
      "Model: ONNX Quantized, Input Length 37: 28.524 ms\n",
      "Model: ONNX Quantized, Input Length 85: 46.151 ms\n",
      "Model: ONNX Quantized, Input Length 122: 61.137 ms\n",
      "Model: ONNX Quantized, Input Length 80: 39.927 ms\n",
      "Model: ONNX Quantized, Input Length 176: 85.084 ms\n",
      "Model: ONNX Quantized, Input Length 141: 69.450 ms\n",
      "Model: ONNX Quantized, Input Length 83: 43.412 ms\n",
      "Model: ONNX Quantized, Input Length 231: 121.302 ms\n",
      "Model: ONNX Quantized, Input Length 125: 55.812 ms\n",
      "Model: ONNX Quantized, Input Length 202: 91.615 ms\n",
      "Model: ONNX Quantized, Input Length 44: 28.292 ms\n",
      "Model: ONNX Quantized, Input Length 15: 17.207 ms\n",
      "Model: ONNX Quantized, Input Length 90: 54.589 ms\n",
      "Model: ONNX Quantized, Input Length 62: 38.404 ms\n",
      "Model: ONNX Quantized, Input Length 114: 67.568 ms\n",
      "Model: ONNX Quantized, Input Length 153: 82.937 ms\n",
      "Model: ONNX Quantized, Input Length 112: 62.547 ms\n",
      "Model: ONNX Quantized, Input Length 57: 38.617 ms\n",
      "Model: ONNX Quantized, Input Length 106: 55.207 ms\n",
      "Model: ONNX Quantized, Input Length 92: 54.207 ms\n",
      "Model: ONNX Quantized, Input Length 86: 48.609 ms\n",
      "Model: ONNX Quantized, Input Length 45: 34.921 ms\n",
      "Model: ONNX Quantized, Input Length 110: 70.765 ms\n",
      "Model: ONNX Quantized, Input Length 73: 48.525 ms\n",
      "Model: ONNX Quantized, Input Length 121: 64.193 ms\n",
      "Model: ONNX Quantized, Input Length 159: 84.747 ms\n",
      "Model: ONNX Quantized, Input Length 51: 70.046 ms\n",
      "Model: ONNX Quantized, Input Length 94: 49.943 ms\n",
      "Model: ONNX Quantized, Input Length 70: 39.771 ms\n",
      "Model: ONNX Quantized, Input Length 92: 44.950 ms\n",
      "Model: ONNX Quantized, Input Length 55: 43.417 ms\n",
      "Model: ONNX Quantized, Input Length 31: 26.057 ms\n",
      "Model: ONNX Quantized, Input Length 39: 29.335 ms\n",
      "Model: ONNX Quantized, Input Length 104: 57.707 ms\n",
      "Model: ONNX Quantized, Input Length 249: 140.604 ms\n",
      "Model: ONNX Quantized, Input Length 80: 44.718 ms\n",
      "Model: ONNX Quantized, Input Length 142: 73.235 ms\n",
      "Model: ONNX Quantized, Input Length 203: 88.691 ms\n",
      "Model: ONNX Quantized, Input Length 97: 63.546 ms\n",
      "Model: ONNX Quantized, Input Length 147: 96.658 ms\n",
      "Model: ONNX Quantized, Input Length 42: 29.804 ms\n",
      "Model: ONNX Quantized, Input Length 154: 78.734 ms\n",
      "Model: ONNX Quantized, Input Length 192: 89.165 ms\n",
      "Model: ONNX Quantized, Input Length 78: 49.598 ms\n",
      "Model: ONNX Quantized, Input Length 274: 147.670 ms\n",
      "Model: ONNX Quantized, Input Length 72: 43.714 ms\n",
      "Model: ONNX Quantized, Input Length 65: 45.929 ms\n",
      "Model: ONNX Quantized, Input Length 57: 36.262 ms\n",
      "Model: ONNX Quantized, Input Length 96: 51.953 ms\n",
      "Model: ONNX Quantized, Input Length 66: 43.320 ms\n",
      "Model: ONNX Quantized, Input Length 37: 29.240 ms\n",
      "Model: ONNX Quantized, Input Length 40: 31.077 ms\n",
      "Model: ONNX Quantized, Input Length 124: 63.167 ms\n",
      "Model: ONNX Quantized, Input Length 19: 22.224 ms\n",
      "Model: ONNX Quantized, Input Length 203: 107.897 ms\n",
      "Model: ONNX Quantized, Input Length 56: 32.549 ms\n",
      "Model: ONNX Quantized, Input Length 97: 47.329 ms\n",
      "Model: ONNX Quantized, Input Length 82: 49.801 ms\n",
      "Model: ONNX Quantized, Input Length 79: 41.448 ms\n",
      "Model: ONNX Quantized, Input Length 74: 44.671 ms\n",
      "Model: ONNX Quantized, Input Length 143: 69.686 ms\n",
      "Model: ONNX Quantized, Input Length 52: 36.112 ms\n",
      "Model: ONNX Quantized, Input Length 157: 78.588 ms\n",
      "Model: ONNX Quantized, Input Length 113: 67.821 ms\n",
      "Model: ONNX Quantized, Input Length 163: 85.902 ms\n",
      "Model: ONNX Quantized, Input Length 71: 44.161 ms\n",
      "Model: ONNX Quantized, Input Length 76: 48.911 ms\n",
      "Model: ONNX Quantized, Input Length 24: 24.760 ms\n",
      "Model: ONNX Quantized, Input Length 137: 77.702 ms\n",
      "Model: ONNX Quantized, Input Length 63: 49.060 ms\n",
      "Model: ONNX Quantized, Input Length 102: 50.548 ms\n",
      "Model: ONNX Quantized, Input Length 52: 39.739 ms\n",
      "Model: ONNX Quantized, Input Length 76: 49.956 ms\n",
      "Model: ONNX Quantized, Input Length 89: 57.127 ms\n",
      "Model: ONNX Quantized, Input Length 75: 45.988 ms\n",
      "Model: ONNX Quantized, Input Length 57: 34.695 ms\n",
      "Model: ONNX Quantized, Input Length 95: 54.378 ms\n",
      "Model: ONNX Quantized, Input Length 79: 46.200 ms\n",
      "Model: ONNX Quantized, Input Length 162: 86.220 ms\n",
      "Model: ONNX Quantized, Input Length 49: 38.944 ms\n",
      "Model: ONNX Quantized, Input Length 39: 32.710 ms\n",
      "Model: ONNX Quantized, Input Length 117: 71.112 ms\n",
      "Model: ONNX Quantized, Input Length 188: 115.717 ms\n",
      "Model: ONNX Quantized, Input Length 131: 73.987 ms\n",
      "Model: ONNX Quantized, Input Length 59: 46.698 ms\n",
      "Model: ONNX Quantized, Input Length 55: 41.702 ms\n",
      "Model: ONNX Quantized, Input Length 43: 36.534 ms\n",
      "Model: ONNX Quantized, Input Length 91: 59.290 ms\n",
      "Model: ONNX Quantized, Input Length 35: 34.499 ms\n",
      "Model: ONNX Quantized, Input Length 78: 49.051 ms\n",
      "Model: ONNX Quantized, Input Length 90: 55.179 ms\n",
      "Model: ONNX Quantized, Input Length 65: 41.393 ms\n",
      "Model: ONNX Quantized, Input Length 22: 22.328 ms\n",
      "Model: ONNX Quantized, Input Length 156: 86.374 ms\n",
      "Model: ONNX Quantized, Input Length 84: 44.129 ms\n",
      "Model: ONNX Quantized, Input Length 93: 55.386 ms\n",
      "Model: ONNX Quantized, Input Length 71: 45.220 ms\n",
      "Model: ONNX Quantized, Input Length 90: 51.659 ms\n",
      "Model: ONNX Quantized, Input Length 106: 66.474 ms\n",
      "Model: ONNX Quantized, Input Length 126: 64.590 ms\n",
      "Model: ONNX Quantized, Input Length 386: 203.832 ms\n",
      "Model: ONNX Quantized, Input Length 155: 79.141 ms\n",
      "Model: ONNX Quantized, Input Length 37: 27.493 ms\n",
      "Model: ONNX Quantized, Input Length 65: 41.149 ms\n",
      "Model: ONNX Quantized, Input Length 71: 48.466 ms\n",
      "Model: ONNX Quantized, Input Length 320: 212.942 ms\n",
      "Model: ONNX Quantized, Input Length 130: 67.126 ms\n",
      "Model: ONNX Quantized, Input Length 43: 33.094 ms\n",
      "Model: ONNX Quantized, Input Length 94: 49.154 ms\n",
      "Model: ONNX Quantized, Input Length 98: 50.377 ms\n",
      "Model: ONNX Quantized, Input Length 66: 42.970 ms\n",
      "Model: ONNX Quantized, Input Length 122: 64.381 ms\n",
      "Model: ONNX Quantized, Input Length 49: 33.837 ms\n",
      "Model: ONNX Quantized, Input Length 119: 65.987 ms\n",
      "Model: ONNX Quantized, Input Length 117: 68.264 ms\n",
      "Model: ONNX Quantized, Input Length 79: 45.864 ms\n",
      "Model: ONNX Quantized, Input Length 92: 47.433 ms\n",
      "Model: ONNX Quantized, Input Length 60: 43.835 ms\n",
      "Model: ONNX Quantized, Input Length 246: 121.707 ms\n",
      "Model: ONNX Quantized, Input Length 42: 38.250 ms\n",
      "Model: ONNX Quantized, Input Length 41: 34.015 ms\n",
      "Model: ONNX Quantized, Input Length 88: 52.667 ms\n",
      "Model: ONNX Quantized, Input Length 46: 32.570 ms\n",
      "Model: ONNX Quantized, Input Length 86: 53.346 ms\n",
      "Model: ONNX Quantized, Input Length 97: 55.636 ms\n",
      "Model: ONNX Quantized, Input Length 136: 66.458 ms\n",
      "Model: ONNX Quantized, Input Length 133: 67.667 ms\n",
      "Model: ONNX Quantized, Input Length 142: 63.924 ms\n",
      "Model: ONNX Quantized, Input Length 86: 56.863 ms\n",
      "Model: ONNX Quantized, Input Length 110: 56.410 ms\n",
      "Model: ONNX Quantized, Input Length 216: 116.480 ms\n",
      "Model: ONNX Quantized, Input Length 54: 40.347 ms\n",
      "Model: ONNX Quantized, Input Length 64: 36.584 ms\n",
      "Model: ONNX Quantized, Input Length 40: 29.044 ms\n",
      "Model: ONNX Quantized, Input Length 76: 41.762 ms\n",
      "Model: ONNX Quantized, Input Length 67: 39.804 ms\n",
      "Model: ONNX Quantized, Input Length 80: 48.398 ms\n",
      "Model: ONNX Quantized, Input Length 67: 40.225 ms\n",
      "Model: ONNX Quantized, Input Length 79: 41.643 ms\n",
      "Model: ONNX Quantized, Input Length 43: 25.697 ms\n",
      "Model: ONNX Quantized, Input Length 194: 129.633 ms\n",
      "Model: ONNX Quantized, Input Length 31: 27.913 ms\n",
      "Model: ONNX Quantized, Input Length 107: 55.035 ms\n",
      "Model: ONNX Quantized, Input Length 55: 33.653 ms\n",
      "Model: ONNX Quantized, Input Length 58: 36.677 ms\n",
      "Model: ONNX Quantized, Input Length 67: 43.476 ms\n",
      "Model: ONNX Quantized, Input Length 158: 94.548 ms\n",
      "Model: ONNX Quantized, Input Length 39: 31.128 ms\n",
      "Model: ONNX Quantized, Input Length 45: 28.734 ms\n",
      "Model: ONNX Quantized, Input Length 100: 48.626 ms\n",
      "Model: ONNX Quantized, Input Length 125: 65.454 ms\n",
      "Model: ONNX Quantized, Input Length 75: 40.586 ms\n",
      "Model: ONNX Quantized, Input Length 61: 41.346 ms\n",
      "Model: ONNX Quantized, Input Length 159: 83.996 ms\n",
      "Model: ONNX Quantized, Input Length 97: 55.450 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 217: 105.550 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 191: 104.764 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 54: 40.414 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 59.884 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 47: 70.636 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 48.242 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 61.080 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 67.370 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 19.826 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 47.389 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 138: 64.636 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 47.342 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 54.463 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 54.295 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 116: 62.197 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 37.134 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 113: 71.047 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 34.053 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 116: 67.304 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 38.621 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 80.911 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 160: 92.091 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 33.278 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 53: 37.496 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 111: 66.822 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 51.519 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 60.675 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 190: 83.528 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 50: 38.488 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 46.720 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 50.909 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 34.614 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 39.319 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 45.835 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 43.424 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 54.960 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 82: 51.225 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 64.334 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 140: 85.323 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 23.185 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 189: 112.355 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 123: 57.782 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 52.905 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 36: 28.013 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 68: 41.176 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 72: 38.369 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 84: 49.724 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 126: 64.711 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 66.495 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 50.574 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 35: 25.697 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 45.889 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 78.607 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 138: 69.059 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 48: 33.637 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 591: 214.981 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 51.319 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 27.451 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 64: 38.618 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 40.784 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 104: 66.410 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 30: 23.562 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 53.914 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 43.189 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 32: 26.319 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 47: 32.061 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 45.369 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 24: 22.358 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 45.079 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 67.160 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 59: 34.323 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 130: 56.593 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 51.665 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 28.228 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 36.444 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 105: 53.284 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 103: 49.962 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 33: 31.156 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 63.844 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 60: 35.507 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 28.135 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 63: 39.308 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 158: 73.028 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 123: 60.126 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 54.723 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 145: 80.642 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 50: 32.780 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 35.147 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 32: 23.975 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 74: 43.375 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 68: 42.321 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 45.619 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 32.322 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 34.770 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 18.413 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 28.729 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 85: 45.320 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 65.847 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 39.753 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 176: 86.528 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 141: 62.760 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 83: 43.653 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 231: 114.119 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 53.955 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 202: 86.820 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 28.929 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 15: 18.179 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 49.202 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 36.660 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 114: 60.864 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 153: 78.236 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 58.049 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 39.779 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 55.917 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 49.899 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 49.828 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 31.791 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 57.958 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 73: 42.807 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 121: 59.846 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 159: 80.729 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 51: 66.702 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 57.186 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 70: 47.272 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 50.561 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 40.438 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 24.285 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 27.664 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 104: 53.134 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 249: 143.768 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 46.355 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 79.745 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 203: 84.426 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 59.687 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 147: 79.152 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 42: 29.348 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 154: 75.564 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 192: 82.922 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 45.129 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 274: 148.704 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 72: 48.126 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 47.698 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 36.480 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 96: 52.118 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 41.086 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 29.639 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 32.862 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 124: 63.155 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 20.324 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 203: 94.351 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 56: 33.483 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 48.553 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 82: 51.566 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 45.484 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 74: 45.967 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 143: 64.523 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 36.570 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 157: 76.736 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 113: 65.449 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 163: 78.480 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 40.488 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 46.597 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 24: 23.960 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 137: 76.809 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 63: 48.027 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 102: 47.178 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 52: 34.597 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 39.737 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 89: 51.898 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 41.548 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 57: 36.340 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 95: 52.496 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 50.452 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 162: 83.172 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 32.842 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 26.745 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 58.776 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 188: 87.128 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 131: 62.597 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 59: 38.947 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 32.552 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 30.728 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 91: 45.857 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 35: 31.053 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 78: 43.484 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 47.422 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 44.936 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 19.983 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 156: 76.971 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 84: 44.341 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 93: 49.413 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 44.523 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 90: 48.373 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 106: 88.465 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 126: 60.657 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 386: 198.171 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 155: 75.211 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 37: 26.269 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 65: 40.431 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 71: 41.331 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 185.374 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 130: 66.445 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 32.403 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 94: 45.063 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 98: 48.317 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 66: 41.988 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 122: 73.998 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 49: 33.979 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 119: 68.804 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 55.686 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 44.598 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 46.536 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 60: 38.463 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 246: 116.654 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 42: 36.004 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 41: 34.828 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 88: 47.596 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 46: 30.308 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 49.425 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 48.972 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 136: 65.683 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 133: 66.954 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 142: 66.926 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 86: 56.573 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 110: 63.055 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 216: 120.178 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 54: 47.777 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 64: 39.591 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 40: 30.974 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 76: 43.922 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 42.661 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 80: 52.279 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 41.320 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 79: 41.382 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 43: 28.973 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 194: 127.016 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 31: 29.814 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 57.475 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 55: 34.994 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 37.200 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 59.767 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 158: 100.813 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 39: 32.482 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 45: 30.454 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 100: 50.624 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 125: 67.193 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 75: 39.884 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 61: 46.125 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 159: 87.067 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 97: 54.227 ms\n",
      "Loading: bert-base-uncased boolq\n"
     ]
    }
   ],
   "source": [
    "runs = 250\n",
    "data_set_name = \"boolq\"\n",
    "data = load_dataset(data_set_name, split=f\"validation[:{runs}]\")\n",
    "\n",
    "for i in range(5):\n",
    "    for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "        print(\"Loading: {} {}\".format(reader, adapter))\n",
    "        \n",
    "        #load base model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "        default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "        adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "        default_model.active_adapters = adapter_name\n",
    "\n",
    "        performance_log(adapter, reader, categorical_base_inference, \"Base\", default_model, tokenizer, data, data_set_name, 1) \n",
    "\n",
    "        #load quant model\n",
    "        quantized_base_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "        performance_log(adapter, reader, categorical_base_inference, \"Base Quantized\", quantized_base_model, tokenizer, data, data_set_name, 1) \n",
    "        \n",
    "        #load onnx models\n",
    "        model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "        onnx_models_list = load_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "        onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"ONNX Quantized\", \"ONNX-OPT Quantized\"]\n",
    "\n",
    "        # eval onnx models\n",
    "        for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "            performance_log(adapter, reader, categorical_onnx_inference, onnx_model_name, onnx_model, tokenizer, data, data_set_name, 1) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = pd.read_csv(\"square_skills/impl_skills.csv\")\n",
    "skill = \"multiple-choice\"\n",
    "skills = load_skills(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_model_inference(model, tokenizer, question, context, choices):\n",
    "    outputs = []\n",
    "    raw_input = [[context, question + \" \" + choice] for choice in choices]\n",
    "    inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    answer_idx = torch.argmax(outputs.logits)\n",
    "\n",
    "    return choices[answer_idx]\n",
    "\n",
    "def mc_onnx_inference(onnx_model, tokenizer, question, context, choices):\n",
    "\n",
    "    raw_input = [[context, question + \" \" + choice] for choice in choices]\n",
    "    inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"np\")\n",
    "\n",
    "    inputs['input_ids'] =  np.expand_dims(inputs['input_ids'], axis=0)\n",
    "    inputs['attention_mask'] =  np.expand_dims(inputs['attention_mask'], axis=0)\n",
    "\n",
    "    if \"token_type_ids\" in inputs: #roberta does not use this\n",
    "        inputs['token_type_ids'] = np.expand_dims(inputs['token_type_ids'], axis=0)\n",
    "\n",
    "    outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\n",
    "    answer_idx = np.argmax(outputs[0])\n",
    "    return choices[answer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_duration(func, model, tokenizer, question, context, choices): \n",
    "    st= time.time()\n",
    "    func(model, tokenizer, question, context, choices)\n",
    "    et = time.time()\n",
    "    return 1000 * (et - st)\n",
    "\n",
    "def save_df(df_new, path_to_logger_file = \"logger_all.csv\"):\n",
    "    if os.path.exists(path_to_logger_file):\n",
    "        df_fin = pd.concat([pd.read_csv(path_to_logger_file), df_new])\n",
    "        df_fin.to_csv(path_to_logger_file,index=False)\n",
    "    else: \n",
    "        df_new.to_csv(path_to_logger_file,index=False)\n",
    "\n",
    "def performance_log(adapter, reader, func, name, model, tokenizer, preped_data_set, data_set_name, data_intervall=1, run_amount=10): \n",
    "\n",
    "    for i in range(run_amount):\n",
    "        df = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"time once (ms)\", \"average_time 50 times (ms)\", \"seq_length\", \"context\", \"question\", \"choices\", \"data_id\", \"data_set_name\"])\n",
    "        \n",
    "        for i in range(0, len(preped_data_set), data_intervall):\n",
    "            question, context, choices = preped_data_set[i][0], preped_data_set[i][1], preped_data_set[i][2]\n",
    "            time_duration = get_time_duration(func, model, tokenizer, question, context, choices)\n",
    "            \n",
    "            seq_length = len(context.split()) # TODO -> reduce stopwords\n",
    "            \n",
    "            df.loc[len(df)] = [adapter, reader, name, time_duration, \"\", seq_length, context, question, choices, i, data_set_name]\n",
    "            \n",
    "            print(\"Model: {}, Input Length {}: {:.3f} ms\".format(name, seq_length, time_duration))\n",
    "        save_df(df, path_to_logger_file=\"inference_time_mcq_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased cosmos_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cosmos_qa (/Users/michaelhermann/.cache/huggingface/datasets/cosmos_qa/default/0.1.0/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: cosmos_qa\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3588.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 92: 426.945 ms\n",
      "Model: Base, Input Length 67: 250.775 ms\n",
      "Model: Base, Input Length 117: 504.971 ms\n",
      "Model: Base, Input Length 58: 332.886 ms\n",
      "Model: Base, Input Length 62: 292.247 ms\n",
      "Model: Base, Input Length 92: 342.463 ms\n",
      "Model: Base, Input Length 112: 514.830 ms\n",
      "Model: Base, Input Length 69: 278.529 ms\n",
      "Model: Base, Input Length 107: 589.166 ms\n",
      "Model: Base, Input Length 44: 255.814 ms\n",
      "Model: Base, Input Length 92: 390.713 ms\n",
      "Model: Base, Input Length 67: 277.638 ms\n",
      "Model: Base, Input Length 117: 577.551 ms\n",
      "Model: Base, Input Length 58: 307.321 ms\n",
      "Model: Base, Input Length 62: 307.414 ms\n",
      "Model: Base, Input Length 92: 365.235 ms\n",
      "Model: Base, Input Length 112: 531.736 ms\n",
      "Model: Base, Input Length 69: 260.557 ms\n",
      "Model: Base, Input Length 107: 432.058 ms\n",
      "Model: Base, Input Length 44: 276.357 ms\n",
      "Model: Base, Input Length 92: 325.536 ms\n",
      "Model: Base, Input Length 67: 276.707 ms\n",
      "Model: Base, Input Length 117: 546.486 ms\n",
      "Model: Base, Input Length 58: 288.886 ms\n",
      "Model: Base, Input Length 62: 278.826 ms\n",
      "Model: Base, Input Length 92: 389.427 ms\n",
      "Model: Base, Input Length 112: 463.801 ms\n",
      "Model: Base, Input Length 69: 263.056 ms\n",
      "Model: Base, Input Length 107: 534.641 ms\n",
      "Model: Base, Input Length 44: 281.513 ms\n",
      "Model: Base, Input Length 92: 344.611 ms\n",
      "Model: Base, Input Length 67: 274.249 ms\n",
      "Model: Base, Input Length 117: 529.625 ms\n",
      "Model: Base, Input Length 58: 250.700 ms\n",
      "Model: Base, Input Length 62: 250.889 ms\n",
      "Model: Base, Input Length 92: 318.579 ms\n",
      "Model: Base, Input Length 112: 392.469 ms\n",
      "Model: Base, Input Length 69: 269.532 ms\n",
      "Model: Base, Input Length 107: 404.731 ms\n",
      "Model: Base, Input Length 44: 239.761 ms\n",
      "Model: Base, Input Length 92: 405.206 ms\n",
      "Model: Base, Input Length 67: 262.864 ms\n",
      "Model: Base, Input Length 117: 607.219 ms\n",
      "Model: Base, Input Length 58: 309.589 ms\n",
      "Model: Base, Input Length 62: 319.764 ms\n",
      "Model: Base, Input Length 92: 371.680 ms\n",
      "Model: Base, Input Length 112: 498.626 ms\n",
      "Model: Base, Input Length 69: 290.937 ms\n",
      "Model: Base, Input Length 107: 459.046 ms\n",
      "Model: Base, Input Length 44: 241.618 ms\n",
      "Model: Base Quantized, Input Length 92: 359.981 ms\n",
      "Model: Base Quantized, Input Length 67: 210.739 ms\n",
      "Model: Base Quantized, Input Length 117: 399.086 ms\n",
      "Model: Base Quantized, Input Length 58: 217.321 ms\n",
      "Model: Base Quantized, Input Length 62: 225.513 ms\n",
      "Model: Base Quantized, Input Length 92: 302.827 ms\n",
      "Model: Base Quantized, Input Length 112: 473.415 ms\n",
      "Model: Base Quantized, Input Length 69: 304.176 ms\n",
      "Model: Base Quantized, Input Length 107: 504.125 ms\n",
      "Model: Base Quantized, Input Length 44: 287.987 ms\n",
      "Model: Base Quantized, Input Length 92: 415.940 ms\n",
      "Model: Base Quantized, Input Length 67: 285.583 ms\n",
      "Model: Base Quantized, Input Length 117: 517.182 ms\n",
      "Model: Base Quantized, Input Length 58: 266.154 ms\n",
      "Model: Base Quantized, Input Length 62: 240.916 ms\n",
      "Model: Base Quantized, Input Length 92: 311.260 ms\n",
      "Model: Base Quantized, Input Length 112: 352.741 ms\n",
      "Model: Base Quantized, Input Length 69: 205.780 ms\n",
      "Model: Base Quantized, Input Length 107: 371.300 ms\n",
      "Model: Base Quantized, Input Length 44: 225.944 ms\n",
      "Model: Base Quantized, Input Length 92: 376.084 ms\n",
      "Model: Base Quantized, Input Length 67: 301.748 ms\n",
      "Model: Base Quantized, Input Length 117: 536.777 ms\n",
      "Model: Base Quantized, Input Length 58: 320.101 ms\n",
      "Model: Base Quantized, Input Length 62: 293.169 ms\n",
      "Model: Base Quantized, Input Length 92: 377.057 ms\n",
      "Model: Base Quantized, Input Length 112: 401.806 ms\n",
      "Model: Base Quantized, Input Length 69: 266.939 ms\n",
      "Model: Base Quantized, Input Length 107: 501.029 ms\n",
      "Model: Base Quantized, Input Length 44: 235.227 ms\n",
      "Model: Base Quantized, Input Length 92: 408.093 ms\n",
      "Model: Base Quantized, Input Length 67: 292.997 ms\n",
      "Model: Base Quantized, Input Length 117: 478.145 ms\n",
      "Model: Base Quantized, Input Length 58: 303.501 ms\n",
      "Model: Base Quantized, Input Length 62: 262.359 ms\n",
      "Model: Base Quantized, Input Length 92: 397.452 ms\n",
      "Model: Base Quantized, Input Length 112: 482.958 ms\n",
      "Model: Base Quantized, Input Length 69: 279.898 ms\n",
      "Model: Base Quantized, Input Length 107: 466.827 ms\n",
      "Model: Base Quantized, Input Length 44: 259.581 ms\n",
      "Model: Base Quantized, Input Length 92: 339.697 ms\n",
      "Model: Base Quantized, Input Length 67: 263.066 ms\n",
      "Model: Base Quantized, Input Length 117: 520.541 ms\n",
      "Model: Base Quantized, Input Length 58: 290.982 ms\n",
      "Model: Base Quantized, Input Length 62: 310.310 ms\n",
      "Model: Base Quantized, Input Length 92: 378.728 ms\n",
      "Model: Base Quantized, Input Length 112: 449.438 ms\n",
      "Model: Base Quantized, Input Length 69: 311.987 ms\n",
      "Model: Base Quantized, Input Length 107: 509.045 ms\n",
      "Model: Base Quantized, Input Length 44: 297.872 ms\n",
      "Model: ONNX, Input Length 92: 194.124 ms\n",
      "Model: ONNX, Input Length 67: 149.987 ms\n",
      "Model: ONNX, Input Length 117: 293.507 ms\n",
      "Model: ONNX, Input Length 58: 211.826 ms\n",
      "Model: ONNX, Input Length 62: 260.407 ms\n",
      "Model: ONNX, Input Length 92: 277.615 ms\n",
      "Model: ONNX, Input Length 112: 330.991 ms\n",
      "Model: ONNX, Input Length 69: 218.816 ms\n",
      "Model: ONNX, Input Length 107: 344.835 ms\n",
      "Model: ONNX, Input Length 44: 261.347 ms\n",
      "Model: ONNX, Input Length 92: 304.478 ms\n",
      "Model: ONNX, Input Length 67: 203.650 ms\n",
      "Model: ONNX, Input Length 117: 375.615 ms\n",
      "Model: ONNX, Input Length 58: 284.794 ms\n",
      "Model: ONNX, Input Length 62: 239.247 ms\n",
      "Model: ONNX, Input Length 92: 314.780 ms\n",
      "Model: ONNX, Input Length 112: 366.988 ms\n",
      "Model: ONNX, Input Length 69: 227.191 ms\n",
      "Model: ONNX, Input Length 107: 374.674 ms\n",
      "Model: ONNX, Input Length 44: 199.002 ms\n",
      "Model: ONNX, Input Length 92: 269.625 ms\n",
      "Model: ONNX, Input Length 67: 206.773 ms\n",
      "Model: ONNX, Input Length 117: 410.245 ms\n",
      "Model: ONNX, Input Length 58: 238.876 ms\n",
      "Model: ONNX, Input Length 62: 242.383 ms\n",
      "Model: ONNX, Input Length 92: 336.821 ms\n",
      "Model: ONNX, Input Length 112: 362.483 ms\n",
      "Model: ONNX, Input Length 69: 215.307 ms\n",
      "Model: ONNX, Input Length 107: 390.733 ms\n",
      "Model: ONNX, Input Length 44: 200.496 ms\n",
      "Model: ONNX, Input Length 92: 276.393 ms\n",
      "Model: ONNX, Input Length 67: 206.152 ms\n",
      "Model: ONNX, Input Length 117: 395.864 ms\n",
      "Model: ONNX, Input Length 58: 232.063 ms\n",
      "Model: ONNX, Input Length 62: 191.853 ms\n",
      "Model: ONNX, Input Length 92: 272.858 ms\n",
      "Model: ONNX, Input Length 112: 359.676 ms\n",
      "Model: ONNX, Input Length 69: 217.658 ms\n",
      "Model: ONNX, Input Length 107: 361.980 ms\n",
      "Model: ONNX, Input Length 44: 178.032 ms\n",
      "Model: ONNX, Input Length 92: 299.598 ms\n",
      "Model: ONNX, Input Length 67: 173.171 ms\n",
      "Model: ONNX, Input Length 117: 304.540 ms\n",
      "Model: ONNX, Input Length 58: 173.483 ms\n",
      "Model: ONNX, Input Length 62: 166.046 ms\n",
      "Model: ONNX, Input Length 92: 272.819 ms\n",
      "Model: ONNX, Input Length 112: 352.363 ms\n",
      "Model: ONNX, Input Length 69: 154.224 ms\n",
      "Model: ONNX, Input Length 107: 263.260 ms\n",
      "Model: ONNX, Input Length 44: 147.899 ms\n",
      "Model: ONNX-OPT, Input Length 92: 243.512 ms\n",
      "Model: ONNX-OPT, Input Length 67: 222.326 ms\n",
      "Model: ONNX-OPT, Input Length 117: 400.179 ms\n",
      "Model: ONNX-OPT, Input Length 58: 253.340 ms\n",
      "Model: ONNX-OPT, Input Length 62: 243.311 ms\n",
      "Model: ONNX-OPT, Input Length 92: 317.375 ms\n",
      "Model: ONNX-OPT, Input Length 112: 422.149 ms\n",
      "Model: ONNX-OPT, Input Length 69: 234.943 ms\n",
      "Model: ONNX-OPT, Input Length 107: 389.153 ms\n",
      "Model: ONNX-OPT, Input Length 44: 240.179 ms\n",
      "Model: ONNX-OPT, Input Length 92: 366.655 ms\n",
      "Model: ONNX-OPT, Input Length 67: 186.911 ms\n",
      "Model: ONNX-OPT, Input Length 117: 370.417 ms\n",
      "Model: ONNX-OPT, Input Length 58: 270.975 ms\n",
      "Model: ONNX-OPT, Input Length 62: 264.945 ms\n",
      "Model: ONNX-OPT, Input Length 92: 325.112 ms\n",
      "Model: ONNX-OPT, Input Length 112: 404.557 ms\n",
      "Model: ONNX-OPT, Input Length 69: 264.558 ms\n",
      "Model: ONNX-OPT, Input Length 107: 378.794 ms\n",
      "Model: ONNX-OPT, Input Length 44: 217.381 ms\n",
      "Model: ONNX-OPT, Input Length 92: 322.023 ms\n",
      "Model: ONNX-OPT, Input Length 67: 242.717 ms\n",
      "Model: ONNX-OPT, Input Length 117: 429.781 ms\n",
      "Model: ONNX-OPT, Input Length 58: 200.640 ms\n",
      "Model: ONNX-OPT, Input Length 62: 184.924 ms\n",
      "Model: ONNX-OPT, Input Length 92: 251.886 ms\n",
      "Model: ONNX-OPT, Input Length 112: 328.934 ms\n",
      "Model: ONNX-OPT, Input Length 69: 252.374 ms\n",
      "Model: ONNX-OPT, Input Length 107: 387.569 ms\n",
      "Model: ONNX-OPT, Input Length 44: 228.427 ms\n",
      "Model: ONNX-OPT, Input Length 92: 320.239 ms\n",
      "Model: ONNX-OPT, Input Length 67: 228.714 ms\n",
      "Model: ONNX-OPT, Input Length 117: 393.701 ms\n",
      "Model: ONNX-OPT, Input Length 58: 161.155 ms\n",
      "Model: ONNX-OPT, Input Length 62: 154.645 ms\n",
      "Model: ONNX-OPT, Input Length 92: 226.050 ms\n",
      "Model: ONNX-OPT, Input Length 112: 245.031 ms\n",
      "Model: ONNX-OPT, Input Length 69: 148.003 ms\n",
      "Model: ONNX-OPT, Input Length 107: 261.666 ms\n",
      "Model: ONNX-OPT, Input Length 44: 150.960 ms\n",
      "Model: ONNX-OPT, Input Length 92: 210.789 ms\n",
      "Model: ONNX-OPT, Input Length 67: 174.608 ms\n",
      "Model: ONNX-OPT, Input Length 117: 398.039 ms\n",
      "Model: ONNX-OPT, Input Length 58: 232.250 ms\n",
      "Model: ONNX-OPT, Input Length 62: 222.440 ms\n",
      "Model: ONNX-OPT, Input Length 92: 244.373 ms\n",
      "Model: ONNX-OPT, Input Length 112: 271.756 ms\n",
      "Model: ONNX-OPT, Input Length 69: 149.217 ms\n",
      "Model: ONNX-OPT, Input Length 107: 267.982 ms\n",
      "Model: ONNX-OPT, Input Length 44: 144.659 ms\n",
      "Model: ONNX Quantized, Input Length 92: 232.042 ms\n",
      "Model: ONNX Quantized, Input Length 67: 157.033 ms\n",
      "Model: ONNX Quantized, Input Length 117: 316.664 ms\n",
      "Model: ONNX Quantized, Input Length 58: 154.662 ms\n",
      "Model: ONNX Quantized, Input Length 62: 136.331 ms\n",
      "Model: ONNX Quantized, Input Length 92: 179.388 ms\n",
      "Model: ONNX Quantized, Input Length 112: 226.879 ms\n",
      "Model: ONNX Quantized, Input Length 69: 117.440 ms\n",
      "Model: ONNX Quantized, Input Length 107: 206.719 ms\n",
      "Model: ONNX Quantized, Input Length 44: 129.974 ms\n",
      "Model: ONNX Quantized, Input Length 92: 211.354 ms\n",
      "Model: ONNX Quantized, Input Length 67: 155.571 ms\n",
      "Model: ONNX Quantized, Input Length 117: 292.511 ms\n",
      "Model: ONNX Quantized, Input Length 58: 127.241 ms\n",
      "Model: ONNX Quantized, Input Length 62: 128.544 ms\n",
      "Model: ONNX Quantized, Input Length 92: 205.951 ms\n",
      "Model: ONNX Quantized, Input Length 112: 291.301 ms\n",
      "Model: ONNX Quantized, Input Length 69: 205.772 ms\n",
      "Model: ONNX Quantized, Input Length 107: 260.831 ms\n",
      "Model: ONNX Quantized, Input Length 44: 158.176 ms\n",
      "Model: ONNX Quantized, Input Length 92: 214.276 ms\n",
      "Model: ONNX Quantized, Input Length 67: 209.374 ms\n",
      "Model: ONNX Quantized, Input Length 117: 356.340 ms\n",
      "Model: ONNX Quantized, Input Length 58: 165.531 ms\n",
      "Model: ONNX Quantized, Input Length 62: 163.445 ms\n",
      "Model: ONNX Quantized, Input Length 92: 212.111 ms\n",
      "Model: ONNX Quantized, Input Length 112: 261.773 ms\n",
      "Model: ONNX Quantized, Input Length 69: 148.833 ms\n",
      "Model: ONNX Quantized, Input Length 107: 275.429 ms\n",
      "Model: ONNX Quantized, Input Length 44: 144.560 ms\n",
      "Model: ONNX Quantized, Input Length 92: 211.764 ms\n",
      "Model: ONNX Quantized, Input Length 67: 146.745 ms\n",
      "Model: ONNX Quantized, Input Length 117: 285.192 ms\n",
      "Model: ONNX Quantized, Input Length 58: 108.624 ms\n",
      "Model: ONNX Quantized, Input Length 62: 110.977 ms\n",
      "Model: ONNX Quantized, Input Length 92: 167.810 ms\n",
      "Model: ONNX Quantized, Input Length 112: 223.728 ms\n",
      "Model: ONNX Quantized, Input Length 69: 99.082 ms\n",
      "Model: ONNX Quantized, Input Length 107: 192.374 ms\n",
      "Model: ONNX Quantized, Input Length 44: 100.269 ms\n",
      "Model: ONNX Quantized, Input Length 92: 149.500 ms\n",
      "Model: ONNX Quantized, Input Length 67: 99.931 ms\n",
      "Model: ONNX Quantized, Input Length 117: 211.128 ms\n",
      "Model: ONNX Quantized, Input Length 58: 149.160 ms\n",
      "Model: ONNX Quantized, Input Length 62: 159.590 ms\n",
      "Model: ONNX Quantized, Input Length 92: 199.498 ms\n",
      "Model: ONNX Quantized, Input Length 112: 251.865 ms\n",
      "Model: ONNX Quantized, Input Length 69: 148.716 ms\n",
      "Model: ONNX Quantized, Input Length 107: 311.001 ms\n",
      "Model: ONNX Quantized, Input Length 44: 165.428 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 244.123 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 141.867 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 276.771 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 168.660 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 249.300 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 226.133 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 267.700 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 165.696 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 282.874 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 185.579 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 210.764 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 149.378 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 350.729 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 186.359 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 172.384 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 227.367 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 264.313 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 156.215 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 276.077 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 157.508 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 207.303 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 142.041 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 273.765 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 174.605 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 281.625 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 214.458 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 265.375 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 151.965 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 260.586 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 143.891 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 186.971 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 137.077 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 262.041 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 146.619 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 145.703 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 193.757 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 202.184 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 117.235 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 235.814 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 141.051 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 256.074 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 150.253 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 274.364 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 162.589 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 166.187 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 210.693 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 266.433 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 158.388 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 271.292 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 154.733 ms\n",
      "Loading: roberta-base cosmos_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cosmos_qa (/Users/michaelhermann/.cache/huggingface/datasets/cosmos_qa/default/0.1.0/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: cosmos_qa\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 2562.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 92: 280.029 ms\n",
      "Model: Base, Input Length 67: 230.252 ms\n",
      "Model: Base, Input Length 117: 434.275 ms\n",
      "Model: Base, Input Length 58: 235.553 ms\n",
      "Model: Base, Input Length 62: 253.420 ms\n",
      "Model: Base, Input Length 92: 276.344 ms\n",
      "Model: Base, Input Length 112: 311.104 ms\n",
      "Model: Base, Input Length 69: 194.644 ms\n",
      "Model: Base, Input Length 107: 322.256 ms\n",
      "Model: Base, Input Length 44: 194.387 ms\n",
      "Model: Base, Input Length 92: 301.184 ms\n",
      "Model: Base, Input Length 67: 245.218 ms\n",
      "Model: Base, Input Length 117: 406.497 ms\n",
      "Model: Base, Input Length 58: 276.011 ms\n",
      "Model: Base, Input Length 62: 222.802 ms\n",
      "Model: Base, Input Length 92: 298.752 ms\n",
      "Model: Base, Input Length 112: 430.356 ms\n",
      "Model: Base, Input Length 69: 308.470 ms\n",
      "Model: Base, Input Length 107: 471.311 ms\n",
      "Model: Base, Input Length 44: 282.988 ms\n",
      "Model: Base, Input Length 92: 414.957 ms\n",
      "Model: Base, Input Length 67: 335.109 ms\n",
      "Model: Base, Input Length 117: 630.408 ms\n",
      "Model: Base, Input Length 58: 345.023 ms\n",
      "Model: Base, Input Length 62: 331.197 ms\n",
      "Model: Base, Input Length 92: 386.187 ms\n",
      "Model: Base, Input Length 112: 520.052 ms\n",
      "Model: Base, Input Length 69: 358.702 ms\n",
      "Model: Base, Input Length 107: 547.856 ms\n",
      "Model: Base, Input Length 44: 328.709 ms\n",
      "Model: Base, Input Length 92: 411.497 ms\n",
      "Model: Base, Input Length 67: 325.543 ms\n",
      "Model: Base, Input Length 117: 578.713 ms\n",
      "Model: Base, Input Length 58: 311.892 ms\n",
      "Model: Base, Input Length 62: 215.201 ms\n",
      "Model: Base, Input Length 92: 332.278 ms\n",
      "Model: Base, Input Length 112: 432.875 ms\n",
      "Model: Base, Input Length 69: 223.517 ms\n",
      "Model: Base, Input Length 107: 354.358 ms\n",
      "Model: Base, Input Length 44: 237.155 ms\n",
      "Model: Base, Input Length 92: 341.143 ms\n",
      "Model: Base, Input Length 67: 270.000 ms\n",
      "Model: Base, Input Length 117: 525.515 ms\n",
      "Model: Base, Input Length 58: 291.800 ms\n",
      "Model: Base, Input Length 62: 214.342 ms\n",
      "Model: Base, Input Length 92: 259.894 ms\n",
      "Model: Base, Input Length 112: 313.044 ms\n",
      "Model: Base, Input Length 69: 210.860 ms\n",
      "Model: Base, Input Length 107: 317.865 ms\n",
      "Model: Base, Input Length 44: 179.315 ms\n",
      "Model: Base Quantized, Input Length 92: 353.312 ms\n",
      "Model: Base Quantized, Input Length 67: 197.196 ms\n",
      "Model: Base Quantized, Input Length 117: 392.029 ms\n",
      "Model: Base Quantized, Input Length 58: 224.727 ms\n",
      "Model: Base Quantized, Input Length 62: 209.296 ms\n",
      "Model: Base Quantized, Input Length 92: 287.986 ms\n",
      "Model: Base Quantized, Input Length 112: 351.884 ms\n",
      "Model: Base Quantized, Input Length 69: 271.904 ms\n",
      "Model: Base Quantized, Input Length 107: 497.201 ms\n",
      "Model: Base Quantized, Input Length 44: 278.532 ms\n",
      "Model: Base Quantized, Input Length 92: 368.492 ms\n",
      "Model: Base Quantized, Input Length 67: 263.027 ms\n",
      "Model: Base Quantized, Input Length 117: 491.073 ms\n",
      "Model: Base Quantized, Input Length 58: 248.787 ms\n",
      "Model: Base Quantized, Input Length 62: 239.083 ms\n",
      "Model: Base Quantized, Input Length 92: 302.902 ms\n",
      "Model: Base Quantized, Input Length 112: 366.466 ms\n",
      "Model: Base Quantized, Input Length 69: 316.622 ms\n",
      "Model: Base Quantized, Input Length 107: 354.502 ms\n",
      "Model: Base Quantized, Input Length 44: 205.872 ms\n",
      "Model: Base Quantized, Input Length 92: 362.353 ms\n",
      "Model: Base Quantized, Input Length 67: 261.081 ms\n",
      "Model: Base Quantized, Input Length 117: 474.005 ms\n",
      "Model: Base Quantized, Input Length 58: 296.809 ms\n",
      "Model: Base Quantized, Input Length 62: 272.581 ms\n",
      "Model: Base Quantized, Input Length 92: 366.295 ms\n",
      "Model: Base Quantized, Input Length 112: 348.235 ms\n",
      "Model: Base Quantized, Input Length 69: 241.859 ms\n",
      "Model: Base Quantized, Input Length 107: 357.023 ms\n",
      "Model: Base Quantized, Input Length 44: 211.852 ms\n",
      "Model: Base Quantized, Input Length 92: 380.050 ms\n",
      "Model: Base Quantized, Input Length 67: 254.067 ms\n",
      "Model: Base Quantized, Input Length 117: 387.022 ms\n",
      "Model: Base Quantized, Input Length 58: 224.044 ms\n",
      "Model: Base Quantized, Input Length 62: 215.755 ms\n",
      "Model: Base Quantized, Input Length 92: 286.656 ms\n",
      "Model: Base Quantized, Input Length 112: 337.026 ms\n",
      "Model: Base Quantized, Input Length 69: 210.326 ms\n",
      "Model: Base Quantized, Input Length 107: 386.305 ms\n",
      "Model: Base Quantized, Input Length 44: 249.054 ms\n",
      "Model: Base Quantized, Input Length 92: 399.763 ms\n",
      "Model: Base Quantized, Input Length 67: 282.339 ms\n",
      "Model: Base Quantized, Input Length 117: 553.298 ms\n",
      "Model: Base Quantized, Input Length 58: 322.614 ms\n",
      "Model: Base Quantized, Input Length 62: 293.820 ms\n",
      "Model: Base Quantized, Input Length 92: 362.327 ms\n",
      "Model: Base Quantized, Input Length 112: 451.708 ms\n",
      "Model: Base Quantized, Input Length 69: 285.568 ms\n",
      "Model: Base Quantized, Input Length 107: 508.566 ms\n",
      "Model: Base Quantized, Input Length 44: 267.095 ms\n",
      "Model: ONNX, Input Length 92: 228.642 ms\n",
      "Model: ONNX, Input Length 67: 167.374 ms\n",
      "Model: ONNX, Input Length 117: 281.745 ms\n",
      "Model: ONNX, Input Length 58: 189.370 ms\n",
      "Model: ONNX, Input Length 62: 186.915 ms\n",
      "Model: ONNX, Input Length 92: 249.316 ms\n",
      "Model: ONNX, Input Length 112: 255.388 ms\n",
      "Model: ONNX, Input Length 69: 167.011 ms\n",
      "Model: ONNX, Input Length 107: 265.891 ms\n",
      "Model: ONNX, Input Length 44: 190.170 ms\n",
      "Model: ONNX, Input Length 92: 243.413 ms\n",
      "Model: ONNX, Input Length 67: 189.194 ms\n",
      "Model: ONNX, Input Length 117: 355.539 ms\n",
      "Model: ONNX, Input Length 58: 185.770 ms\n",
      "Model: ONNX, Input Length 62: 160.518 ms\n",
      "Model: ONNX, Input Length 92: 256.039 ms\n",
      "Model: ONNX, Input Length 112: 309.224 ms\n",
      "Model: ONNX, Input Length 69: 198.420 ms\n",
      "Model: ONNX, Input Length 107: 288.963 ms\n",
      "Model: ONNX, Input Length 44: 161.706 ms\n",
      "Model: ONNX, Input Length 92: 261.020 ms\n",
      "Model: ONNX, Input Length 67: 173.641 ms\n",
      "Model: ONNX, Input Length 117: 371.623 ms\n",
      "Model: ONNX, Input Length 58: 267.392 ms\n",
      "Model: ONNX, Input Length 62: 212.880 ms\n",
      "Model: ONNX, Input Length 92: 259.102 ms\n",
      "Model: ONNX, Input Length 112: 327.641 ms\n",
      "Model: ONNX, Input Length 69: 233.583 ms\n",
      "Model: ONNX, Input Length 107: 335.378 ms\n",
      "Model: ONNX, Input Length 44: 226.831 ms\n",
      "Model: ONNX, Input Length 92: 340.454 ms\n",
      "Model: ONNX, Input Length 67: 242.691 ms\n",
      "Model: ONNX, Input Length 117: 445.306 ms\n",
      "Model: ONNX, Input Length 58: 249.492 ms\n",
      "Model: ONNX, Input Length 62: 188.663 ms\n",
      "Model: ONNX, Input Length 92: 318.847 ms\n",
      "Model: ONNX, Input Length 112: 325.543 ms\n",
      "Model: ONNX, Input Length 69: 218.630 ms\n",
      "Model: ONNX, Input Length 107: 390.456 ms\n",
      "Model: ONNX, Input Length 44: 235.071 ms\n",
      "Model: ONNX, Input Length 92: 329.375 ms\n",
      "Model: ONNX, Input Length 67: 242.837 ms\n",
      "Model: ONNX, Input Length 117: 404.873 ms\n",
      "Model: ONNX, Input Length 58: 253.662 ms\n",
      "Model: ONNX, Input Length 62: 267.862 ms\n",
      "Model: ONNX, Input Length 92: 287.791 ms\n",
      "Model: ONNX, Input Length 112: 299.877 ms\n",
      "Model: ONNX, Input Length 69: 198.880 ms\n",
      "Model: ONNX, Input Length 107: 281.450 ms\n",
      "Model: ONNX, Input Length 44: 142.322 ms\n",
      "Model: ONNX-OPT, Input Length 92: 251.905 ms\n",
      "Model: ONNX-OPT, Input Length 67: 168.666 ms\n",
      "Model: ONNX-OPT, Input Length 117: 389.815 ms\n",
      "Model: ONNX-OPT, Input Length 58: 221.181 ms\n",
      "Model: ONNX-OPT, Input Length 62: 153.125 ms\n",
      "Model: ONNX-OPT, Input Length 92: 196.510 ms\n",
      "Model: ONNX-OPT, Input Length 112: 233.931 ms\n",
      "Model: ONNX-OPT, Input Length 69: 155.815 ms\n",
      "Model: ONNX-OPT, Input Length 107: 239.915 ms\n",
      "Model: ONNX-OPT, Input Length 44: 145.184 ms\n",
      "Model: ONNX-OPT, Input Length 92: 214.275 ms\n",
      "Model: ONNX-OPT, Input Length 67: 193.691 ms\n",
      "Model: ONNX-OPT, Input Length 117: 401.353 ms\n",
      "Model: ONNX-OPT, Input Length 58: 229.773 ms\n",
      "Model: ONNX-OPT, Input Length 62: 181.135 ms\n",
      "Model: ONNX-OPT, Input Length 92: 227.073 ms\n",
      "Model: ONNX-OPT, Input Length 112: 342.388 ms\n",
      "Model: ONNX-OPT, Input Length 69: 198.402 ms\n",
      "Model: ONNX-OPT, Input Length 107: 333.667 ms\n",
      "Model: ONNX-OPT, Input Length 44: 190.109 ms\n",
      "Model: ONNX-OPT, Input Length 92: 286.584 ms\n",
      "Model: ONNX-OPT, Input Length 67: 207.108 ms\n",
      "Model: ONNX-OPT, Input Length 117: 322.244 ms\n",
      "Model: ONNX-OPT, Input Length 58: 185.818 ms\n",
      "Model: ONNX-OPT, Input Length 62: 221.642 ms\n",
      "Model: ONNX-OPT, Input Length 92: 213.201 ms\n",
      "Model: ONNX-OPT, Input Length 112: 256.533 ms\n",
      "Model: ONNX-OPT, Input Length 69: 284.009 ms\n",
      "Model: ONNX-OPT, Input Length 107: 294.252 ms\n",
      "Model: ONNX-OPT, Input Length 44: 145.842 ms\n",
      "Model: ONNX-OPT, Input Length 92: 277.588 ms\n",
      "Model: ONNX-OPT, Input Length 67: 202.321 ms\n",
      "Model: ONNX-OPT, Input Length 117: 460.651 ms\n",
      "Model: ONNX-OPT, Input Length 58: 191.348 ms\n",
      "Model: ONNX-OPT, Input Length 62: 218.220 ms\n",
      "Model: ONNX-OPT, Input Length 92: 282.351 ms\n",
      "Model: ONNX-OPT, Input Length 112: 330.114 ms\n",
      "Model: ONNX-OPT, Input Length 69: 226.932 ms\n",
      "Model: ONNX-OPT, Input Length 107: 349.768 ms\n",
      "Model: ONNX-OPT, Input Length 44: 206.134 ms\n",
      "Model: ONNX-OPT, Input Length 92: 317.908 ms\n",
      "Model: ONNX-OPT, Input Length 67: 148.092 ms\n",
      "Model: ONNX-OPT, Input Length 117: 285.080 ms\n",
      "Model: ONNX-OPT, Input Length 58: 198.861 ms\n",
      "Model: ONNX-OPT, Input Length 62: 210.546 ms\n",
      "Model: ONNX-OPT, Input Length 92: 263.708 ms\n",
      "Model: ONNX-OPT, Input Length 112: 237.815 ms\n",
      "Model: ONNX-OPT, Input Length 69: 143.609 ms\n",
      "Model: ONNX-OPT, Input Length 107: 234.346 ms\n",
      "Model: ONNX-OPT, Input Length 44: 136.414 ms\n",
      "Model: ONNX Quantized, Input Length 92: 165.769 ms\n",
      "Model: ONNX Quantized, Input Length 67: 134.900 ms\n",
      "Model: ONNX Quantized, Input Length 117: 275.938 ms\n",
      "Model: ONNX Quantized, Input Length 58: 152.559 ms\n",
      "Model: ONNX Quantized, Input Length 62: 113.358 ms\n",
      "Model: ONNX Quantized, Input Length 92: 169.961 ms\n",
      "Model: ONNX Quantized, Input Length 112: 187.254 ms\n",
      "Model: ONNX Quantized, Input Length 69: 114.021 ms\n",
      "Model: ONNX Quantized, Input Length 107: 181.772 ms\n",
      "Model: ONNX Quantized, Input Length 44: 101.760 ms\n",
      "Model: ONNX Quantized, Input Length 92: 149.962 ms\n",
      "Model: ONNX Quantized, Input Length 67: 104.014 ms\n",
      "Model: ONNX Quantized, Input Length 117: 207.011 ms\n",
      "Model: ONNX Quantized, Input Length 58: 112.921 ms\n",
      "Model: ONNX Quantized, Input Length 62: 124.073 ms\n",
      "Model: ONNX Quantized, Input Length 92: 168.843 ms\n",
      "Model: ONNX Quantized, Input Length 112: 241.833 ms\n",
      "Model: ONNX Quantized, Input Length 69: 151.428 ms\n",
      "Model: ONNX Quantized, Input Length 107: 190.070 ms\n",
      "Model: ONNX Quantized, Input Length 44: 105.024 ms\n",
      "Model: ONNX Quantized, Input Length 92: 142.665 ms\n",
      "Model: ONNX Quantized, Input Length 67: 120.622 ms\n",
      "Model: ONNX Quantized, Input Length 117: 272.523 ms\n",
      "Model: ONNX Quantized, Input Length 58: 155.059 ms\n",
      "Model: ONNX Quantized, Input Length 62: 122.968 ms\n",
      "Model: ONNX Quantized, Input Length 92: 159.651 ms\n",
      "Model: ONNX Quantized, Input Length 112: 211.444 ms\n",
      "Model: ONNX Quantized, Input Length 69: 167.092 ms\n",
      "Model: ONNX Quantized, Input Length 107: 232.727 ms\n",
      "Model: ONNX Quantized, Input Length 44: 148.881 ms\n",
      "Model: ONNX Quantized, Input Length 92: 157.317 ms\n",
      "Model: ONNX Quantized, Input Length 67: 123.162 ms\n",
      "Model: ONNX Quantized, Input Length 117: 245.474 ms\n",
      "Model: ONNX Quantized, Input Length 58: 133.489 ms\n",
      "Model: ONNX Quantized, Input Length 62: 141.456 ms\n",
      "Model: ONNX Quantized, Input Length 92: 155.036 ms\n",
      "Model: ONNX Quantized, Input Length 112: 182.936 ms\n",
      "Model: ONNX Quantized, Input Length 69: 119.049 ms\n",
      "Model: ONNX Quantized, Input Length 107: 244.026 ms\n",
      "Model: ONNX Quantized, Input Length 44: 142.034 ms\n",
      "Model: ONNX Quantized, Input Length 92: 200.256 ms\n",
      "Model: ONNX Quantized, Input Length 67: 139.349 ms\n",
      "Model: ONNX Quantized, Input Length 117: 273.128 ms\n",
      "Model: ONNX Quantized, Input Length 58: 161.786 ms\n",
      "Model: ONNX Quantized, Input Length 62: 162.593 ms\n",
      "Model: ONNX Quantized, Input Length 92: 191.300 ms\n",
      "Model: ONNX Quantized, Input Length 112: 232.052 ms\n",
      "Model: ONNX Quantized, Input Length 69: 116.327 ms\n",
      "Model: ONNX Quantized, Input Length 107: 239.027 ms\n",
      "Model: ONNX Quantized, Input Length 44: 108.896 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 194.418 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 133.465 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 267.156 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 130.632 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 120.473 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 179.544 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 238.297 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 141.571 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 184.882 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 132.440 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 192.372 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 134.089 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 272.010 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 153.499 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 118.578 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 154.329 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 172.357 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 111.406 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 231.272 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 141.573 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 179.457 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 125.718 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 268.735 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 213.991 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 149.570 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 196.765 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 252.178 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 161.232 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 245.015 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 141.947 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 194.283 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 141.038 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 288.741 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 161.121 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 158.970 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 195.621 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 236.094 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 137.741 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 240.333 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 145.825 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 202.553 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 67: 137.717 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 117: 281.790 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 58: 150.631 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 62: 149.875 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 92: 188.331 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 112: 241.033 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 69: 160.433 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 107: 257.742 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 44: 143.639 ms\n",
      "Loading: bert-base-uncased multirc\n",
      "Loading: roberta-base multirc\n",
      "Loading: bert-base-uncased quail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset quail (/Users/michaelhermann/.cache/huggingface/datasets/quail/quail/1.3.0/3cabab19c99e571b528209e14313cfff1debf772db9e24e19b4fcbeb8399336c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: quail\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3010.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 310: 1303.256 ms\n",
      "Model: Base, Input Length 310: 1402.113 ms\n",
      "Model: Base, Input Length 320: 1502.304 ms\n",
      "Model: Base, Input Length 320: 1674.653 ms\n",
      "Model: Base, Input Length 325: 1854.459 ms\n",
      "Model: Base, Input Length 325: 1935.818 ms\n",
      "Model: Base, Input Length 278: 1680.534 ms\n",
      "Model: Base, Input Length 278: 1635.078 ms\n",
      "Model: Base, Input Length 313: 1725.402 ms\n",
      "Model: Base, Input Length 313: 1642.391 ms\n",
      "Model: Base, Input Length 310: 1504.776 ms\n",
      "Model: Base, Input Length 310: 1486.798 ms\n",
      "Model: Base, Input Length 320: 1594.606 ms\n",
      "Model: Base, Input Length 320: 1690.476 ms\n",
      "Model: Base, Input Length 325: 1791.503 ms\n",
      "Model: Base, Input Length 325: 1867.741 ms\n",
      "Model: Base, Input Length 278: 1486.974 ms\n",
      "Model: Base, Input Length 278: 1639.316 ms\n",
      "Model: Base, Input Length 313: 1830.416 ms\n",
      "Model: Base, Input Length 313: 1582.012 ms\n",
      "Model: Base, Input Length 310: 1745.011 ms\n",
      "Model: Base, Input Length 310: 1724.833 ms\n",
      "Model: Base, Input Length 320: 1847.859 ms\n",
      "Model: Base, Input Length 320: 1907.717 ms\n",
      "Model: Base, Input Length 325: 1911.394 ms\n",
      "Model: Base, Input Length 325: 1968.420 ms\n",
      "Model: Base, Input Length 278: 1755.595 ms\n",
      "Model: Base, Input Length 278: 1712.818 ms\n",
      "Model: Base, Input Length 313: 1858.014 ms\n",
      "Model: Base, Input Length 313: 1783.177 ms\n",
      "Model: Base, Input Length 310: 1786.503 ms\n",
      "Model: Base, Input Length 310: 1728.568 ms\n",
      "Model: Base, Input Length 320: 1835.720 ms\n",
      "Model: Base, Input Length 320: 1853.035 ms\n",
      "Model: Base, Input Length 325: 1973.526 ms\n",
      "Model: Base, Input Length 325: 1976.365 ms\n",
      "Model: Base, Input Length 278: 1704.013 ms\n",
      "Model: Base, Input Length 278: 1656.538 ms\n",
      "Model: Base, Input Length 313: 1796.364 ms\n",
      "Model: Base, Input Length 313: 1811.186 ms\n",
      "Model: Base, Input Length 310: 1786.709 ms\n",
      "Model: Base, Input Length 310: 1653.075 ms\n",
      "Model: Base, Input Length 320: 1890.256 ms\n",
      "Model: Base, Input Length 320: 1844.582 ms\n",
      "Model: Base, Input Length 325: 1869.330 ms\n",
      "Model: Base, Input Length 325: 1939.795 ms\n",
      "Model: Base, Input Length 278: 1645.250 ms\n",
      "Model: Base, Input Length 278: 1607.213 ms\n",
      "Model: Base, Input Length 313: 1738.396 ms\n",
      "Model: Base, Input Length 313: 1830.869 ms\n",
      "Model: Base Quantized, Input Length 310: 1769.960 ms\n",
      "Model: Base Quantized, Input Length 310: 1570.313 ms\n",
      "Model: Base Quantized, Input Length 320: 1890.115 ms\n",
      "Model: Base Quantized, Input Length 320: 1782.035 ms\n",
      "Model: Base Quantized, Input Length 325: 1851.672 ms\n",
      "Model: Base Quantized, Input Length 325: 1734.936 ms\n",
      "Model: Base Quantized, Input Length 278: 1630.830 ms\n",
      "Model: Base Quantized, Input Length 278: 1778.671 ms\n",
      "Model: Base Quantized, Input Length 313: 1701.969 ms\n",
      "Model: Base Quantized, Input Length 313: 1914.122 ms\n",
      "Model: Base Quantized, Input Length 310: 1825.550 ms\n",
      "Model: Base Quantized, Input Length 310: 1808.113 ms\n",
      "Model: Base Quantized, Input Length 320: 2009.120 ms\n",
      "Model: Base Quantized, Input Length 320: 1900.438 ms\n",
      "Model: Base Quantized, Input Length 325: 1969.426 ms\n",
      "Model: Base Quantized, Input Length 325: 2017.450 ms\n",
      "Model: Base Quantized, Input Length 278: 1904.645 ms\n",
      "Model: Base Quantized, Input Length 278: 1784.176 ms\n",
      "Model: Base Quantized, Input Length 313: 2041.854 ms\n",
      "Model: Base Quantized, Input Length 313: 1975.114 ms\n",
      "Model: Base Quantized, Input Length 310: 1997.900 ms\n",
      "Model: Base Quantized, Input Length 310: 1756.445 ms\n",
      "Model: Base Quantized, Input Length 320: 1609.581 ms\n",
      "Model: Base Quantized, Input Length 320: 1677.156 ms\n",
      "Model: Base Quantized, Input Length 325: 1708.690 ms\n",
      "Model: Base Quantized, Input Length 325: 1779.085 ms\n",
      "Model: Base Quantized, Input Length 278: 1454.974 ms\n",
      "Model: Base Quantized, Input Length 278: 1488.330 ms\n",
      "Model: Base Quantized, Input Length 313: 1573.320 ms\n",
      "Model: Base Quantized, Input Length 313: 1636.117 ms\n",
      "Model: Base Quantized, Input Length 310: 1623.540 ms\n",
      "Model: Base Quantized, Input Length 310: 1518.171 ms\n",
      "Model: Base Quantized, Input Length 320: 1631.544 ms\n",
      "Model: Base Quantized, Input Length 320: 1921.168 ms\n",
      "Model: Base Quantized, Input Length 325: 1950.147 ms\n",
      "Model: Base Quantized, Input Length 325: 1892.749 ms\n",
      "Model: Base Quantized, Input Length 278: 1625.016 ms\n",
      "Model: Base Quantized, Input Length 278: 1597.520 ms\n",
      "Model: Base Quantized, Input Length 313: 1615.080 ms\n",
      "Model: Base Quantized, Input Length 313: 1607.287 ms\n",
      "Model: Base Quantized, Input Length 310: 1695.914 ms\n",
      "Model: Base Quantized, Input Length 310: 1757.654 ms\n",
      "Model: Base Quantized, Input Length 320: 1785.727 ms\n",
      "Model: Base Quantized, Input Length 320: 1818.073 ms\n",
      "Model: Base Quantized, Input Length 325: 1988.255 ms\n",
      "Model: Base Quantized, Input Length 325: 1871.492 ms\n",
      "Model: Base Quantized, Input Length 278: 1589.423 ms\n",
      "Model: Base Quantized, Input Length 278: 1799.517 ms\n",
      "Model: Base Quantized, Input Length 313: 1788.977 ms\n",
      "Model: Base Quantized, Input Length 313: 1810.889 ms\n",
      "Model: ONNX, Input Length 310: 977.581 ms\n",
      "Model: ONNX, Input Length 310: 1106.659 ms\n",
      "Model: ONNX, Input Length 320: 1072.991 ms\n",
      "Model: ONNX, Input Length 320: 1196.381 ms\n",
      "Model: ONNX, Input Length 325: 1111.258 ms\n",
      "Model: ONNX, Input Length 325: 1145.640 ms\n",
      "Model: ONNX, Input Length 278: 1099.202 ms\n",
      "Model: ONNX, Input Length 278: 1233.365 ms\n",
      "Model: ONNX, Input Length 313: 1183.143 ms\n",
      "Model: ONNX, Input Length 313: 1194.614 ms\n",
      "Model: ONNX, Input Length 310: 1264.861 ms\n",
      "Model: ONNX, Input Length 310: 1146.116 ms\n",
      "Model: ONNX, Input Length 320: 1108.908 ms\n",
      "Model: ONNX, Input Length 320: 1079.041 ms\n",
      "Model: ONNX, Input Length 325: 1161.011 ms\n",
      "Model: ONNX, Input Length 325: 1181.689 ms\n",
      "Model: ONNX, Input Length 278: 1122.940 ms\n",
      "Model: ONNX, Input Length 278: 1133.514 ms\n",
      "Model: ONNX, Input Length 313: 1515.331 ms\n",
      "Model: ONNX, Input Length 313: 1327.316 ms\n",
      "Model: ONNX, Input Length 310: 1188.799 ms\n",
      "Model: ONNX, Input Length 310: 1251.238 ms\n",
      "Model: ONNX, Input Length 320: 1094.265 ms\n",
      "Model: ONNX, Input Length 320: 1158.932 ms\n",
      "Model: ONNX, Input Length 325: 1229.498 ms\n",
      "Model: ONNX, Input Length 325: 1274.560 ms\n",
      "Model: ONNX, Input Length 278: 1117.267 ms\n",
      "Model: ONNX, Input Length 278: 1341.393 ms\n",
      "Model: ONNX, Input Length 313: 1051.572 ms\n",
      "Model: ONNX, Input Length 313: 1128.819 ms\n",
      "Model: ONNX, Input Length 310: 1217.259 ms\n",
      "Model: ONNX, Input Length 310: 1114.431 ms\n",
      "Model: ONNX, Input Length 320: 1053.139 ms\n",
      "Model: ONNX, Input Length 320: 1209.987 ms\n",
      "Model: ONNX, Input Length 325: 1225.443 ms\n",
      "Model: ONNX, Input Length 325: 1295.334 ms\n",
      "Model: ONNX, Input Length 278: 1069.203 ms\n",
      "Model: ONNX, Input Length 278: 1210.888 ms\n",
      "Model: ONNX, Input Length 313: 1262.218 ms\n",
      "Model: ONNX, Input Length 313: 1275.610 ms\n",
      "Model: ONNX, Input Length 310: 1022.175 ms\n",
      "Model: ONNX, Input Length 310: 1222.559 ms\n",
      "Model: ONNX, Input Length 320: 1055.836 ms\n",
      "Model: ONNX, Input Length 320: 1167.922 ms\n",
      "Model: ONNX, Input Length 325: 1207.667 ms\n",
      "Model: ONNX, Input Length 325: 1372.070 ms\n",
      "Model: ONNX, Input Length 278: 1237.189 ms\n",
      "Model: ONNX, Input Length 278: 1362.184 ms\n",
      "Model: ONNX, Input Length 313: 1177.699 ms\n",
      "Model: ONNX, Input Length 313: 1176.334 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1069.625 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1151.133 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1112.595 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1086.033 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1075.104 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1033.733 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1031.425 ms\n",
      "Model: ONNX-OPT, Input Length 278: 949.748 ms\n",
      "Model: ONNX-OPT, Input Length 313: 935.170 ms\n",
      "Model: ONNX-OPT, Input Length 313: 963.804 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1056.824 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1187.647 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1139.665 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1227.510 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1291.549 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1390.891 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1135.531 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1189.651 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1348.318 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1335.744 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1341.116 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1182.180 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1342.207 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1383.096 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1299.769 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1248.247 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1027.641 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1189.677 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1118.308 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1277.243 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1376.821 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1282.658 ms\n",
      "Model: ONNX-OPT, Input Length 320: 3927.579 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1497.639 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1415.894 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1419.583 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1356.223 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1421.359 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1454.804 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1404.025 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1377.543 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1370.532 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1379.563 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1395.632 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1561.859 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1502.640 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1286.350 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1292.468 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1277.535 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1400.637 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1168.483 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1061.348 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1022.343 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1157.315 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1097.636 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1186.174 ms\n",
      "Model: ONNX Quantized, Input Length 278: 986.989 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1060.524 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1055.844 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1025.126 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1013.805 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1040.480 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1019.680 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1100.428 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1185.401 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1111.543 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1032.562 ms\n",
      "Model: ONNX Quantized, Input Length 278: 956.233 ms\n",
      "Model: ONNX Quantized, Input Length 313: 923.855 ms\n",
      "Model: ONNX Quantized, Input Length 313: 936.544 ms\n",
      "Model: ONNX Quantized, Input Length 310: 944.905 ms\n",
      "Model: ONNX Quantized, Input Length 310: 844.771 ms\n",
      "Model: ONNX Quantized, Input Length 320: 842.079 ms\n",
      "Model: ONNX Quantized, Input Length 320: 862.879 ms\n",
      "Model: ONNX Quantized, Input Length 325: 862.166 ms\n",
      "Model: ONNX Quantized, Input Length 325: 915.780 ms\n",
      "Model: ONNX Quantized, Input Length 278: 770.871 ms\n",
      "Model: ONNX Quantized, Input Length 278: 738.872 ms\n",
      "Model: ONNX Quantized, Input Length 313: 767.132 ms\n",
      "Model: ONNX Quantized, Input Length 313: 808.464 ms\n",
      "Model: ONNX Quantized, Input Length 310: 860.357 ms\n",
      "Model: ONNX Quantized, Input Length 310: 751.340 ms\n",
      "Model: ONNX Quantized, Input Length 320: 764.242 ms\n",
      "Model: ONNX Quantized, Input Length 320: 761.298 ms\n",
      "Model: ONNX Quantized, Input Length 325: 812.437 ms\n",
      "Model: ONNX Quantized, Input Length 325: 804.237 ms\n",
      "Model: ONNX Quantized, Input Length 278: 760.037 ms\n",
      "Model: ONNX Quantized, Input Length 278: 724.915 ms\n",
      "Model: ONNX Quantized, Input Length 313: 741.280 ms\n",
      "Model: ONNX Quantized, Input Length 313: 774.625 ms\n",
      "Model: ONNX Quantized, Input Length 310: 870.810 ms\n",
      "Model: ONNX Quantized, Input Length 310: 773.788 ms\n",
      "Model: ONNX Quantized, Input Length 320: 753.035 ms\n",
      "Model: ONNX Quantized, Input Length 320: 749.627 ms\n",
      "Model: ONNX Quantized, Input Length 325: 798.318 ms\n",
      "Model: ONNX Quantized, Input Length 325: 812.611 ms\n",
      "Model: ONNX Quantized, Input Length 278: 717.626 ms\n",
      "Model: ONNX Quantized, Input Length 278: 711.161 ms\n",
      "Model: ONNX Quantized, Input Length 313: 737.191 ms\n",
      "Model: ONNX Quantized, Input Length 313: 741.889 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 798.749 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 815.587 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 757.012 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 763.052 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 804.079 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 819.206 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 713.361 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 710.664 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 723.960 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 719.169 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 818.727 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 763.086 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 732.201 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 749.902 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 777.822 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 864.446 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 740.922 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 725.072 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 730.298 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 795.898 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 884.933 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 712.638 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 722.727 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 745.040 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 791.170 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 875.683 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 803.627 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 720.766 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 717.875 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 735.890 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 818.186 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 736.359 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 754.758 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 753.843 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 807.566 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 805.903 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 720.406 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 714.264 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 735.742 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 747.980 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 871.124 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 791.892 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 746.369 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 751.239 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 805.606 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 801.944 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 715.389 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 713.017 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 738.165 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 761.077 ms\n",
      "Loading: roberta-base quail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset quail (/Users/michaelhermann/.cache/huggingface/datasets/quail/quail/1.3.0/3cabab19c99e571b528209e14313cfff1debf772db9e24e19b4fcbeb8399336c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: quail\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4319.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 310: 1404.750 ms\n",
      "Model: Base, Input Length 310: 1334.878 ms\n",
      "Model: Base, Input Length 320: 1241.838 ms\n",
      "Model: Base, Input Length 320: 1235.162 ms\n",
      "Model: Base, Input Length 325: 1366.376 ms\n",
      "Model: Base, Input Length 325: 1482.925 ms\n",
      "Model: Base, Input Length 278: 1269.972 ms\n",
      "Model: Base, Input Length 278: 1279.464 ms\n",
      "Model: Base, Input Length 313: 1277.459 ms\n",
      "Model: Base, Input Length 313: 1303.000 ms\n",
      "Model: Base, Input Length 310: 1381.914 ms\n",
      "Model: Base, Input Length 310: 1483.488 ms\n",
      "Model: Base, Input Length 320: 1535.306 ms\n",
      "Model: Base, Input Length 320: 1498.500 ms\n",
      "Model: Base, Input Length 325: 1583.278 ms\n",
      "Model: Base, Input Length 325: 1775.756 ms\n",
      "Model: Base, Input Length 278: 1561.959 ms\n",
      "Model: Base, Input Length 278: 1557.847 ms\n",
      "Model: Base, Input Length 313: 1587.280 ms\n",
      "Model: Base, Input Length 313: 1710.099 ms\n",
      "Model: Base, Input Length 310: 1688.143 ms\n",
      "Model: Base, Input Length 310: 1847.453 ms\n",
      "Model: Base, Input Length 320: 4352.211 ms\n",
      "Model: Base, Input Length 320: 2530.828 ms\n",
      "Model: Base, Input Length 325: 2206.564 ms\n",
      "Model: Base, Input Length 325: 2064.966 ms\n",
      "Model: Base, Input Length 278: 1664.341 ms\n",
      "Model: Base, Input Length 278: 1697.947 ms\n",
      "Model: Base, Input Length 313: 1665.468 ms\n",
      "Model: Base, Input Length 313: 1611.677 ms\n",
      "Model: Base, Input Length 310: 1741.608 ms\n",
      "Model: Base, Input Length 310: 1676.127 ms\n",
      "Model: Base, Input Length 320: 1701.272 ms\n",
      "Model: Base, Input Length 320: 1631.659 ms\n",
      "Model: Base, Input Length 325: 1707.861 ms\n",
      "Model: Base, Input Length 325: 1723.679 ms\n",
      "Model: Base, Input Length 278: 1486.317 ms\n",
      "Model: Base, Input Length 278: 1482.618 ms\n",
      "Model: Base, Input Length 313: 1498.809 ms\n",
      "Model: Base, Input Length 313: 1415.209 ms\n",
      "Model: Base, Input Length 310: 1625.782 ms\n",
      "Model: Base, Input Length 310: 1643.160 ms\n",
      "Model: Base, Input Length 320: 1458.260 ms\n",
      "Model: Base, Input Length 320: 1471.888 ms\n",
      "Model: Base, Input Length 325: 1518.784 ms\n",
      "Model: Base, Input Length 325: 1631.585 ms\n",
      "Model: Base, Input Length 278: 1358.740 ms\n",
      "Model: Base, Input Length 278: 1373.836 ms\n",
      "Model: Base, Input Length 313: 1391.044 ms\n",
      "Model: Base, Input Length 313: 1435.270 ms\n",
      "Model: Base Quantized, Input Length 310: 1526.646 ms\n",
      "Model: Base Quantized, Input Length 310: 1413.324 ms\n",
      "Model: Base Quantized, Input Length 320: 1475.073 ms\n",
      "Model: Base Quantized, Input Length 320: 1582.205 ms\n",
      "Model: Base Quantized, Input Length 325: 1536.916 ms\n",
      "Model: Base Quantized, Input Length 325: 1573.315 ms\n",
      "Model: Base Quantized, Input Length 278: 1354.569 ms\n",
      "Model: Base Quantized, Input Length 278: 1468.147 ms\n",
      "Model: Base Quantized, Input Length 313: 1420.015 ms\n",
      "Model: Base Quantized, Input Length 313: 1495.331 ms\n",
      "Model: Base Quantized, Input Length 310: 1555.331 ms\n",
      "Model: Base Quantized, Input Length 310: 1467.554 ms\n",
      "Model: Base Quantized, Input Length 320: 1456.487 ms\n",
      "Model: Base Quantized, Input Length 320: 1495.446 ms\n",
      "Model: Base Quantized, Input Length 325: 1598.956 ms\n",
      "Model: Base Quantized, Input Length 325: 1625.282 ms\n",
      "Model: Base Quantized, Input Length 278: 1417.174 ms\n",
      "Model: Base Quantized, Input Length 278: 1366.380 ms\n",
      "Model: Base Quantized, Input Length 313: 1480.168 ms\n",
      "Model: Base Quantized, Input Length 313: 1414.337 ms\n",
      "Model: Base Quantized, Input Length 310: 1625.798 ms\n",
      "Model: Base Quantized, Input Length 310: 1513.946 ms\n",
      "Model: Base Quantized, Input Length 320: 1487.712 ms\n",
      "Model: Base Quantized, Input Length 320: 1531.767 ms\n",
      "Model: Base Quantized, Input Length 325: 1519.293 ms\n",
      "Model: Base Quantized, Input Length 325: 1621.672 ms\n",
      "Model: Base Quantized, Input Length 278: 1434.863 ms\n",
      "Model: Base Quantized, Input Length 278: 1418.418 ms\n",
      "Model: Base Quantized, Input Length 313: 1453.415 ms\n",
      "Model: Base Quantized, Input Length 313: 1421.165 ms\n",
      "Model: Base Quantized, Input Length 310: 1575.364 ms\n",
      "Model: Base Quantized, Input Length 310: 1430.583 ms\n",
      "Model: Base Quantized, Input Length 320: 1464.672 ms\n",
      "Model: Base Quantized, Input Length 320: 1446.503 ms\n",
      "Model: Base Quantized, Input Length 325: 1546.545 ms\n",
      "Model: Base Quantized, Input Length 325: 1513.114 ms\n",
      "Model: Base Quantized, Input Length 278: 1287.258 ms\n",
      "Model: Base Quantized, Input Length 278: 1380.280 ms\n",
      "Model: Base Quantized, Input Length 313: 1394.181 ms\n",
      "Model: Base Quantized, Input Length 313: 1347.872 ms\n",
      "Model: Base Quantized, Input Length 310: 1481.482 ms\n",
      "Model: Base Quantized, Input Length 310: 1454.211 ms\n",
      "Model: Base Quantized, Input Length 320: 1395.171 ms\n",
      "Model: Base Quantized, Input Length 320: 1494.834 ms\n",
      "Model: Base Quantized, Input Length 325: 1551.853 ms\n",
      "Model: Base Quantized, Input Length 325: 1566.448 ms\n",
      "Model: Base Quantized, Input Length 278: 1405.226 ms\n",
      "Model: Base Quantized, Input Length 278: 1382.406 ms\n",
      "Model: Base Quantized, Input Length 313: 1485.240 ms\n",
      "Model: Base Quantized, Input Length 313: 1391.766 ms\n",
      "Model: ONNX, Input Length 310: 802.335 ms\n",
      "Model: ONNX, Input Length 310: 794.614 ms\n",
      "Model: ONNX, Input Length 320: 798.281 ms\n",
      "Model: ONNX, Input Length 320: 864.718 ms\n",
      "Model: ONNX, Input Length 325: 864.571 ms\n",
      "Model: ONNX, Input Length 325: 861.921 ms\n",
      "Model: ONNX, Input Length 278: 755.526 ms\n",
      "Model: ONNX, Input Length 278: 803.709 ms\n",
      "Model: ONNX, Input Length 313: 832.345 ms\n",
      "Model: ONNX, Input Length 313: 850.132 ms\n",
      "Model: ONNX, Input Length 310: 1021.375 ms\n",
      "Model: ONNX, Input Length 310: 893.599 ms\n",
      "Model: ONNX, Input Length 320: 882.716 ms\n",
      "Model: ONNX, Input Length 320: 889.222 ms\n",
      "Model: ONNX, Input Length 325: 941.373 ms\n",
      "Model: ONNX, Input Length 325: 971.753 ms\n",
      "Model: ONNX, Input Length 278: 841.064 ms\n",
      "Model: ONNX, Input Length 278: 857.045 ms\n",
      "Model: ONNX, Input Length 313: 892.056 ms\n",
      "Model: ONNX, Input Length 313: 917.767 ms\n",
      "Model: ONNX, Input Length 310: 1070.486 ms\n",
      "Model: ONNX, Input Length 310: 938.430 ms\n",
      "Model: ONNX, Input Length 320: 935.431 ms\n",
      "Model: ONNX, Input Length 320: 953.466 ms\n",
      "Model: ONNX, Input Length 325: 1017.207 ms\n",
      "Model: ONNX, Input Length 325: 1054.906 ms\n",
      "Model: ONNX, Input Length 278: 979.413 ms\n",
      "Model: ONNX, Input Length 278: 884.318 ms\n",
      "Model: ONNX, Input Length 313: 961.646 ms\n",
      "Model: ONNX, Input Length 313: 928.904 ms\n",
      "Model: ONNX, Input Length 310: 1147.883 ms\n",
      "Model: ONNX, Input Length 310: 1116.834 ms\n",
      "Model: ONNX, Input Length 320: 1005.951 ms\n",
      "Model: ONNX, Input Length 320: 1022.643 ms\n",
      "Model: ONNX, Input Length 325: 1097.094 ms\n",
      "Model: ONNX, Input Length 325: 1126.183 ms\n",
      "Model: ONNX, Input Length 278: 953.763 ms\n",
      "Model: ONNX, Input Length 278: 907.975 ms\n",
      "Model: ONNX, Input Length 313: 949.588 ms\n",
      "Model: ONNX, Input Length 313: 965.313 ms\n",
      "Model: ONNX, Input Length 310: 1062.107 ms\n",
      "Model: ONNX, Input Length 310: 1049.421 ms\n",
      "Model: ONNX, Input Length 320: 1005.626 ms\n",
      "Model: ONNX, Input Length 320: 986.298 ms\n",
      "Model: ONNX, Input Length 325: 1029.221 ms\n",
      "Model: ONNX, Input Length 325: 1086.242 ms\n",
      "Model: ONNX, Input Length 278: 1048.862 ms\n",
      "Model: ONNX, Input Length 278: 950.688 ms\n",
      "Model: ONNX, Input Length 313: 976.774 ms\n",
      "Model: ONNX, Input Length 313: 1055.735 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1357.659 ms\n",
      "Model: ONNX-OPT, Input Length 310: 996.499 ms\n",
      "Model: ONNX-OPT, Input Length 320: 974.266 ms\n",
      "Model: ONNX-OPT, Input Length 320: 996.802 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1144.286 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1067.478 ms\n",
      "Model: ONNX-OPT, Input Length 278: 928.392 ms\n",
      "Model: ONNX-OPT, Input Length 278: 856.858 ms\n",
      "Model: ONNX-OPT, Input Length 313: 907.904 ms\n",
      "Model: ONNX-OPT, Input Length 313: 898.303 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1135.575 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1718.776 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1844.215 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1193.106 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1062.363 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1087.060 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1037.676 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1017.250 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1090.487 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1117.194 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1388.846 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1258.007 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1268.698 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1248.815 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1355.309 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1532.361 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1318.644 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1273.658 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1450.092 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1513.337 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1652.929 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1734.013 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1629.805 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1626.212 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1764.093 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1672.470 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1545.918 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1681.361 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1669.067 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1678.516 ms\n",
      "Model: ONNX-OPT, Input Length 310: 2105.065 ms\n",
      "Model: ONNX-OPT, Input Length 310: 1844.482 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1927.030 ms\n",
      "Model: ONNX-OPT, Input Length 320: 1839.959 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1823.062 ms\n",
      "Model: ONNX-OPT, Input Length 325: 1827.783 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1677.179 ms\n",
      "Model: ONNX-OPT, Input Length 278: 1743.162 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1802.469 ms\n",
      "Model: ONNX-OPT, Input Length 313: 1655.283 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1563.981 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1463.524 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1338.088 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1351.969 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1513.779 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1408.252 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1402.277 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1226.469 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1183.714 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1229.900 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1410.330 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1225.217 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1253.534 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1301.951 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1302.685 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1296.496 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1213.041 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1157.192 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1204.898 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1252.068 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1355.422 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1253.898 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1240.728 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1177.282 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1186.693 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1214.673 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1072.207 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1090.667 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1112.727 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1109.031 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1342.210 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1332.777 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1140.335 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1155.911 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1235.421 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1226.605 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1116.979 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1099.477 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1138.171 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1113.143 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1299.487 ms\n",
      "Model: ONNX Quantized, Input Length 310: 1198.515 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1136.754 ms\n",
      "Model: ONNX Quantized, Input Length 320: 1149.389 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1273.131 ms\n",
      "Model: ONNX Quantized, Input Length 325: 1214.370 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1111.844 ms\n",
      "Model: ONNX Quantized, Input Length 278: 1082.351 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1117.596 ms\n",
      "Model: ONNX Quantized, Input Length 313: 1101.740 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 1437.538 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 1279.666 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 1178.649 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 1168.930 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 1257.314 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 1233.895 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 1058.050 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 1064.070 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 1382.793 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 1441.478 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 1234.496 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 1037.674 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 1054.716 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 974.131 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 983.008 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 962.178 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 832.796 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 802.375 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 839.951 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 899.725 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 938.492 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 887.604 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 809.575 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 808.819 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 804.420 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 806.639 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 826.093 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 869.454 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 719.317 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 696.145 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 824.267 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 673.610 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 670.551 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 671.365 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 726.748 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 743.239 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 605.503 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 602.972 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 654.882 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 625.858 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 632.658 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 310: 746.528 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 648.728 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 320: 645.847 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 677.761 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 325: 687.673 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 587.046 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 602.774 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 615.878 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 313: 624.563 ms\n",
      "Loading: roberta-base quartz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset quartz (/Users/michaelhermann/.cache/huggingface/datasets/quartz/default/0.1.0/6e5195fb88ecd7a75eda5d8f3549c262c8b15267366f38f9c153f40da92724a6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: quartz\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 1910.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 19: 61.021 ms\n",
      "Model: Base, Input Length 20: 49.230 ms\n",
      "Model: Base, Input Length 20: 82.056 ms\n",
      "Model: Base, Input Length 18: 119.725 ms\n",
      "Model: Base, Input Length 18: 63.673 ms\n",
      "Model: Base, Input Length 10: 49.744 ms\n",
      "Model: Base, Input Length 16: 63.643 ms\n",
      "Model: Base, Input Length 10: 80.672 ms\n",
      "Model: Base, Input Length 22: 60.755 ms\n",
      "Model: Base, Input Length 14: 54.604 ms\n",
      "Model: Base, Input Length 19: 63.584 ms\n",
      "Model: Base, Input Length 20: 47.030 ms\n",
      "Model: Base, Input Length 20: 56.905 ms\n",
      "Model: Base, Input Length 18: 65.986 ms\n",
      "Model: Base, Input Length 18: 94.128 ms\n",
      "Model: Base, Input Length 10: 71.926 ms\n",
      "Model: Base, Input Length 16: 87.300 ms\n",
      "Model: Base, Input Length 10: 111.518 ms\n",
      "Model: Base, Input Length 22: 84.403 ms\n",
      "Model: Base, Input Length 14: 45.700 ms\n",
      "Model: Base, Input Length 19: 64.764 ms\n",
      "Model: Base, Input Length 20: 49.461 ms\n",
      "Model: Base, Input Length 20: 58.390 ms\n",
      "Model: Base, Input Length 18: 55.564 ms\n",
      "Model: Base, Input Length 18: 63.956 ms\n",
      "Model: Base, Input Length 10: 64.030 ms\n",
      "Model: Base, Input Length 16: 65.943 ms\n",
      "Model: Base, Input Length 10: 122.383 ms\n",
      "Model: Base, Input Length 22: 90.154 ms\n",
      "Model: Base, Input Length 14: 66.330 ms\n",
      "Model: Base, Input Length 19: 86.785 ms\n",
      "Model: Base, Input Length 20: 51.788 ms\n",
      "Model: Base, Input Length 20: 60.487 ms\n",
      "Model: Base, Input Length 18: 58.697 ms\n",
      "Model: Base, Input Length 18: 68.729 ms\n",
      "Model: Base, Input Length 10: 52.280 ms\n",
      "Model: Base, Input Length 16: 57.805 ms\n",
      "Model: Base, Input Length 10: 81.025 ms\n",
      "Model: Base, Input Length 22: 62.590 ms\n",
      "Model: Base, Input Length 14: 48.239 ms\n",
      "Model: Base, Input Length 19: 54.785 ms\n",
      "Model: Base, Input Length 20: 47.561 ms\n",
      "Model: Base, Input Length 20: 84.904 ms\n",
      "Model: Base, Input Length 18: 77.069 ms\n",
      "Model: Base, Input Length 18: 96.323 ms\n",
      "Model: Base, Input Length 10: 67.498 ms\n",
      "Model: Base, Input Length 16: 87.811 ms\n",
      "Model: Base, Input Length 10: 91.618 ms\n",
      "Model: Base, Input Length 22: 65.984 ms\n",
      "Model: Base, Input Length 14: 50.514 ms\n",
      "Model: Base Quantized, Input Length 19: 75.358 ms\n",
      "Model: Base Quantized, Input Length 20: 63.011 ms\n",
      "Model: Base Quantized, Input Length 20: 80.270 ms\n",
      "Model: Base Quantized, Input Length 18: 77.129 ms\n",
      "Model: Base Quantized, Input Length 18: 95.048 ms\n",
      "Model: Base Quantized, Input Length 10: 81.545 ms\n",
      "Model: Base Quantized, Input Length 16: 100.724 ms\n",
      "Model: Base Quantized, Input Length 10: 126.925 ms\n",
      "Model: Base Quantized, Input Length 22: 93.723 ms\n",
      "Model: Base Quantized, Input Length 14: 62.895 ms\n",
      "Model: Base Quantized, Input Length 19: 73.742 ms\n",
      "Model: Base Quantized, Input Length 20: 65.148 ms\n",
      "Model: Base Quantized, Input Length 20: 70.818 ms\n",
      "Model: Base Quantized, Input Length 18: 72.188 ms\n",
      "Model: Base Quantized, Input Length 18: 84.912 ms\n",
      "Model: Base Quantized, Input Length 10: 66.362 ms\n",
      "Model: Base Quantized, Input Length 16: 72.318 ms\n",
      "Model: Base Quantized, Input Length 10: 94.312 ms\n",
      "Model: Base Quantized, Input Length 22: 72.458 ms\n",
      "Model: Base Quantized, Input Length 14: 95.795 ms\n",
      "Model: Base Quantized, Input Length 19: 75.612 ms\n",
      "Model: Base Quantized, Input Length 20: 62.215 ms\n",
      "Model: Base Quantized, Input Length 20: 71.979 ms\n",
      "Model: Base Quantized, Input Length 18: 68.748 ms\n",
      "Model: Base Quantized, Input Length 18: 78.800 ms\n",
      "Model: Base Quantized, Input Length 10: 59.239 ms\n",
      "Model: Base Quantized, Input Length 16: 71.761 ms\n",
      "Model: Base Quantized, Input Length 10: 120.291 ms\n",
      "Model: Base Quantized, Input Length 22: 103.570 ms\n",
      "Model: Base Quantized, Input Length 14: 84.199 ms\n",
      "Model: Base Quantized, Input Length 19: 97.625 ms\n",
      "Model: Base Quantized, Input Length 20: 64.527 ms\n",
      "Model: Base Quantized, Input Length 20: 70.246 ms\n",
      "Model: Base Quantized, Input Length 18: 67.577 ms\n",
      "Model: Base Quantized, Input Length 18: 76.593 ms\n",
      "Model: Base Quantized, Input Length 10: 65.087 ms\n",
      "Model: Base Quantized, Input Length 16: 75.632 ms\n",
      "Model: Base Quantized, Input Length 10: 88.683 ms\n",
      "Model: Base Quantized, Input Length 22: 72.092 ms\n",
      "Model: Base Quantized, Input Length 14: 66.446 ms\n",
      "Model: Base Quantized, Input Length 19: 69.806 ms\n",
      "Model: Base Quantized, Input Length 20: 60.114 ms\n",
      "Model: Base Quantized, Input Length 20: 75.533 ms\n",
      "Model: Base Quantized, Input Length 18: 75.414 ms\n",
      "Model: Base Quantized, Input Length 18: 87.567 ms\n",
      "Model: Base Quantized, Input Length 10: 83.937 ms\n",
      "Model: Base Quantized, Input Length 16: 102.081 ms\n",
      "Model: Base Quantized, Input Length 10: 125.971 ms\n",
      "Model: Base Quantized, Input Length 22: 99.625 ms\n",
      "Model: Base Quantized, Input Length 14: 63.624 ms\n",
      "Model: ONNX, Input Length 19: 43.042 ms\n",
      "Model: ONNX, Input Length 20: 37.073 ms\n",
      "Model: ONNX, Input Length 20: 41.617 ms\n",
      "Model: ONNX, Input Length 18: 38.057 ms\n",
      "Model: ONNX, Input Length 18: 43.679 ms\n",
      "Model: ONNX, Input Length 10: 35.766 ms\n",
      "Model: ONNX, Input Length 16: 44.768 ms\n",
      "Model: ONNX, Input Length 10: 54.465 ms\n",
      "Model: ONNX, Input Length 22: 41.274 ms\n",
      "Model: ONNX, Input Length 14: 36.051 ms\n",
      "Model: ONNX, Input Length 19: 58.222 ms\n",
      "Model: ONNX, Input Length 20: 48.928 ms\n",
      "Model: ONNX, Input Length 20: 52.841 ms\n",
      "Model: ONNX, Input Length 18: 53.913 ms\n",
      "Model: ONNX, Input Length 18: 65.511 ms\n",
      "Model: ONNX, Input Length 10: 50.665 ms\n",
      "Model: ONNX, Input Length 16: 59.487 ms\n",
      "Model: ONNX, Input Length 10: 58.286 ms\n",
      "Model: ONNX, Input Length 22: 49.148 ms\n",
      "Model: ONNX, Input Length 14: 36.006 ms\n",
      "Model: ONNX, Input Length 19: 42.348 ms\n",
      "Model: ONNX, Input Length 20: 35.205 ms\n",
      "Model: ONNX, Input Length 20: 40.220 ms\n",
      "Model: ONNX, Input Length 18: 40.314 ms\n",
      "Model: ONNX, Input Length 18: 45.832 ms\n",
      "Model: ONNX, Input Length 10: 38.070 ms\n",
      "Model: ONNX, Input Length 16: 41.066 ms\n",
      "Model: ONNX, Input Length 10: 52.498 ms\n",
      "Model: ONNX, Input Length 22: 45.165 ms\n",
      "Model: ONNX, Input Length 14: 37.639 ms\n",
      "Model: ONNX, Input Length 19: 39.725 ms\n",
      "Model: ONNX, Input Length 20: 35.795 ms\n",
      "Model: ONNX, Input Length 20: 39.947 ms\n",
      "Model: ONNX, Input Length 18: 37.983 ms\n",
      "Model: ONNX, Input Length 18: 42.589 ms\n",
      "Model: ONNX, Input Length 10: 43.156 ms\n",
      "Model: ONNX, Input Length 16: 60.969 ms\n",
      "Model: ONNX, Input Length 10: 75.832 ms\n",
      "Model: ONNX, Input Length 22: 63.932 ms\n",
      "Model: ONNX, Input Length 14: 49.848 ms\n",
      "Model: ONNX, Input Length 19: 56.913 ms\n",
      "Model: ONNX, Input Length 20: 48.336 ms\n",
      "Model: ONNX, Input Length 20: 39.689 ms\n",
      "Model: ONNX, Input Length 18: 38.261 ms\n",
      "Model: ONNX, Input Length 18: 44.705 ms\n",
      "Model: ONNX, Input Length 10: 38.498 ms\n",
      "Model: ONNX, Input Length 16: 43.226 ms\n",
      "Model: ONNX, Input Length 10: 54.261 ms\n",
      "Model: ONNX, Input Length 22: 43.744 ms\n",
      "Model: ONNX, Input Length 14: 35.625 ms\n",
      "Model: ONNX-OPT, Input Length 19: 45.470 ms\n",
      "Model: ONNX-OPT, Input Length 20: 36.322 ms\n",
      "Model: ONNX-OPT, Input Length 20: 36.645 ms\n",
      "Model: ONNX-OPT, Input Length 18: 37.735 ms\n",
      "Model: ONNX-OPT, Input Length 18: 52.805 ms\n",
      "Model: ONNX-OPT, Input Length 10: 50.470 ms\n",
      "Model: ONNX-OPT, Input Length 16: 43.268 ms\n",
      "Model: ONNX-OPT, Input Length 10: 53.133 ms\n",
      "Model: ONNX-OPT, Input Length 22: 41.558 ms\n",
      "Model: ONNX-OPT, Input Length 14: 37.117 ms\n",
      "Model: ONNX-OPT, Input Length 19: 39.405 ms\n",
      "Model: ONNX-OPT, Input Length 20: 35.392 ms\n",
      "Model: ONNX-OPT, Input Length 20: 40.865 ms\n",
      "Model: ONNX-OPT, Input Length 18: 37.523 ms\n",
      "Model: ONNX-OPT, Input Length 18: 42.175 ms\n",
      "Model: ONNX-OPT, Input Length 10: 36.348 ms\n",
      "Model: ONNX-OPT, Input Length 16: 43.128 ms\n",
      "Model: ONNX-OPT, Input Length 10: 55.461 ms\n",
      "Model: ONNX-OPT, Input Length 22: 61.608 ms\n",
      "Model: ONNX-OPT, Input Length 14: 50.056 ms\n",
      "Model: ONNX-OPT, Input Length 19: 57.393 ms\n",
      "Model: ONNX-OPT, Input Length 20: 48.332 ms\n",
      "Model: ONNX-OPT, Input Length 20: 54.822 ms\n",
      "Model: ONNX-OPT, Input Length 18: 54.455 ms\n",
      "Model: ONNX-OPT, Input Length 18: 55.138 ms\n",
      "Model: ONNX-OPT, Input Length 10: 38.686 ms\n",
      "Model: ONNX-OPT, Input Length 16: 42.465 ms\n",
      "Model: ONNX-OPT, Input Length 10: 53.323 ms\n",
      "Model: ONNX-OPT, Input Length 22: 45.573 ms\n",
      "Model: ONNX-OPT, Input Length 14: 36.600 ms\n",
      "Model: ONNX-OPT, Input Length 19: 39.704 ms\n",
      "Model: ONNX-OPT, Input Length 20: 35.060 ms\n",
      "Model: ONNX-OPT, Input Length 20: 42.797 ms\n",
      "Model: ONNX-OPT, Input Length 18: 38.207 ms\n",
      "Model: ONNX-OPT, Input Length 18: 44.159 ms\n",
      "Model: ONNX-OPT, Input Length 10: 39.225 ms\n",
      "Model: ONNX-OPT, Input Length 16: 42.424 ms\n",
      "Model: ONNX-OPT, Input Length 10: 54.469 ms\n",
      "Model: ONNX-OPT, Input Length 22: 42.159 ms\n",
      "Model: ONNX-OPT, Input Length 14: 39.295 ms\n",
      "Model: ONNX-OPT, Input Length 19: 40.834 ms\n",
      "Model: ONNX-OPT, Input Length 20: 34.438 ms\n",
      "Model: ONNX-OPT, Input Length 20: 38.467 ms\n",
      "Model: ONNX-OPT, Input Length 18: 38.600 ms\n",
      "Model: ONNX-OPT, Input Length 18: 47.849 ms\n",
      "Model: ONNX-OPT, Input Length 10: 37.991 ms\n",
      "Model: ONNX-OPT, Input Length 16: 46.246 ms\n",
      "Model: ONNX-OPT, Input Length 10: 51.074 ms\n",
      "Model: ONNX-OPT, Input Length 22: 42.548 ms\n",
      "Model: ONNX-OPT, Input Length 14: 38.078 ms\n",
      "Model: ONNX Quantized, Input Length 19: 32.253 ms\n",
      "Model: ONNX Quantized, Input Length 20: 24.606 ms\n",
      "Model: ONNX Quantized, Input Length 20: 28.396 ms\n",
      "Model: ONNX Quantized, Input Length 18: 28.044 ms\n",
      "Model: ONNX Quantized, Input Length 18: 30.925 ms\n",
      "Model: ONNX Quantized, Input Length 10: 25.590 ms\n",
      "Model: ONNX Quantized, Input Length 16: 29.967 ms\n",
      "Model: ONNX Quantized, Input Length 10: 36.823 ms\n",
      "Model: ONNX Quantized, Input Length 22: 34.850 ms\n",
      "Model: ONNX Quantized, Input Length 14: 26.628 ms\n",
      "Model: ONNX Quantized, Input Length 19: 38.333 ms\n",
      "Model: ONNX Quantized, Input Length 20: 33.869 ms\n",
      "Model: ONNX Quantized, Input Length 20: 37.173 ms\n",
      "Model: ONNX Quantized, Input Length 18: 37.519 ms\n",
      "Model: ONNX Quantized, Input Length 18: 42.369 ms\n",
      "Model: ONNX Quantized, Input Length 10: 34.817 ms\n",
      "Model: ONNX Quantized, Input Length 16: 41.153 ms\n",
      "Model: ONNX Quantized, Input Length 10: 50.307 ms\n",
      "Model: ONNX Quantized, Input Length 22: 37.787 ms\n",
      "Model: ONNX Quantized, Input Length 14: 29.391 ms\n",
      "Model: ONNX Quantized, Input Length 19: 28.635 ms\n",
      "Model: ONNX Quantized, Input Length 20: 26.310 ms\n",
      "Model: ONNX Quantized, Input Length 20: 28.515 ms\n",
      "Model: ONNX Quantized, Input Length 18: 28.252 ms\n",
      "Model: ONNX Quantized, Input Length 18: 34.974 ms\n",
      "Model: ONNX Quantized, Input Length 10: 26.863 ms\n",
      "Model: ONNX Quantized, Input Length 16: 30.780 ms\n",
      "Model: ONNX Quantized, Input Length 10: 37.025 ms\n",
      "Model: ONNX Quantized, Input Length 22: 31.167 ms\n",
      "Model: ONNX Quantized, Input Length 14: 27.950 ms\n",
      "Model: ONNX Quantized, Input Length 19: 29.720 ms\n",
      "Model: ONNX Quantized, Input Length 20: 25.476 ms\n",
      "Model: ONNX Quantized, Input Length 20: 30.340 ms\n",
      "Model: ONNX Quantized, Input Length 18: 27.322 ms\n",
      "Model: ONNX Quantized, Input Length 18: 30.801 ms\n",
      "Model: ONNX Quantized, Input Length 10: 27.123 ms\n",
      "Model: ONNX Quantized, Input Length 16: 30.111 ms\n",
      "Model: ONNX Quantized, Input Length 10: 37.561 ms\n",
      "Model: ONNX Quantized, Input Length 22: 31.343 ms\n",
      "Model: ONNX Quantized, Input Length 14: 27.594 ms\n",
      "Model: ONNX Quantized, Input Length 19: 28.143 ms\n",
      "Model: ONNX Quantized, Input Length 20: 24.613 ms\n",
      "Model: ONNX Quantized, Input Length 20: 27.327 ms\n",
      "Model: ONNX Quantized, Input Length 18: 27.380 ms\n",
      "Model: ONNX Quantized, Input Length 18: 32.392 ms\n",
      "Model: ONNX Quantized, Input Length 10: 27.401 ms\n",
      "Model: ONNX Quantized, Input Length 16: 34.305 ms\n",
      "Model: ONNX Quantized, Input Length 10: 38.116 ms\n",
      "Model: ONNX Quantized, Input Length 22: 30.858 ms\n",
      "Model: ONNX Quantized, Input Length 14: 26.300 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 31.617 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 24.876 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 28.131 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 31.280 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 30.410 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 27.632 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 16: 30.167 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 36.532 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 30.545 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 26.802 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 32.292 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 25.274 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 28.373 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 28.141 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 31.189 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 28.259 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 16: 31.839 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 48.263 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 31.963 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 37.629 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 41.998 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 38.178 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 40.490 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 40.284 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 46.401 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 38.205 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 16: 44.827 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 45.633 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 32.895 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 32.669 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 32.401 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 28.892 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 33.933 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 35.963 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 46.185 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 38.379 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 16: 36.553 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 40.401 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 34.273 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 29.082 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 19: 31.723 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 30.631 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 20: 32.448 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 30.126 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 18: 37.034 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 28.551 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 16: 32.244 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 10: 42.408 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 22: 32.438 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 14: 28.529 ms\n",
      "Loading: bert-base-uncased race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset race (/Users/michaelhermann/.cache/huggingface/datasets/race/all/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: race\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 2443.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 339: 1102.949 ms\n",
      "Model: Base, Input Length 433: 1404.662 ms\n",
      "Model: Base, Input Length 385: 1284.259 ms\n",
      "Model: Base, Input Length 317: 934.925 ms\n",
      "Model: Base, Input Length 327: 997.387 ms\n",
      "Model: Base, Input Length 583: 1400.525 ms\n",
      "Model: Base, Input Length 254: 708.003 ms\n",
      "Model: Base, Input Length 347: 1271.092 ms\n",
      "Model: Base, Input Length 305: 889.786 ms\n",
      "Model: Base, Input Length 278: 886.947 ms\n",
      "Model: Base, Input Length 339: 1176.637 ms\n",
      "Model: Base, Input Length 433: 1405.618 ms\n",
      "Model: Base, Input Length 385: 1348.178 ms\n",
      "Model: Base, Input Length 317: 940.470 ms\n",
      "Model: Base, Input Length 327: 999.911 ms\n",
      "Model: Base, Input Length 583: 1464.257 ms\n",
      "Model: Base, Input Length 254: 780.219 ms\n",
      "Model: Base, Input Length 347: 1329.559 ms\n",
      "Model: Base, Input Length 305: 907.678 ms\n",
      "Model: Base, Input Length 278: 945.687 ms\n",
      "Model: Base, Input Length 339: 1227.425 ms\n",
      "Model: Base, Input Length 433: 1513.969 ms\n",
      "Model: Base, Input Length 385: 1319.548 ms\n",
      "Model: Base, Input Length 317: 962.651 ms\n",
      "Model: Base, Input Length 327: 1057.439 ms\n",
      "Model: Base, Input Length 583: 1553.332 ms\n",
      "Model: Base, Input Length 254: 758.261 ms\n",
      "Model: Base, Input Length 347: 1281.590 ms\n",
      "Model: Base, Input Length 305: 942.634 ms\n",
      "Model: Base, Input Length 278: 973.612 ms\n",
      "Model: Base, Input Length 339: 1438.262 ms\n",
      "Model: Base, Input Length 433: 1563.356 ms\n",
      "Model: Base, Input Length 385: 1421.528 ms\n",
      "Model: Base, Input Length 317: 1110.733 ms\n",
      "Model: Base, Input Length 327: 1160.906 ms\n",
      "Model: Base, Input Length 583: 1574.409 ms\n",
      "Model: Base, Input Length 254: 826.234 ms\n",
      "Model: Base, Input Length 347: 1373.489 ms\n",
      "Model: Base, Input Length 305: 1076.898 ms\n",
      "Model: Base, Input Length 278: 1024.044 ms\n",
      "Model: Base, Input Length 339: 1489.706 ms\n",
      "Model: Base, Input Length 433: 1838.746 ms\n",
      "Model: Base, Input Length 385: 1470.856 ms\n",
      "Model: Base, Input Length 317: 1126.227 ms\n",
      "Model: Base, Input Length 327: 1320.303 ms\n",
      "Model: Base, Input Length 583: 1687.687 ms\n",
      "Model: Base, Input Length 254: 899.997 ms\n",
      "Model: Base, Input Length 347: 1451.252 ms\n",
      "Model: Base, Input Length 305: 1040.537 ms\n",
      "Model: Base, Input Length 278: 1053.992 ms\n",
      "Model: Base Quantized, Input Length 339: 1393.297 ms\n",
      "Model: Base Quantized, Input Length 433: 1626.314 ms\n",
      "Model: Base Quantized, Input Length 385: 1573.614 ms\n",
      "Model: Base Quantized, Input Length 317: 1093.747 ms\n",
      "Model: Base Quantized, Input Length 327: 1179.615 ms\n",
      "Model: Base Quantized, Input Length 583: 1645.709 ms\n",
      "Model: Base Quantized, Input Length 254: 848.864 ms\n",
      "Model: Base Quantized, Input Length 347: 1396.275 ms\n",
      "Model: Base Quantized, Input Length 305: 1027.054 ms\n",
      "Model: Base Quantized, Input Length 278: 998.601 ms\n",
      "Model: Base Quantized, Input Length 339: 1516.083 ms\n",
      "Model: Base Quantized, Input Length 433: 1614.113 ms\n",
      "Model: Base Quantized, Input Length 385: 1470.100 ms\n",
      "Model: Base Quantized, Input Length 317: 1103.499 ms\n",
      "Model: Base Quantized, Input Length 327: 1330.138 ms\n",
      "Model: Base Quantized, Input Length 583: 1614.331 ms\n",
      "Model: Base Quantized, Input Length 254: 858.660 ms\n",
      "Model: Base Quantized, Input Length 347: 1411.419 ms\n",
      "Model: Base Quantized, Input Length 305: 1003.262 ms\n",
      "Model: Base Quantized, Input Length 278: 996.955 ms\n",
      "Model: Base Quantized, Input Length 339: 1534.834 ms\n",
      "Model: Base Quantized, Input Length 433: 1593.109 ms\n",
      "Model: Base Quantized, Input Length 385: 1524.115 ms\n",
      "Model: Base Quantized, Input Length 317: 1164.315 ms\n",
      "Model: Base Quantized, Input Length 327: 1263.184 ms\n",
      "Model: Base Quantized, Input Length 583: 1573.718 ms\n",
      "Model: Base Quantized, Input Length 254: 916.779 ms\n",
      "Model: Base Quantized, Input Length 347: 1551.986 ms\n",
      "Model: Base Quantized, Input Length 305: 1034.962 ms\n",
      "Model: Base Quantized, Input Length 278: 1067.127 ms\n",
      "Model: Base Quantized, Input Length 339: 1376.881 ms\n",
      "Model: Base Quantized, Input Length 433: 1649.446 ms\n",
      "Model: Base Quantized, Input Length 385: 1425.994 ms\n",
      "Model: Base Quantized, Input Length 317: 1095.751 ms\n",
      "Model: Base Quantized, Input Length 327: 1162.356 ms\n",
      "Model: Base Quantized, Input Length 583: 1634.077 ms\n",
      "Model: Base Quantized, Input Length 254: 796.593 ms\n",
      "Model: Base Quantized, Input Length 347: 1394.264 ms\n",
      "Model: Base Quantized, Input Length 305: 1011.548 ms\n",
      "Model: Base Quantized, Input Length 278: 1021.673 ms\n",
      "Model: Base Quantized, Input Length 339: 1551.137 ms\n",
      "Model: Base Quantized, Input Length 433: 1624.578 ms\n",
      "Model: Base Quantized, Input Length 385: 1475.836 ms\n",
      "Model: Base Quantized, Input Length 317: 1131.534 ms\n",
      "Model: Base Quantized, Input Length 327: 1214.069 ms\n",
      "Model: Base Quantized, Input Length 583: 1614.332 ms\n",
      "Model: Base Quantized, Input Length 254: 837.129 ms\n",
      "Model: Base Quantized, Input Length 347: 1400.460 ms\n",
      "Model: Base Quantized, Input Length 305: 984.367 ms\n",
      "Model: Base Quantized, Input Length 278: 1033.688 ms\n",
      "Model: ONNX, Input Length 339: 718.855 ms\n",
      "Model: ONNX, Input Length 433: 915.688 ms\n",
      "Model: ONNX, Input Length 385: 862.755 ms\n",
      "Model: ONNX, Input Length 317: 625.549 ms\n",
      "Model: ONNX, Input Length 327: 700.233 ms\n",
      "Model: ONNX, Input Length 583: 950.012 ms\n",
      "Model: ONNX, Input Length 254: 507.365 ms\n",
      "Model: ONNX, Input Length 347: 849.414 ms\n",
      "Model: ONNX, Input Length 305: 620.787 ms\n",
      "Model: ONNX, Input Length 278: 683.757 ms\n",
      "Model: ONNX, Input Length 339: 925.882 ms\n",
      "Model: ONNX, Input Length 433: 1113.673 ms\n",
      "Model: ONNX, Input Length 385: 906.814 ms\n",
      "Model: ONNX, Input Length 317: 704.673 ms\n",
      "Model: ONNX, Input Length 327: 797.779 ms\n",
      "Model: ONNX, Input Length 583: 1031.367 ms\n",
      "Model: ONNX, Input Length 254: 566.451 ms\n",
      "Model: ONNX, Input Length 347: 917.491 ms\n",
      "Model: ONNX, Input Length 305: 648.672 ms\n",
      "Model: ONNX, Input Length 278: 655.900 ms\n",
      "Model: ONNX, Input Length 339: 895.683 ms\n",
      "Model: ONNX, Input Length 433: 1112.462 ms\n",
      "Model: ONNX, Input Length 385: 947.606 ms\n",
      "Model: ONNX, Input Length 317: 717.938 ms\n",
      "Model: ONNX, Input Length 327: 785.107 ms\n",
      "Model: ONNX, Input Length 583: 1026.780 ms\n",
      "Model: ONNX, Input Length 254: 566.499 ms\n",
      "Model: ONNX, Input Length 347: 953.737 ms\n",
      "Model: ONNX, Input Length 305: 644.636 ms\n",
      "Model: ONNX, Input Length 278: 659.400 ms\n",
      "Model: ONNX, Input Length 339: 834.559 ms\n",
      "Model: ONNX, Input Length 433: 1204.176 ms\n",
      "Model: ONNX, Input Length 385: 1052.203 ms\n",
      "Model: ONNX, Input Length 317: 744.254 ms\n",
      "Model: ONNX, Input Length 327: 804.893 ms\n",
      "Model: ONNX, Input Length 583: 1037.495 ms\n",
      "Model: ONNX, Input Length 254: 609.634 ms\n",
      "Model: ONNX, Input Length 347: 988.025 ms\n",
      "Model: ONNX, Input Length 305: 693.997 ms\n",
      "Model: ONNX, Input Length 278: 698.249 ms\n",
      "Model: ONNX, Input Length 339: 1014.652 ms\n",
      "Model: ONNX, Input Length 433: 1063.271 ms\n",
      "Model: ONNX, Input Length 385: 968.409 ms\n",
      "Model: ONNX, Input Length 317: 750.860 ms\n",
      "Model: ONNX, Input Length 327: 827.543 ms\n",
      "Model: ONNX, Input Length 583: 1057.099 ms\n",
      "Model: ONNX, Input Length 254: 594.416 ms\n",
      "Model: ONNX, Input Length 347: 1150.538 ms\n",
      "Model: ONNX, Input Length 305: 673.500 ms\n",
      "Model: ONNX, Input Length 278: 754.101 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1055.081 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1198.553 ms\n",
      "Model: ONNX-OPT, Input Length 385: 1173.239 ms\n",
      "Model: ONNX-OPT, Input Length 317: 747.153 ms\n",
      "Model: ONNX-OPT, Input Length 327: 830.529 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1047.840 ms\n",
      "Model: ONNX-OPT, Input Length 254: 587.585 ms\n",
      "Model: ONNX-OPT, Input Length 347: 966.230 ms\n",
      "Model: ONNX-OPT, Input Length 305: 682.319 ms\n",
      "Model: ONNX-OPT, Input Length 278: 701.196 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1043.891 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1144.328 ms\n",
      "Model: ONNX-OPT, Input Length 385: 940.489 ms\n",
      "Model: ONNX-OPT, Input Length 317: 730.343 ms\n",
      "Model: ONNX-OPT, Input Length 327: 784.580 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1038.834 ms\n",
      "Model: ONNX-OPT, Input Length 254: 576.344 ms\n",
      "Model: ONNX-OPT, Input Length 347: 927.364 ms\n",
      "Model: ONNX-OPT, Input Length 305: 643.708 ms\n",
      "Model: ONNX-OPT, Input Length 278: 649.604 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1067.907 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1083.573 ms\n",
      "Model: ONNX-OPT, Input Length 385: 960.142 ms\n",
      "Model: ONNX-OPT, Input Length 317: 740.825 ms\n",
      "Model: ONNX-OPT, Input Length 327: 775.776 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1028.851 ms\n",
      "Model: ONNX-OPT, Input Length 254: 566.461 ms\n",
      "Model: ONNX-OPT, Input Length 347: 915.351 ms\n",
      "Model: ONNX-OPT, Input Length 305: 652.648 ms\n",
      "Model: ONNX-OPT, Input Length 278: 666.117 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1057.243 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1116.716 ms\n",
      "Model: ONNX-OPT, Input Length 385: 998.484 ms\n",
      "Model: ONNX-OPT, Input Length 317: 728.876 ms\n",
      "Model: ONNX-OPT, Input Length 327: 791.762 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1036.378 ms\n",
      "Model: ONNX-OPT, Input Length 254: 560.538 ms\n",
      "Model: ONNX-OPT, Input Length 347: 920.992 ms\n",
      "Model: ONNX-OPT, Input Length 305: 650.268 ms\n",
      "Model: ONNX-OPT, Input Length 278: 671.943 ms\n",
      "Model: ONNX-OPT, Input Length 339: 985.067 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1023.012 ms\n",
      "Model: ONNX-OPT, Input Length 385: 940.059 ms\n",
      "Model: ONNX-OPT, Input Length 317: 723.046 ms\n",
      "Model: ONNX-OPT, Input Length 327: 784.749 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1025.459 ms\n",
      "Model: ONNX-OPT, Input Length 254: 582.767 ms\n",
      "Model: ONNX-OPT, Input Length 347: 934.811 ms\n",
      "Model: ONNX-OPT, Input Length 305: 645.236 ms\n",
      "Model: ONNX-OPT, Input Length 278: 684.312 ms\n",
      "Model: ONNX Quantized, Input Length 339: 691.404 ms\n",
      "Model: ONNX Quantized, Input Length 433: 983.965 ms\n",
      "Model: ONNX Quantized, Input Length 385: 791.158 ms\n",
      "Model: ONNX Quantized, Input Length 317: 590.643 ms\n",
      "Model: ONNX Quantized, Input Length 327: 653.860 ms\n",
      "Model: ONNX Quantized, Input Length 583: 838.537 ms\n",
      "Model: ONNX Quantized, Input Length 254: 472.761 ms\n",
      "Model: ONNX Quantized, Input Length 347: 764.994 ms\n",
      "Model: ONNX Quantized, Input Length 305: 530.290 ms\n",
      "Model: ONNX Quantized, Input Length 278: 535.898 ms\n",
      "Model: ONNX Quantized, Input Length 339: 784.907 ms\n",
      "Model: ONNX Quantized, Input Length 433: 847.029 ms\n",
      "Model: ONNX Quantized, Input Length 385: 752.716 ms\n",
      "Model: ONNX Quantized, Input Length 317: 568.434 ms\n",
      "Model: ONNX Quantized, Input Length 327: 606.307 ms\n",
      "Model: ONNX Quantized, Input Length 583: 813.890 ms\n",
      "Model: ONNX Quantized, Input Length 254: 432.386 ms\n",
      "Model: ONNX Quantized, Input Length 347: 722.334 ms\n",
      "Model: ONNX Quantized, Input Length 305: 493.745 ms\n",
      "Model: ONNX Quantized, Input Length 278: 501.462 ms\n",
      "Model: ONNX Quantized, Input Length 339: 798.397 ms\n",
      "Model: ONNX Quantized, Input Length 433: 823.255 ms\n",
      "Model: ONNX Quantized, Input Length 385: 807.915 ms\n",
      "Model: ONNX Quantized, Input Length 317: 628.322 ms\n",
      "Model: ONNX Quantized, Input Length 327: 608.228 ms\n",
      "Model: ONNX Quantized, Input Length 583: 824.812 ms\n",
      "Model: ONNX Quantized, Input Length 254: 426.826 ms\n",
      "Model: ONNX Quantized, Input Length 347: 748.492 ms\n",
      "Model: ONNX Quantized, Input Length 305: 625.830 ms\n",
      "Model: ONNX Quantized, Input Length 278: 519.263 ms\n",
      "Model: ONNX Quantized, Input Length 339: 793.137 ms\n",
      "Model: ONNX Quantized, Input Length 433: 906.887 ms\n",
      "Model: ONNX Quantized, Input Length 385: 764.796 ms\n",
      "Model: ONNX Quantized, Input Length 317: 560.325 ms\n",
      "Model: ONNX Quantized, Input Length 327: 618.670 ms\n",
      "Model: ONNX Quantized, Input Length 583: 817.781 ms\n",
      "Model: ONNX Quantized, Input Length 254: 455.989 ms\n",
      "Model: ONNX Quantized, Input Length 347: 711.675 ms\n",
      "Model: ONNX Quantized, Input Length 305: 510.267 ms\n",
      "Model: ONNX Quantized, Input Length 278: 504.925 ms\n",
      "Model: ONNX Quantized, Input Length 339: 764.179 ms\n",
      "Model: ONNX Quantized, Input Length 433: 903.915 ms\n",
      "Model: ONNX Quantized, Input Length 385: 858.857 ms\n",
      "Model: ONNX Quantized, Input Length 317: 552.361 ms\n",
      "Model: ONNX Quantized, Input Length 327: 608.821 ms\n",
      "Model: ONNX Quantized, Input Length 583: 923.082 ms\n",
      "Model: ONNX Quantized, Input Length 254: 551.018 ms\n",
      "Model: ONNX Quantized, Input Length 347: 755.367 ms\n",
      "Model: ONNX Quantized, Input Length 305: 498.308 ms\n",
      "Model: ONNX Quantized, Input Length 278: 501.850 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 758.419 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 927.937 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 751.514 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 544.169 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 610.302 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 801.837 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 417.301 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 720.473 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 483.099 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 497.123 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 627.313 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 917.497 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 740.114 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 544.735 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 593.794 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 790.470 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 425.753 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 729.273 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 491.916 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 489.225 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 638.203 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 918.592 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 735.048 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 548.533 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 594.132 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 800.737 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 420.809 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 704.442 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 541.041 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 497.496 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 735.717 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 910.815 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 736.326 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 551.568 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 603.365 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 817.599 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 454.274 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 704.454 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 506.920 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 501.324 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 689.925 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 886.189 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 742.074 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 564.528 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 613.002 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 806.353 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 424.804 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 714.704 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 487.603 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 512.488 ms\n",
      "Loading: roberta-base race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset race (/Users/michaelhermann/.cache/huggingface/datasets/race/all/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: race\n",
      "Preped data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 2789.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Base, Input Length 339: 1231.804 ms\n",
      "Model: Base, Input Length 433: 1379.646 ms\n",
      "Model: Base, Input Length 385: 1271.117 ms\n",
      "Model: Base, Input Length 317: 977.235 ms\n",
      "Model: Base, Input Length 327: 1041.774 ms\n",
      "Model: Base, Input Length 583: 1421.205 ms\n",
      "Model: Base, Input Length 254: 708.533 ms\n",
      "Model: Base, Input Length 347: 1233.355 ms\n",
      "Model: Base, Input Length 305: 904.011 ms\n",
      "Model: Base, Input Length 278: 962.422 ms\n",
      "Model: Base, Input Length 339: 1198.474 ms\n",
      "Model: Base, Input Length 433: 1355.160 ms\n",
      "Model: Base, Input Length 385: 1281.995 ms\n",
      "Model: Base, Input Length 317: 996.682 ms\n",
      "Model: Base, Input Length 327: 1168.753 ms\n",
      "Model: Base, Input Length 583: 1438.865 ms\n",
      "Model: Base, Input Length 254: 775.726 ms\n",
      "Model: Base, Input Length 347: 1338.522 ms\n",
      "Model: Base, Input Length 305: 1007.953 ms\n",
      "Model: Base, Input Length 278: 1038.411 ms\n",
      "Model: Base, Input Length 339: 1456.903 ms\n",
      "Model: Base, Input Length 433: 1587.107 ms\n",
      "Model: Base, Input Length 385: 1500.965 ms\n",
      "Model: Base, Input Length 317: 1151.585 ms\n",
      "Model: Base, Input Length 327: 1187.568 ms\n",
      "Model: Base, Input Length 583: 1563.883 ms\n",
      "Model: Base, Input Length 254: 868.844 ms\n",
      "Model: Base, Input Length 347: 1419.432 ms\n",
      "Model: Base, Input Length 305: 1070.639 ms\n",
      "Model: Base, Input Length 278: 1091.403 ms\n",
      "Model: Base, Input Length 339: 1462.228 ms\n",
      "Model: Base, Input Length 433: 1553.429 ms\n",
      "Model: Base, Input Length 385: 1435.959 ms\n",
      "Model: Base, Input Length 317: 1142.853 ms\n",
      "Model: Base, Input Length 327: 1172.121 ms\n",
      "Model: Base, Input Length 583: 1589.475 ms\n",
      "Model: Base, Input Length 254: 819.062 ms\n",
      "Model: Base, Input Length 347: 1393.762 ms\n",
      "Model: Base, Input Length 305: 1047.474 ms\n",
      "Model: Base, Input Length 278: 1088.833 ms\n",
      "Model: Base, Input Length 339: 1492.230 ms\n",
      "Model: Base, Input Length 433: 1575.098 ms\n",
      "Model: Base, Input Length 385: 1466.510 ms\n",
      "Model: Base, Input Length 317: 1133.962 ms\n",
      "Model: Base, Input Length 327: 1191.919 ms\n",
      "Model: Base, Input Length 583: 1795.497 ms\n",
      "Model: Base, Input Length 254: 849.622 ms\n",
      "Model: Base, Input Length 347: 1417.528 ms\n",
      "Model: Base, Input Length 305: 1069.494 ms\n",
      "Model: Base, Input Length 278: 1207.014 ms\n",
      "Model: Base Quantized, Input Length 339: 1421.196 ms\n",
      "Model: Base Quantized, Input Length 433: 1559.086 ms\n",
      "Model: Base Quantized, Input Length 385: 1482.182 ms\n",
      "Model: Base Quantized, Input Length 317: 1146.766 ms\n",
      "Model: Base Quantized, Input Length 327: 1175.866 ms\n",
      "Model: Base Quantized, Input Length 583: 1613.131 ms\n",
      "Model: Base Quantized, Input Length 254: 832.478 ms\n",
      "Model: Base Quantized, Input Length 347: 1414.618 ms\n",
      "Model: Base Quantized, Input Length 305: 1048.955 ms\n",
      "Model: Base Quantized, Input Length 278: 1111.015 ms\n",
      "Model: Base Quantized, Input Length 339: 1415.656 ms\n",
      "Model: Base Quantized, Input Length 433: 1529.732 ms\n",
      "Model: Base Quantized, Input Length 385: 1412.958 ms\n",
      "Model: Base Quantized, Input Length 317: 1093.878 ms\n",
      "Model: Base Quantized, Input Length 327: 1171.193 ms\n",
      "Model: Base Quantized, Input Length 583: 1539.461 ms\n",
      "Model: Base Quantized, Input Length 254: 807.059 ms\n",
      "Model: Base Quantized, Input Length 347: 1370.702 ms\n",
      "Model: Base Quantized, Input Length 305: 1020.053 ms\n",
      "Model: Base Quantized, Input Length 278: 1077.331 ms\n",
      "Model: Base Quantized, Input Length 339: 1434.880 ms\n",
      "Model: Base Quantized, Input Length 433: 1554.028 ms\n",
      "Model: Base Quantized, Input Length 385: 1455.549 ms\n",
      "Model: Base Quantized, Input Length 317: 1132.752 ms\n",
      "Model: Base Quantized, Input Length 327: 1188.709 ms\n",
      "Model: Base Quantized, Input Length 583: 1614.288 ms\n",
      "Model: Base Quantized, Input Length 254: 876.871 ms\n",
      "Model: Base Quantized, Input Length 347: 1402.885 ms\n",
      "Model: Base Quantized, Input Length 305: 1059.677 ms\n",
      "Model: Base Quantized, Input Length 278: 1112.882 ms\n",
      "Model: Base Quantized, Input Length 339: 1400.076 ms\n",
      "Model: Base Quantized, Input Length 433: 1576.456 ms\n",
      "Model: Base Quantized, Input Length 385: 1415.567 ms\n",
      "Model: Base Quantized, Input Length 317: 1108.334 ms\n",
      "Model: Base Quantized, Input Length 327: 1152.311 ms\n",
      "Model: Base Quantized, Input Length 583: 1595.093 ms\n",
      "Model: Base Quantized, Input Length 254: 817.388 ms\n",
      "Model: Base Quantized, Input Length 347: 1387.544 ms\n",
      "Model: Base Quantized, Input Length 305: 1031.876 ms\n",
      "Model: Base Quantized, Input Length 278: 1066.390 ms\n",
      "Model: Base Quantized, Input Length 339: 1355.147 ms\n",
      "Model: Base Quantized, Input Length 433: 1535.317 ms\n",
      "Model: Base Quantized, Input Length 385: 1691.245 ms\n",
      "Model: Base Quantized, Input Length 317: 1128.953 ms\n",
      "Model: Base Quantized, Input Length 327: 1194.078 ms\n",
      "Model: Base Quantized, Input Length 583: 1729.056 ms\n",
      "Model: Base Quantized, Input Length 254: 843.078 ms\n",
      "Model: Base Quantized, Input Length 347: 1402.194 ms\n",
      "Model: Base Quantized, Input Length 305: 1091.246 ms\n",
      "Model: Base Quantized, Input Length 278: 1106.625 ms\n",
      "Model: ONNX, Input Length 339: 718.087 ms\n",
      "Model: ONNX, Input Length 433: 915.382 ms\n",
      "Model: ONNX, Input Length 385: 849.747 ms\n",
      "Model: ONNX, Input Length 317: 664.112 ms\n",
      "Model: ONNX, Input Length 327: 717.432 ms\n",
      "Model: ONNX, Input Length 583: 935.283 ms\n",
      "Model: ONNX, Input Length 254: 514.690 ms\n",
      "Model: ONNX, Input Length 347: 844.170 ms\n",
      "Model: ONNX, Input Length 305: 634.575 ms\n",
      "Model: ONNX, Input Length 278: 663.272 ms\n",
      "Model: ONNX, Input Length 339: 908.335 ms\n",
      "Model: ONNX, Input Length 433: 1120.028 ms\n",
      "Model: ONNX, Input Length 385: 900.401 ms\n",
      "Model: ONNX, Input Length 317: 716.121 ms\n",
      "Model: ONNX, Input Length 327: 808.314 ms\n",
      "Model: ONNX, Input Length 583: 1014.644 ms\n",
      "Model: ONNX, Input Length 254: 553.349 ms\n",
      "Model: ONNX, Input Length 347: 923.737 ms\n",
      "Model: ONNX, Input Length 305: 679.077 ms\n",
      "Model: ONNX, Input Length 278: 706.654 ms\n",
      "Model: ONNX, Input Length 339: 968.864 ms\n",
      "Model: ONNX, Input Length 433: 1073.778 ms\n",
      "Model: ONNX, Input Length 385: 944.486 ms\n",
      "Model: ONNX, Input Length 317: 760.976 ms\n",
      "Model: ONNX, Input Length 327: 799.233 ms\n",
      "Model: ONNX, Input Length 583: 1028.566 ms\n",
      "Model: ONNX, Input Length 254: 607.212 ms\n",
      "Model: ONNX, Input Length 347: 940.852 ms\n",
      "Model: ONNX, Input Length 305: 670.897 ms\n",
      "Model: ONNX, Input Length 278: 709.140 ms\n",
      "Model: ONNX, Input Length 339: 957.270 ms\n",
      "Model: ONNX, Input Length 433: 1057.655 ms\n",
      "Model: ONNX, Input Length 385: 958.856 ms\n",
      "Model: ONNX, Input Length 317: 748.547 ms\n",
      "Model: ONNX, Input Length 327: 805.076 ms\n",
      "Model: ONNX, Input Length 583: 1032.907 ms\n",
      "Model: ONNX, Input Length 254: 565.674 ms\n",
      "Model: ONNX, Input Length 347: 924.818 ms\n",
      "Model: ONNX, Input Length 305: 704.199 ms\n",
      "Model: ONNX, Input Length 278: 730.425 ms\n",
      "Model: ONNX, Input Length 339: 959.763 ms\n",
      "Model: ONNX, Input Length 433: 1070.190 ms\n",
      "Model: ONNX, Input Length 385: 941.690 ms\n",
      "Model: ONNX, Input Length 317: 755.912 ms\n",
      "Model: ONNX, Input Length 327: 809.887 ms\n",
      "Model: ONNX, Input Length 583: 1014.610 ms\n",
      "Model: ONNX, Input Length 254: 579.410 ms\n",
      "Model: ONNX, Input Length 347: 915.350 ms\n",
      "Model: ONNX, Input Length 305: 677.487 ms\n",
      "Model: ONNX, Input Length 278: 720.869 ms\n",
      "Model: ONNX-OPT, Input Length 339: 967.755 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1225.302 ms\n",
      "Model: ONNX-OPT, Input Length 385: 1014.002 ms\n",
      "Model: ONNX-OPT, Input Length 317: 737.472 ms\n",
      "Model: ONNX-OPT, Input Length 327: 1030.761 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1050.756 ms\n",
      "Model: ONNX-OPT, Input Length 254: 605.923 ms\n",
      "Model: ONNX-OPT, Input Length 347: 913.759 ms\n",
      "Model: ONNX-OPT, Input Length 305: 697.837 ms\n",
      "Model: ONNX-OPT, Input Length 278: 905.455 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1007.294 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1065.275 ms\n",
      "Model: ONNX-OPT, Input Length 385: 961.813 ms\n",
      "Model: ONNX-OPT, Input Length 317: 750.909 ms\n",
      "Model: ONNX-OPT, Input Length 327: 803.091 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1030.042 ms\n",
      "Model: ONNX-OPT, Input Length 254: 622.757 ms\n",
      "Model: ONNX-OPT, Input Length 347: 909.403 ms\n",
      "Model: ONNX-OPT, Input Length 305: 681.014 ms\n",
      "Model: ONNX-OPT, Input Length 278: 710.068 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1069.069 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1080.901 ms\n",
      "Model: ONNX-OPT, Input Length 385: 987.578 ms\n",
      "Model: ONNX-OPT, Input Length 317: 754.264 ms\n",
      "Model: ONNX-OPT, Input Length 327: 793.854 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1030.263 ms\n",
      "Model: ONNX-OPT, Input Length 254: 565.740 ms\n",
      "Model: ONNX-OPT, Input Length 347: 909.413 ms\n",
      "Model: ONNX-OPT, Input Length 305: 676.331 ms\n",
      "Model: ONNX-OPT, Input Length 278: 726.949 ms\n",
      "Model: ONNX-OPT, Input Length 339: 1070.736 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1068.168 ms\n",
      "Model: ONNX-OPT, Input Length 385: 932.434 ms\n",
      "Model: ONNX-OPT, Input Length 317: 761.952 ms\n",
      "Model: ONNX-OPT, Input Length 327: 820.684 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1038.712 ms\n",
      "Model: ONNX-OPT, Input Length 254: 574.005 ms\n",
      "Model: ONNX-OPT, Input Length 347: 908.546 ms\n",
      "Model: ONNX-OPT, Input Length 305: 683.016 ms\n",
      "Model: ONNX-OPT, Input Length 278: 721.640 ms\n",
      "Model: ONNX-OPT, Input Length 339: 996.582 ms\n",
      "Model: ONNX-OPT, Input Length 433: 1025.792 ms\n",
      "Model: ONNX-OPT, Input Length 385: 937.714 ms\n",
      "Model: ONNX-OPT, Input Length 317: 728.598 ms\n",
      "Model: ONNX-OPT, Input Length 327: 787.394 ms\n",
      "Model: ONNX-OPT, Input Length 583: 1059.231 ms\n",
      "Model: ONNX-OPT, Input Length 254: 572.007 ms\n",
      "Model: ONNX-OPT, Input Length 347: 925.293 ms\n",
      "Model: ONNX-OPT, Input Length 305: 686.552 ms\n",
      "Model: ONNX-OPT, Input Length 278: 709.143 ms\n",
      "Model: ONNX Quantized, Input Length 339: 793.502 ms\n",
      "Model: ONNX Quantized, Input Length 433: 964.027 ms\n",
      "Model: ONNX Quantized, Input Length 385: 764.580 ms\n",
      "Model: ONNX Quantized, Input Length 317: 606.166 ms\n",
      "Model: ONNX Quantized, Input Length 327: 651.155 ms\n",
      "Model: ONNX Quantized, Input Length 583: 836.566 ms\n",
      "Model: ONNX Quantized, Input Length 254: 447.248 ms\n",
      "Model: ONNX Quantized, Input Length 347: 719.913 ms\n",
      "Model: ONNX Quantized, Input Length 305: 538.091 ms\n",
      "Model: ONNX Quantized, Input Length 278: 587.474 ms\n",
      "Model: ONNX Quantized, Input Length 339: 768.481 ms\n",
      "Model: ONNX Quantized, Input Length 433: 923.274 ms\n",
      "Model: ONNX Quantized, Input Length 385: 735.479 ms\n",
      "Model: ONNX Quantized, Input Length 317: 569.436 ms\n",
      "Model: ONNX Quantized, Input Length 327: 616.074 ms\n",
      "Model: ONNX Quantized, Input Length 583: 807.592 ms\n",
      "Model: ONNX Quantized, Input Length 254: 444.489 ms\n",
      "Model: ONNX Quantized, Input Length 347: 717.828 ms\n",
      "Model: ONNX Quantized, Input Length 305: 524.420 ms\n",
      "Model: ONNX Quantized, Input Length 278: 545.211 ms\n",
      "Model: ONNX Quantized, Input Length 339: 717.318 ms\n",
      "Model: ONNX Quantized, Input Length 433: 851.887 ms\n",
      "Model: ONNX Quantized, Input Length 385: 726.572 ms\n",
      "Model: ONNX Quantized, Input Length 317: 578.038 ms\n",
      "Model: ONNX Quantized, Input Length 327: 634.867 ms\n",
      "Model: ONNX Quantized, Input Length 583: 814.744 ms\n",
      "Model: ONNX Quantized, Input Length 254: 437.124 ms\n",
      "Model: ONNX Quantized, Input Length 347: 711.462 ms\n",
      "Model: ONNX Quantized, Input Length 305: 533.331 ms\n",
      "Model: ONNX Quantized, Input Length 278: 706.579 ms\n",
      "Model: ONNX Quantized, Input Length 339: 638.964 ms\n",
      "Model: ONNX Quantized, Input Length 433: 946.822 ms\n",
      "Model: ONNX Quantized, Input Length 385: 761.961 ms\n",
      "Model: ONNX Quantized, Input Length 317: 585.807 ms\n",
      "Model: ONNX Quantized, Input Length 327: 628.039 ms\n",
      "Model: ONNX Quantized, Input Length 583: 936.731 ms\n",
      "Model: ONNX Quantized, Input Length 254: 429.094 ms\n",
      "Model: ONNX Quantized, Input Length 347: 704.108 ms\n",
      "Model: ONNX Quantized, Input Length 305: 531.903 ms\n",
      "Model: ONNX Quantized, Input Length 278: 570.134 ms\n",
      "Model: ONNX Quantized, Input Length 339: 737.709 ms\n",
      "Model: ONNX Quantized, Input Length 433: 838.487 ms\n",
      "Model: ONNX Quantized, Input Length 385: 731.786 ms\n",
      "Model: ONNX Quantized, Input Length 317: 594.088 ms\n",
      "Model: ONNX Quantized, Input Length 327: 645.526 ms\n",
      "Model: ONNX Quantized, Input Length 583: 857.553 ms\n",
      "Model: ONNX Quantized, Input Length 254: 426.539 ms\n",
      "Model: ONNX Quantized, Input Length 347: 699.633 ms\n",
      "Model: ONNX Quantized, Input Length 305: 509.551 ms\n",
      "Model: ONNX Quantized, Input Length 278: 540.119 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 616.382 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 907.586 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 718.347 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 559.306 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 614.171 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 819.719 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 409.514 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 701.193 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 541.285 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 670.907 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 800.535 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 802.277 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 721.105 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 548.568 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 604.622 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 779.885 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 411.869 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 699.201 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 533.594 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 563.671 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 750.690 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 840.549 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 733.449 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 564.755 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 617.344 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 808.852 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 468.140 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 706.142 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 528.285 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 545.612 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 633.913 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 928.270 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 729.967 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 579.878 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 626.149 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 812.462 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 420.747 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 716.757 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 545.330 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 560.788 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 339: 716.316 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 433: 865.672 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 385: 728.680 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 317: 565.831 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 327: 628.501 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 583: 800.779 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 254: 426.381 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 347: 704.175 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 305: 525.031 ms\n",
      "Model: ONNX-OPT Quantized, Input Length 278: 567.526 ms\n"
     ]
    }
   ],
   "source": [
    "data_amount = 100\n",
    "for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "    print(\"Loading: {} {}\".format(reader, adapter))\n",
    "    \n",
    "    #load adapter specific dataset\n",
    "    data_set_name = adapter\n",
    "    if data_set_name in [\"commonsense_qa\", \"social_i_qa\", \"multirc\"]:\n",
    "        continue\n",
    "    elif data_set_name == \"race\":\n",
    "        data = load_dataset(data_set_name, \"all\", split=f\"validation[:{data_amount}]\")\n",
    "    else: \n",
    "        data = load_dataset(data_set_name, split=f\"validation[:{data_amount}]\")\n",
    "    \n",
    "    print(f\"Loaded dataset: {data_set_name}\")\n",
    "\n",
    "    # build preped data\n",
    "    preped_data_set = []\n",
    "    for example in data:\n",
    "        if data_set_name == \"cosmos_qa\":\n",
    "            choices = [example[\"answer0\"], example[\"answer1\"], example[\"answer2\"], example[\"answer3\"]]\n",
    "            preped_data_set.append((example[\"question\"], example[\"context\"], choices))\n",
    "        elif data_set_name == \"quail\":\n",
    "            preped_data_set.append((example[\"question\"], example[\"context\"], example[\"answers\"]))\n",
    "        elif data_set_name == \"quartz\":\n",
    "            preped_data_set.append((example[\"question\"], example[\"para\"], example[\"choices\"][\"text\"]))\n",
    "        elif data_set_name ==\"race\":\n",
    "            preped_data_set.append((example[\"question\"], example[\"article\"], example[\"options\"]))\n",
    "            id_name = \"example_id\"\n",
    "            \n",
    "        else:\n",
    "            print(\"Error. Not implemented data_set. Dont know how to build preped_data_set.\")\n",
    "            Exception\n",
    "    print(\"Preped data\")\n",
    "\n",
    "    data_runs = 5\n",
    "    data_intervall = 10\n",
    "    \n",
    "    #load and eval base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "    default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "    adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "    default_model.active_adapters = adapter_name\n",
    "    performance_log(adapter, reader, mc_model_inference, \"Base\", default_model, tokenizer, preped_data_set, data_set_name, data_intervall, data_runs) \n",
    "    \n",
    "    #load and eval quant model\n",
    "    quantized_base_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "    performance_log(adapter, reader, mc_model_inference, \"Base Quantized\", quantized_base_model, tokenizer, preped_data_set, data_set_name, data_intervall, data_runs) \n",
    "    \n",
    "    #load onnx models\n",
    "    model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "    onnx_models_list = load_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "    onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"ONNX Quantized\", \"ONNX-OPT Quantized\"]\n",
    "\n",
    "    # eval onnx models\n",
    "    for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "        performance_log(adapter, reader, mc_onnx_inference, onnx_model_name, onnx_model, tokenizer, preped_data_set, data_set_name, data_intervall, data_runs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>time once (ms)</th>\n",
       "      <th>average_time 50 times (ms)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>data_id</th>\n",
       "      <th>data_set_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>364.140987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Do i need to go for a legal divorce ? I wanted...</td>\n",
       "      <td>Why is this person asking about divorce ?</td>\n",
       "      <td>['If he gets married in the church he wo nt ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cosmos_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Base</td>\n",
       "      <td>240.724087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>I watched the first McCain / Obama debate last...</td>\n",
       "      <td>How would this person be classified ?</td>\n",
       "      <td>['None of the above choices .', 'Liberal', 'Co...</td>\n",
       "      <td>10</td>\n",
       "      <td>cosmos_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Base</td>\n",
       "      <td>454.405308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117</td>\n",
       "      <td>So , while i was in the library in my old neig...</td>\n",
       "      <td>What did you do after realizing that your thin...</td>\n",
       "      <td>['I set about reporting the theft to the campu...</td>\n",
       "      <td>20</td>\n",
       "      <td>cosmos_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Base</td>\n",
       "      <td>268.949986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>At the beginning of the change there were jet ...</td>\n",
       "      <td>Why did jet airplanes allow us jump from one p...</td>\n",
       "      <td>['Because it was enough to add two or three co...</td>\n",
       "      <td>30</td>\n",
       "      <td>cosmos_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Base</td>\n",
       "      <td>261.901140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>Another thing I do n't appreciate is the shoot...</td>\n",
       "      <td>Why might I have problems with Jon playing a s...</td>\n",
       "      <td>[\"Because a shooting game involves violence bu...</td>\n",
       "      <td>40</td>\n",
       "      <td>cosmos_qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>940.914154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>583</td>\n",
       "      <td>What is one of the most boring and tiresome wo...</td>\n",
       "      <td>What can we learn about responsibility?</td>\n",
       "      <td>[\"It's of secondary importance to discipline.\"...</td>\n",
       "      <td>50</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>500.789881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>254</td>\n",
       "      <td>Children have their own rules in playing games...</td>\n",
       "      <td>The writer believes that   _  .</td>\n",
       "      <td>['children should make better rules for their ...</td>\n",
       "      <td>60</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>797.747374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>347</td>\n",
       "      <td>Before l tell you bow many hours a day people ...</td>\n",
       "      <td>According to the poll, the time people spend v...</td>\n",
       "      <td>['one to three hours', 'four to six hours', 'o...</td>\n",
       "      <td>70</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>599.487305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305</td>\n",
       "      <td>We are fortunate to be living in a time when a...</td>\n",
       "      <td>The writer's attitude toward the digital socie...</td>\n",
       "      <td>['critical', 'positive', 'neutral', 'negative']</td>\n",
       "      <td>80</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>620.810270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "      <td>Bali is an Indonesia island that is rich in in...</td>\n",
       "      <td>When a person dies in Bali, it is a common pra...</td>\n",
       "      <td>['express deep sorrow at his death', 'celebrat...</td>\n",
       "      <td>90</td>\n",
       "      <td>race</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name  time once (ms)  average_time 50 times (ms)  \\\n",
       "0                   Base      364.140987                         NaN   \n",
       "1                   Base      240.724087                         NaN   \n",
       "2                   Base      454.405308                         NaN   \n",
       "3                   Base      268.949986                         NaN   \n",
       "4                   Base      261.901140                         NaN   \n",
       "...                  ...             ...                         ...   \n",
       "2095  ONNX-OPT Quantized      940.914154                         NaN   \n",
       "2096  ONNX-OPT Quantized      500.789881                         NaN   \n",
       "2097  ONNX-OPT Quantized      797.747374                         NaN   \n",
       "2098  ONNX-OPT Quantized      599.487305                         NaN   \n",
       "2099  ONNX-OPT Quantized      620.810270                         NaN   \n",
       "\n",
       "      seq_length                                            context  \\\n",
       "0             92  Do i need to go for a legal divorce ? I wanted...   \n",
       "1             67  I watched the first McCain / Obama debate last...   \n",
       "2            117  So , while i was in the library in my old neig...   \n",
       "3             58  At the beginning of the change there were jet ...   \n",
       "4             62  Another thing I do n't appreciate is the shoot...   \n",
       "...          ...                                                ...   \n",
       "2095         583  What is one of the most boring and tiresome wo...   \n",
       "2096         254  Children have their own rules in playing games...   \n",
       "2097         347  Before l tell you bow many hours a day people ...   \n",
       "2098         305  We are fortunate to be living in a time when a...   \n",
       "2099         278  Bali is an Indonesia island that is rich in in...   \n",
       "\n",
       "                                               question  \\\n",
       "0             Why is this person asking about divorce ?   \n",
       "1                 How would this person be classified ?   \n",
       "2     What did you do after realizing that your thin...   \n",
       "3     Why did jet airplanes allow us jump from one p...   \n",
       "4     Why might I have problems with Jon playing a s...   \n",
       "...                                                 ...   \n",
       "2095            What can we learn about responsibility?   \n",
       "2096                    The writer believes that   _  .   \n",
       "2097  According to the poll, the time people spend v...   \n",
       "2098  The writer's attitude toward the digital socie...   \n",
       "2099  When a person dies in Bali, it is a common pra...   \n",
       "\n",
       "                                                choices  data_id data_set_name  \n",
       "0     ['If he gets married in the church he wo nt ha...        0     cosmos_qa  \n",
       "1     ['None of the above choices .', 'Liberal', 'Co...       10     cosmos_qa  \n",
       "2     ['I set about reporting the theft to the campu...       20     cosmos_qa  \n",
       "3     ['Because it was enough to add two or three co...       30     cosmos_qa  \n",
       "4     [\"Because a shooting game involves violence bu...       40     cosmos_qa  \n",
       "...                                                 ...      ...           ...  \n",
       "2095  [\"It's of secondary importance to discipline.\"...       50          race  \n",
       "2096  ['children should make better rules for their ...       60          race  \n",
       "2097  ['one to three hours', 'four to six hours', 'o...       70          race  \n",
       "2098    ['critical', 'positive', 'neutral', 'negative']       80          race  \n",
       "2099  ['express deep sorrow at his death', 'celebrat...       90          race  \n",
       "\n",
       "[2100 rows x 9 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"inference_time_mcq_2.csv\")\n",
    "df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = pd.read_csv(\"square_skills/impl_skills.csv\")\n",
    "# skill = \"multiple-choice\"\n",
    "# skills = load_skills(skill)\n",
    "\n",
    "skills = all_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_of_model(model):\n",
    "    # torch.save(model.state_dict(), \"temp.p\")\n",
    "    # size_of_model = os.path.getsize(\"temp.p\")/(1024*1024)\n",
    "    # print('Size (MB):', os.path.getsize(\"temp.p\")/(1024*1024))\n",
    "    # os.remove('temp.p')\n",
    "\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_of_model = (param_size + buffer_size) / 1024**2\n",
    "    return size_of_model\n",
    "\n",
    "def save_df(df_new, path_to_logger_file = \"logger_all.csv\"):\n",
    "    if os.path.exists(path_to_logger_file):\n",
    "        df_fin = pd.concat([pd.read_csv(path_to_logger_file), df_new])\n",
    "        df_fin.to_csv(path_to_logger_file,index=False)\n",
    "    else: \n",
    "        df_new.to_csv(path_to_logger_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3083.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.32056427001953\n",
      "388.361328125\n",
      "Loading: roberta-base boolq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4957.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.16434478759766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased cosmos_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4683.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.31763076782227\n",
      "388.361328125\n",
      "Loading: roberta-base cosmos_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 6042.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.1614112854004\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 5154.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4245.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased hotpotqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 5136.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base hotpotqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 5389.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased multirc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4431.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.32056427001953\n",
      "388.361328125\n",
      "Loading: roberta-base multirc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4322.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.16434478759766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased newsqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 5272.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base newsqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4057.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased quail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4918.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.31763076782227\n",
      "388.361328125\n",
      "Loading: roberta-base quail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4850.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.1614112854004\n",
      "446.2051086425781\n",
      "Loading: roberta-base quartz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3687.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.1614112854004\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased quoref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3666.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base quoref\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4131.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4655.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.31763076782227\n",
      "388.361328125\n",
      "Loading: roberta-base race\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3831.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.1614112854004\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased squad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3829.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base squad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 4761.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n",
      "Loading: bert-base-uncased squad_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 2830.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421.06763458251953\n",
      "388.361328125\n",
      "Loading: roberta-base squad_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3894.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478.91141510009766\n",
      "446.2051086425781\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"reader\", \"adapter\", \"base\", \"base_quant\", \"onnx\", \"onnx_quant\"])\n",
    "\n",
    "for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "    print(\"Loading: {} {}\".format(reader, adapter))\n",
    "\n",
    "\n",
    "    #load base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "    default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "    adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "    default_model.active_adapters = adapter_name\n",
    "    # get base model size\n",
    "    default_model_size = get_size_of_model(default_model)\n",
    "    print(default_model_size)\n",
    "    \n",
    "    #get quant model size\n",
    "    quantized_base_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "    quantized_base_model_size = get_size_of_model(quantized_base_model)\n",
    "    print(quantized_base_model_size)\n",
    "\n",
    "    try:\n",
    "        #load onnx model\n",
    "        onnx_model_size = os.path.getsize(f\"onnx/{reader}-pf-{adapter}-onnx/model.onnx\")/(1024*1024)\n",
    "        print(onnx_model_size)\n",
    "\n",
    "    except:\n",
    "        print(\"error while exporting onnx\")\n",
    "        onnx_model_size = \"error\"\n",
    "    \n",
    "    try:\n",
    "        # get onnx quant size \n",
    "        onnx_quant_model_size = os.path.getsize(f\"onnx/{reader}-pf-{adapter}-onnx/model_quant.onnx\")/(1024*1024)\n",
    "        print(onnx_quant_model_size)\n",
    "\n",
    "    except:\n",
    "        print(\"error while exporting onnx quant\")\n",
    "        onnx_quant_model_size = \"error\"\n",
    "\n",
    "        \n",
    "    df.loc[len(df)] = [reader, adapter, default_model_size, quantized_base_model_size, onnx_model_size, onnx_quant_model_size]\n",
    "save_df(df, path_to_logger_file=\"file_size_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Accuracy \n",
    "compare base model prediction to exported model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate all extractive qa model on squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_name = \"squad\"\n",
    "data = load_dataset(data_set_name, split=\"validation[:500]\")\n",
    "metric = evaluate.load(data_set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_evaluate(inference_func, model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs):\n",
    "    examples = list(zip(data[\"question\"], data[\"context\"]))\n",
    "    predictions = []\n",
    "    for example in examples:\n",
    "        _, task_outputs, _, _ = inference_func(model, tokenizer, [example], preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "        predictions.append(task_outputs[\"answers\"][0][0][\"answer\"])\n",
    "    \n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in zip(data[\"id\"], predictions)]\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in data]\n",
    "    \n",
    "    score = metric.compute(predictions=formatted_predictions, references=references)\n",
    "\n",
    "    return score[\"f1\"], score[\"exact_match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "    print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "    #load base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "    default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "    adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "    default_model.active_adapters = adapter_name\n",
    "\n",
    "    # Test acc for base model\n",
    "    f1, exact = squad_evaluate(base_qa, default_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "    result.append((\"Base\", skill, reader, adapter, f1, exact, data_set_name))\n",
    "\n",
    "    #load onnx models\n",
    "    model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "    onnx_models_list = load_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "    onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"Quantized ONNX\", \"Quantized ONNX - OPT\"]\n",
    "\n",
    "    # Test acc for onnx models\n",
    "    for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "        f1, exact = squad_evaluate(question_answering, onnx_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "        result.append((onnx_model_name, skill, reader, adapter, f1, exact, data_set_name))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=[\"name\", \"skill\", \"reader\", \"adapter\", \"f1\", \"exact\", \"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df, \"accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate extractive qa model on specific adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Retrieval Model</th>\n",
       "      <th>Datastore</th>\n",
       "      <th>Reader Model</th>\n",
       "      <th>Reader Adapter</th>\n",
       "      <th>Type</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DROP BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>drop</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DROP RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>drop</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HotpotQA BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HotpotQA RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NewsQA BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>newsqa</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NewsQA RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>newsqa</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quoref BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quoref</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Quoref RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quoref</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SQuAD 1.1 BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>squad</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SQuAD 1.1 RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SQuAD 2.0 BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SQuAD 2.0 RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>span-extraction</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Retrieval Model  Datastore       Reader Model  \\\n",
       "4           DROP BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "5        DROP RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "6       HotpotQA BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "7    HotpotQA RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "8         NewsQA BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "9      NewsQA RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "14        Quoref BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "15     Quoref RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "18     SQuAD 1.1 BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "19  SQuAD 1.1 RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "20     SQuAD 2.0 BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "21  SQuAD 2.0 RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "\n",
       "   Reader Adapter             Type  Code  \n",
       "4            drop  span-extraction  code  \n",
       "5            drop  span-extraction  code  \n",
       "6        hotpotqa  span-extraction  code  \n",
       "7        hotpotqa  span-extraction  code  \n",
       "8          newsqa  span-extraction  code  \n",
       "9          newsqa  span-extraction  code  \n",
       "14         quoref  span-extraction  code  \n",
       "15         quoref  span-extraction  code  \n",
       "18          squad  span-extraction  code  \n",
       "19          squad  span-extraction  code  \n",
       "20       squad_v2  span-extraction  code  \n",
       "21       squad_v2  span-extraction  code  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill =  \"span-extraction\"\n",
    "skills_df = load_skills(skill)\n",
    "skills_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "        \"skill\", \"reader\", \"adapter\", \n",
    "        \"timestamp\", \n",
    "        \"answer_base\", \n",
    "        \"answer_quantized_model\", \n",
    "        \"answer_onnx_model\", \n",
    "        \"answer_onnx_opt_model\", \n",
    "        \"answer_quant_onnx_model\", \n",
    "        \"answer_quant_onnx_opt_model\", \n",
    "        \"data_id\", \"dataset\", \"question\", \"context\", \"answer_dataset\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_get_results(adapter, inference_func, model, question, context, tokenizer):\n",
    "    _, task_outputs, _, _ = inference_func(model, tokenizer, question, context)\n",
    "    prediction = task_outputs[\"answers\"][0][0][\"answer\"]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "runs = 10\n",
    "for reader, adapter in zip(skills[\"Reader Model\"], skills[\"Reader Adapter\"]):\n",
    "    print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "    #load adapter specific dataset\n",
    "    data_set_name = adapter\n",
    "    if data_set_name in [\"newsqa\", \"hotpot_qa\"]:\n",
    "        continue\n",
    "    else: \n",
    "        data = load_dataset(data_set_name, split=f\"validation[:{runs}]\")\n",
    "        print(f\"Loaded dataset: {data_set_name}\")\n",
    "    \n",
    "    if adapter == \"drop\":\n",
    "        context_name = \"passage\"\n",
    "        id_name = \"query_id\"\n",
    "        answers_name = \"answers_spans\"\n",
    "    else:\n",
    "        context_name = \"context\"\n",
    "        id_name = \"id\"\n",
    "        answers_name = \"answers\"\n",
    "    \n",
    "    #load base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "    default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "    adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "    default_model.active_adapters = adapter_name\n",
    "    \n",
    "    # Get base results\n",
    "    base_model_result = extractive_get_results(adapter, base_qa, default_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "\n",
    "    #load and eval quant model \n",
    "    quantized_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "    quant_base_model_result = extractive_get_results(adapter, base_qa, quantized_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "\n",
    "    result.append((\"Quantized Base Model\", skill, reader, adapter, scoring, data_set_name, runs)) \n",
    "    \n",
    "    #load onnx models\n",
    "    model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "    onnx_models_list = load_onnx_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "    onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"Quantized ONNX\", \"Quantized ONNX - OPT\"] \n",
    "    \n",
    "    for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "        onnx = extractive_get_results(adapter, question_answering, onnx_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "\n",
    "        scoring = accuracy_scoring(base_model_result, onnx)\n",
    "\n",
    "        result.append((onnx_model_name, skill, reader, adapter, scoring, data_set_name, runs))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inf(\n",
    "        preped_data_set, modelname, run_func, input_model, tokenizer,\n",
    "    ):    \n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\n",
    "            \"skill\", \"reader\", \"adapter\", \n",
    "            \"timestamp\", \n",
    "            \"answer_base\", \n",
    "            \"answer_quantized_model\", \n",
    "            \"answer_onnx_model\", \n",
    "            \"answer_onnx_opt_model\", \n",
    "            \"answer_quant_onnx_model\", \n",
    "            \"answer_quant_onnx_opt_model\", \n",
    "            \"data_id\", \"dataset\", \"question\", \"context\", \"answer_dataset\"\n",
    "        ])\n",
    "\n",
    "    for data_id in tqdm(range(len(preped_data_set))):\n",
    "        \n",
    "        example_id = preped_data_set[data_id][0]\n",
    "        question = preped_data_set[data_id][1]\n",
    "        context = preped_data_set[data_id][2]\n",
    "        choices = preped_data_set[data_id][3]\n",
    "        answer_dataset = preped_data_set[data_id][4]\n",
    "        \n",
    "        answer, answer_logits = run_func(input_model, tokenizer, question, context, choices)   \n",
    "        data_set_name = adapter\n",
    "\n",
    "        df.loc[len(df)] = [\n",
    "            skill, reader, adapter, modelname,\n",
    "            pd.Timestamp.now(),\n",
    "            answer, answer_logits,\n",
    "            example_id, data_set_name, question, context[:90], choices, answer_dataset\n",
    "        ]\n",
    "    \n",
    "    save_df(df, f\"temp/{adapter}_{reader}_{modelname}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive_get_results(adapter, base_qa, quantized_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_amount = 1\n",
    "\n",
    "skipping_adapters = [\"newsqa\", \"hotpot_qa\"] \n",
    "# TODO quail for roberta\n",
    "for adapter in skills_df[\"Reader Adapter\"].unique():\n",
    "\n",
    "    if adapter in skipping_adapters:\n",
    "        print(f\"Skipping {adapter}\")\n",
    "        continue\n",
    "    \n",
    "    adapter_df = skills_df[skills_df[\"Reader Adapter\"] == adapter]\n",
    "\n",
    "    #load adapter specific dataset\n",
    "    data_set_name = adapter\n",
    "    if example_amount == 0:\n",
    "        data = load_dataset(data_set_name, split=f\"validation\")\n",
    "    else: \n",
    "        data = load_dataset(data_set_name, split=f\"validation[:{runs}]\")\n",
    "\n",
    "    if adapter == \"drop\":\n",
    "        context_name = \"passage\"\n",
    "        id_name = \"query_id\"\n",
    "        answers_name = \"answers_spans\"\n",
    "    else:\n",
    "        context_name = \"context\"\n",
    "        id_name = \"id\"\n",
    "        answers_name = \"answers\"\n",
    "\n",
    "    print(f\"Loaded and preped dataset: {data_set_name} with {len(data)} example questions\")\n",
    "\n",
    "    # load models\n",
    "    for reader in adapter_df[\"Reader Model\"].unique():\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "        #  load base model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "        base_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "        adapter_name = base_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "        base_model.active_adapters = adapter_name\n",
    "        \n",
    "        #load and eval quant model \n",
    "        quantized_base_model = torch.quantization.quantize_dynamic(base_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "        #load onnx models\n",
    "        model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "        onnx_model, onnx_model_opt, onnx_model_quant, onnx_model_quant_opt = load_onnx_model(model_onnx, model_onnx_quant)\n",
    "        \n",
    "        base_p = Process(target=run_inf, args=(preped_data_set, \"base\", mc_base_inference, base_model, tokenizer))\n",
    "        quant_base_p = Process(target=run_inf, args=(preped_data_set, \"quant_base\", mc_base_inference, quantized_base_model, tokenizer,))\n",
    "        onnx_p = Process(target=run_inf, args=(preped_data_set, \"onnx\", mc_onnx_inference, onnx_model, tokenizer))\n",
    "        onn_opt_p = Process(target=run_inf, args=(preped_data_set, \"onnx_opt\", mc_onnx_inference, onnx_model_opt, tokenizer))\n",
    "        quant_onnx_p = Process(target=run_inf, args=(preped_data_set, \"quant_onnx\", mc_onnx_inference, onnx_model_quant, tokenizer))\n",
    "        quant_onnx_opt_p = Process(target=run_inf, args=(preped_data_set, \"quant_onnx_opt\", mc_onnx_inference, onnx_model_quant_opt, tokenizer))\n",
    "    \n",
    "        base_p.start()\n",
    "        quant_base_p.start()\n",
    "        onnx_p.start()\n",
    "        onn_opt_p.start()\n",
    "        quant_onnx_p.start()\n",
    "        quant_onnx_opt_p.start()\n",
    "\n",
    "        base_p.join()\n",
    "        quant_base_p.join()\n",
    "        onnx_p.join()\n",
    "        onn_opt_p.join()\n",
    "        quant_onnx_p.join()\n",
    "        quant_onnx_opt_p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df, \"sim_base_to_onnx.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate categorical qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Retrieval Model</th>\n",
       "      <th>Datastore</th>\n",
       "      <th>Reader Model</th>\n",
       "      <th>Reader Adapter</th>\n",
       "      <th>Type</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoolQ BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>boolq</td>\n",
       "      <td>categorical</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoolQ RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>boolq</td>\n",
       "      <td>categorical</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Retrieval Model  Datastore       Reader Model  \\\n",
       "0     BoolQ BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "1  BoolQ RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "\n",
       "  Reader Adapter         Type  Code  \n",
       "0          boolq  categorical  code  \n",
       "1          boolq  categorical  code  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill = \"categorical\"\n",
    "skills_df = load_skills(skill)\n",
    "skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"skill\", \"reader\", \"adapter\", \"timestamp\", \n",
    "                \"answer_base\", \"logits_answer_base\",\n",
    "                \"answer_quantized_model\", \"logits_answer_quantized_model\", \n",
    "                \"answer_onnx_model\", \"logits_answer_onnx_model\",\n",
    "                \"answer_onnx_opt_model\", \"logits_answer_onnx_opt_model\",\n",
    "                \"answer_quant_onnx_model\", \"logits_answer_quant_onnx_model\",\n",
    "                \"answer_quant_onnx_opt_model\", \"logits_answer_quant_onnx_opt_model\",\n",
    "                \"data_id\", \"dataset\", \"question\", \"context\", \"answer_dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cosmos_qa (/Users/michaelhermann/.cache/huggingface/datasets/cosmos_qa/default/0.1.0/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: cosmos_qa with 2985 example questions\n",
      "Loading: bert-base-uncased cosmos_qa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:250: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:228: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3036.05it/s]\n",
      "  0%|          | 0/2985 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'passage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m data_id \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data))):\n\u001b[1;32m     30\u001b[0m     question \u001b[39m=\u001b[39m data[data_id][\u001b[39m\"\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 31\u001b[0m     context \u001b[39m=\u001b[39m data[data_id][\u001b[39m\"\u001b[39;49m\u001b[39mpassage\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     32\u001b[0m     answer_dataset \u001b[39m=\u001b[39m data[data_id][\u001b[39m\"\u001b[39m\u001b[39manswer\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     34\u001b[0m     \u001b[39m# Get base results\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'passage'"
     ]
    }
   ],
   "source": [
    "example_amount = 1\n",
    "\n",
    "for adapter in skills_df[\"Reader Adapter\"].unique():\n",
    "    \n",
    "    # load dataset\n",
    "    data_set_name = adapter\n",
    "    # data = load_dataset(data_set_name, split=f\"validation[:{example_amount}]\")\n",
    "    data = load_dataset(data_set_name, split=\"validation\")\n",
    "    print(f\"Loaded dataset: {data_set_name} with {len(data)} example questions\")\n",
    "\n",
    "    # load models\n",
    "    for reader in skills_df[\"Reader Model\"]:\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        #load base model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "        default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "        adapter_name = default_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "        default_model.active_adapters = adapter_name\n",
    "\n",
    "        #load quant model\n",
    "        quantized_base_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "        \n",
    "        #load onnx models\n",
    "        model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "        onnx_model, onnx_model_opt, onnx_model_quant, onnx_model_quant_opt = load_onnx_model(model_onnx, model_onnx_quant)\n",
    "        \n",
    "        for data_id in tqdm(range(len(data))):\n",
    "\n",
    "            question = data[data_id][\"question\"]\n",
    "            context = data[data_id][\"passage\"]\n",
    "            answer_dataset = data[data_id][\"answer\"]\n",
    "\n",
    "            # Get base results\n",
    "            base_model_answer, base_model_answer_logit = categorical_base_inference(default_model, tokenizer, question, context)\n",
    "            \n",
    "            # #eval quant model\n",
    "            quant_base_model_answer, quant_base_model_logit = categorical_base_inference(quantized_base_model, tokenizer, question, context)\n",
    "            \n",
    "            # eval onnx models\n",
    "            onnx_model_answer, onnx_model_answer_logit = categorical_onnx_inference(onnx_model, tokenizer, question, context)\n",
    "            onnx_opt_model_answer, onnx_opt_model_answer_logit = categorical_onnx_inference(onnx_model_opt, tokenizer, question, context)\n",
    "            quant_onnx_model_answer, quant_onnx_model_answer_logit = categorical_onnx_inference(onnx_model_quant, tokenizer, question, context)\n",
    "            quant_onnx_opt_model_answer, quant_onnx_opt_model_answer_logit = categorical_onnx_inference(onnx_model_quant_opt, tokenizer, question, context)\n",
    "\n",
    "            df.loc[len(df)] = [\n",
    "                skill, reader, adapter,\n",
    "                pd.Timestamp.now(),\n",
    "                base_model_answer, base_model_answer_logit.detach().numpy(), # returned tensor\n",
    "                quant_base_model_answer, quant_base_model_logit.detach().numpy(), # returned tensor\n",
    "                onnx_model_answer, onnx_model_answer_logit,\n",
    "                onnx_opt_model_answer, onnx_opt_model_answer_logit,\n",
    "                quant_onnx_model_answer, quant_onnx_model_answer_logit,\n",
    "                quant_onnx_opt_model_answer, quant_onnx_opt_model_answer_logit,\n",
    "                data_id, data_set_name, question, context, answer_dataset\n",
    "\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df, \"sim_base_to_onnx_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get results of acc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate mcq qa on specific adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Retrieval Model</th>\n",
       "      <th>Datastore</th>\n",
       "      <th>Reader Model</th>\n",
       "      <th>Reader Adapter</th>\n",
       "      <th>Type</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CosmosQA BERT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CosmosQA RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>QuAIL BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quail</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>QuAIL RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quail</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QuaRTz BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>QuaRTz RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RACE BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RACE RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>race</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Social-IQA BERT Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>social_i_qa</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Social-IQA RoBERTa Adapter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>social_i_qa</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  Retrieval Model  Datastore       Reader Model  \\\n",
       "2                CosmosQA BERT              NaN        NaN  bert-base-uncased   \n",
       "3     CosmosQA RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "10          QuAIL BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "11       QuAIL RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "12         QuaRTz BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "13      QuaRTz RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "16           RACE BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "17        RACE RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "23     Social-IQA BERT Adapter              NaN        NaN  bert-base-uncased   \n",
       "24  Social-IQA RoBERTa Adapter              NaN        NaN       roberta-base   \n",
       "\n",
       "   Reader Adapter             Type  Code  \n",
       "2       cosmos_qa  multiple-choice  code  \n",
       "3       cosmos_qa  multiple-choice  code  \n",
       "10          quail  multiple-choice  code  \n",
       "11          quail  multiple-choice  code  \n",
       "12         quartz  multiple-choice  code  \n",
       "13         quartz  multiple-choice  code  \n",
       "16           race  multiple-choice  code  \n",
       "17           race  multiple-choice  code  \n",
       "23    social_i_qa  multiple-choice  code  \n",
       "24    social_i_qa  multiple-choice  code  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill =  \"multiple-choice\"\n",
    "skills_df = load_skills(skill)\n",
    "skills_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some Models are not implemented for testing\n",
    "# \"commonsense_qa\", \n",
    "# non mcq: \"multirc\" is categorical (True/False)\n",
    "# TODO \"social_i_qa\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep_dataset(data_set_name, example_amount=0):\n",
    "    if example_amount == 0:\n",
    "        print(f\"Loading all example data of {data_set_name} dataset\")\n",
    "        split_size = f\"validation\" #loading complete dataset\n",
    "    else:\n",
    "        print(f\"Loading just {example_amount} example of {data_set_name} dataset\")\n",
    "        split_size = f\"validation[:{example_amount}]\" #loading only a part of the dataset\n",
    "        \n",
    "    preped_data_set = []\n",
    "    print(\"Now laoding dataset.\")\n",
    "\n",
    "    if data_set_name in [\"cosmos_qa\", \"quail\", \"quartz\"]:\n",
    "        data = load_dataset(data_set_name, split=split_size)\n",
    "    elif data_set_name == \"race\":\n",
    "        data = load_dataset(data_set_name, \"middle\", split=split_size)\n",
    "    elif data_set_name in [\"multi_rc\", \"commonsense_qa\", \"social_i_qa\"]: #social_i_qa not implemented\n",
    "        print(\"Error. Not implemented data_set. Don't know how to build preped_data_set.\")\n",
    "        return False\n",
    "    else: \n",
    "        print(\"Error. Not implemented data_set. Cant load dataset.\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Loaded dataset: {data_set_name}. Now preping dataset\")\n",
    "    \n",
    "    # build preped data \n",
    "    i = 0 #helper varibale for social_i_qa dataset\n",
    "    for example in data:\n",
    "        if data_set_name == \"cosmos_qa\":\n",
    "            example_id = example[\"id\"]\n",
    "            question = example[\"question\"]\n",
    "            context = example[\"context\"]\n",
    "            choices = [example[\"answer0\"], example[\"answer1\"], example[\"answer2\"], example[\"answer3\"]]\n",
    "            correct_answer = choices[example[\"label\"]]\n",
    "        elif data_set_name == \"quail\":\n",
    "            example_id = example[\"id\"]\n",
    "            question = example[\"question\"]\n",
    "            context = example[\"context\"]\n",
    "            choices = example[\"answers\"]\n",
    "            correct_answer = example[\"answers\"][example[\"correct_answer_id\"]]\n",
    "        elif data_set_name == \"quartz\":\n",
    "            example_id = example[\"id\"]\n",
    "            question = example[\"question\"]\n",
    "            context = example[\"para\"]\n",
    "            choices = example[\"choices\"][\"text\"]\n",
    "            correct_answer = example[\"choices\"][\"text\"][ord(example[\"answerKey\"])-65] # convert ASCII char to Int.\n",
    "        elif data_set_name ==\"race\":\n",
    "            example_id = example[\"example_id\"]\n",
    "            question = example[\"question\"]\n",
    "            context = example[\"article\"]\n",
    "            choices = example[\"options\"]\n",
    "            correct_answer = example[\"options\"][ord(example[\"answer\"])-65] # convert ASCII char to Int.  \n",
    "        elif data_set_name == \"social_i_qa\":\n",
    "            example_id = i\n",
    "            i+=1\n",
    "            question = example[\"question\"]\n",
    "            context = example[\"context\"]\n",
    "            choices = [example[\"answerA\"], example[\"answerB\"], example[\"answerC\"]]\n",
    "            correct_answer = choices[int(example[\"label\"])-1]\n",
    "        else:\n",
    "            print(\"Error. Not implemented data_set. Don't know how to build preped_data_set.\")\n",
    "            Exception\n",
    "        \n",
    "        preped_data_set.append((example_id, question, context, choices, correct_answer))\n",
    "    return preped_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "        \"skill\", \"reader\", \"adapter\", \n",
    "        \"timestamp\", \n",
    "        \"answer_base\", \"logits_answer_base\",\n",
    "        \"answer_quantized_model\", \"logits_answer_quantized_model\", \n",
    "        \"answer_onnx_model\", \"logits_answer_onnx_model\",\n",
    "        \"answer_onnx_opt_model\", \"logits_answer_onnx_opt_model\",\n",
    "        \"answer_quant_onnx_model\", \"logits_answer_quant_onnx_model\",\n",
    "        \"answer_quant_onnx_opt_model\", \"logits_answer_quant_onnx_opt_model\",\n",
    "        \"data_id\", \"dataset\", \"question\", \"context\", \"choices\", \"answer_dataset\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_amount = 0\n",
    "\n",
    "skipping_adapters = [\"cosmos_qa\", \"quail\", \"quartz\"] \n",
    "# TODO quail for roberta\n",
    "for adapter in skills_df[\"Reader Adapter\"].unique():\n",
    "\n",
    "    if adapter in skipping_adapters:\n",
    "        print(f\"Skipping {adapter}\")\n",
    "        continue\n",
    "\n",
    "    adapter_df = skills_df[skills_df[\"Reader Adapter\"] == adapter]\n",
    "    # load dataset\n",
    "    data_set_name = adapter\n",
    "    preped_data_set = load_and_prep_dataset(data_set_name, example_amount=example_amount)\n",
    "    \n",
    "    if not preped_data_set:\n",
    "        continue\n",
    "    print(f\"Loaded and preped dataset: {data_set_name} with {len(preped_data_set)} example questions\")\n",
    "\n",
    "    # load models\n",
    "    for reader in adapter_df[\"Reader Model\"].unique():\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "        #  load base model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "        base_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "        adapter_name = base_model.load_adapter(f\"AdapterHub/{reader}-pf-{adapter}\", source=\"hf\")\n",
    "        base_model.active_adapters = adapter_name\n",
    "        \n",
    "        #load and eval quant model \n",
    "        quantized_base_model = torch.quantization.quantize_dynamic(base_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "        #load onnx models\n",
    "        model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "        onnx_model, onnx_model_opt, onnx_model_quant, onnx_model_quant_opt = load_onnx_model(model_onnx, model_onnx_quant)\n",
    "        \n",
    "        for data_id in tqdm(range(len(preped_data_set))):\n",
    "            \n",
    "            example_id = preped_data_set[data_id][0]\n",
    "            question = preped_data_set[data_id][1]\n",
    "            context = preped_data_set[data_id][2]\n",
    "            choices = preped_data_set[data_id][3]\n",
    "            answer_dataset = preped_data_set[data_id][4]\n",
    "            \n",
    "            # Get base results\n",
    "            base_model_answer, base_model_answer_logit = mc_base_inference(base_model, tokenizer, question, context, choices)\n",
    "            \n",
    "            # #eval quant model\n",
    "            quant_base_model_answer, quant_base_model_logit = mc_base_inference(quantized_base_model, tokenizer, question, context, choices)\n",
    "            \n",
    "            # eval onnx models\n",
    "            onnx_model_answer, onnx_model_answer_logit = mc_onnx_inference(onnx_model, tokenizer, question, context, choices)\n",
    "            onnx_opt_model_answer, onnx_opt_model_answer_logit = mc_onnx_inference(onnx_model_opt, tokenizer, question, context, choices)\n",
    "            quant_onnx_model_answer, quant_onnx_model_answer_logit = mc_onnx_inference(onnx_model_quant, tokenizer, question, context, choices)\n",
    "            quant_onnx_opt_model_answer, quant_onnx_opt_model_answer_logit = mc_onnx_inference(onnx_model_quant_opt, tokenizer, question, context, choices)\n",
    "            \n",
    "            df.loc[len(df)] = [\n",
    "                skill, reader, adapter,\n",
    "                pd.Timestamp.now(),\n",
    "                base_model_answer, base_model_answer_logit.detach().numpy(), # returned tensor\n",
    "                quant_base_model_answer, quant_base_model_logit.detach().numpy(), # returned tensor\n",
    "                onnx_model_answer, onnx_model_answer_logit,\n",
    "                onnx_opt_model_answer, onnx_opt_model_answer_logit,\n",
    "                quant_onnx_model_answer, quant_onnx_model_answer_logit,\n",
    "                quant_onnx_opt_model_answer, quant_onnx_opt_model_answer_logit,\n",
    "                example_id, data_set_name, question, context[:90], choices, answer_dataset\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>reader</th>\n",
       "      <th>adapter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>answer_base</th>\n",
       "      <th>logits_answer_base</th>\n",
       "      <th>answer_quantized_model</th>\n",
       "      <th>logits_answer_quantized_model</th>\n",
       "      <th>answer_onnx_model</th>\n",
       "      <th>logits_answer_onnx_model</th>\n",
       "      <th>...</th>\n",
       "      <th>answer_quant_onnx_model</th>\n",
       "      <th>logits_answer_quant_onnx_model</th>\n",
       "      <th>answer_quant_onnx_opt_model</th>\n",
       "      <th>logits_answer_quant_onnx_opt_model</th>\n",
       "      <th>data_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:05:46.014108</td>\n",
       "      <td>increase</td>\n",
       "      <td>[[-0.32308546, -0.30430058]]</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[-0.308659, -0.31289622]]</td>\n",
       "      <td>increase</td>\n",
       "      <td>[[-0.4425696, -0.42104053]]</td>\n",
       "      <td>...</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[-0.3296341, -0.37187508]]</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[-0.3296341, -0.37187508]]</td>\n",
       "      <td>QRQA-10372-1-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>If Jim moves some particles of matter farther ...</td>\n",
       "      <td>When particles of matter are closer together, ...</td>\n",
       "      <td>[decrease, increase]</td>\n",
       "      <td>decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:05:46.371430</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-0.4190234, -0.41873103]]</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[-0.41074574, -0.42236027]]</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-0.3726902, -0.35832736]]</td>\n",
       "      <td>...</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-0.09447962, -0.052512124]]</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-0.09447962, -0.052512124]]</td>\n",
       "      <td>QRQA-10371-4-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Long ago the surface of Venus warmed enough th...</td>\n",
       "      <td>An increase in greenhouse gases leads to great...</td>\n",
       "      <td>[increased, decreased]</td>\n",
       "      <td>decreased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:05:46.770601</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.23802754, -0.16951808]]</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.25703636, -0.19954418]]</td>\n",
       "      <td>more</td>\n",
       "      <td>[[-0.14772616, -0.27151406]]</td>\n",
       "      <td>...</td>\n",
       "      <td>more</td>\n",
       "      <td>[[0.04064788, -0.005649729]]</td>\n",
       "      <td>more</td>\n",
       "      <td>[[0.04064788, -0.005649729]]</td>\n",
       "      <td>QRQA-10296-1-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>If less waters falls on an area of land it wil...</td>\n",
       "      <td>As more water covered the land, sand and silt ...</td>\n",
       "      <td>[more, less]</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:05:47.174047</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-0.4421321, -0.43315184]]</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-0.43794847, -0.43287364]]</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-0.4584921, -0.42407662]]</td>\n",
       "      <td>...</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-0.18492502, -0.16221972]]</td>\n",
       "      <td>open</td>\n",
       "      <td>[[-0.18492502, -0.16221972]]</td>\n",
       "      <td>QRQA-10115-3</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Rich applies a solution to the dish that incre...</td>\n",
       "      <td>The increase in turgor pressure of the guard c...</td>\n",
       "      <td>[close, open]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:05:47.519285</td>\n",
       "      <td>younger</td>\n",
       "      <td>[[-0.25191066, -0.23725833]]</td>\n",
       "      <td>younger</td>\n",
       "      <td>[[-0.2438518, -0.21938437]]</td>\n",
       "      <td>older</td>\n",
       "      <td>[[-0.29735819, -0.30204332]]</td>\n",
       "      <td>...</td>\n",
       "      <td>younger</td>\n",
       "      <td>[[0.000687332, 0.018745586]]</td>\n",
       "      <td>younger</td>\n",
       "      <td>[[0.000687332, 0.018745586]]</td>\n",
       "      <td>QRQA-10082-1</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Simon was digging in his yard and found that t...</td>\n",
       "      <td>Therefore, deeper rock layers must be older th...</td>\n",
       "      <td>[older, younger]</td>\n",
       "      <td>older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>2023-01-23 15:33:21.106616</td>\n",
       "      <td>in the city's Royal Infirmary</td>\n",
       "      <td>[[-3.917631, -6.4893255, -5.9038916, -8.029111]]</td>\n",
       "      <td>in the city's Royal Infirmary</td>\n",
       "      <td>[[-4.3647966, -6.3341856, -5.713045, -8.156919]]</td>\n",
       "      <td>in the city's Royal Infirmary</td>\n",
       "      <td>[[-0.6763504, -0.72670203, -0.7026611, -0.7307...</td>\n",
       "      <td>...</td>\n",
       "      <td>in the city's Royal Infirmary</td>\n",
       "      <td>[[-1.1538754, -1.6065819, -1.6095581, -1.49463...</td>\n",
       "      <td>in the city's Royal Infirmary</td>\n",
       "      <td>[[-1.1538754, -1.6065819, -1.6095581, -1.49463...</td>\n",
       "      <td>high4931.txt</td>\n",
       "      <td>race</td>\n",
       "      <td>Carmen Blake, the 27-year-old mother, gave gir...</td>\n",
       "      <td>Mother-of-three Carmen Blake called her midwif...</td>\n",
       "      <td>[in the city's Royal Infirmary, in the ambulan...</td>\n",
       "      <td>in the street on her way to hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>2023-01-23 15:33:25.883003</td>\n",
       "      <td>there were not enough ambulance in the Royal I...</td>\n",
       "      <td>[[-4.259598, -6.2071323, -6.157572, -5.3511953]]</td>\n",
       "      <td>there were not enough ambulance in the Royal I...</td>\n",
       "      <td>[[-4.143508, -6.141632, -6.0479107, -5.3279276]]</td>\n",
       "      <td>there were not enough ambulance in the Royal I...</td>\n",
       "      <td>[[-1.0495282, -1.0743983, -1.3698975, -1.27539...</td>\n",
       "      <td>...</td>\n",
       "      <td>the maternity ward said Ms Blake ought to call...</td>\n",
       "      <td>[[-1.5933855, -1.8198922, -1.6915305, -1.33661...</td>\n",
       "      <td>the maternity ward said Ms Blake ought to call...</td>\n",
       "      <td>[[-1.5933855, -1.8198922, -1.6915305, -1.33661...</td>\n",
       "      <td>high4931.txt</td>\n",
       "      <td>race</td>\n",
       "      <td>It can be inferred that  _  .</td>\n",
       "      <td>Mother-of-three Carmen Blake called her midwif...</td>\n",
       "      <td>[there were not enough ambulance in the Royal ...</td>\n",
       "      <td>the maternity ward said Ms Blake only needed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>2023-01-23 15:33:30.686327</td>\n",
       "      <td>failing to send an ambulance to help her</td>\n",
       "      <td>[[-2.0323603, -9.8245, -5.6678953, -9.328723]]</td>\n",
       "      <td>failing to send an ambulance to help her</td>\n",
       "      <td>[[-2.2095993, -9.937094, -5.8011723, -8.906239]]</td>\n",
       "      <td>failing to send an ambulance to help her</td>\n",
       "      <td>[[-0.6847511, -0.8641702, -0.93433905, -0.7369...</td>\n",
       "      <td>...</td>\n",
       "      <td>having killed her newly-born baby</td>\n",
       "      <td>[[-1.7267761, -1.033859, -1.3351793, -1.3934815]]</td>\n",
       "      <td>having killed her newly-born baby</td>\n",
       "      <td>[[-1.7267761, -1.033859, -1.3351793, -1.3934815]]</td>\n",
       "      <td>high4931.txt</td>\n",
       "      <td>race</td>\n",
       "      <td>Carmen Blake accused the Royal Infirmary of  _  .</td>\n",
       "      <td>Mother-of-three Carmen Blake called her midwif...</td>\n",
       "      <td>[failing to send an ambulance to help her, hav...</td>\n",
       "      <td>failing to send an ambulance to help her</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>2023-01-23 15:33:38.350756</td>\n",
       "      <td>some experts in education</td>\n",
       "      <td>[[-2.3059714, -0.6309271, -1.1633444, 0.229082...</td>\n",
       "      <td>some experts in education</td>\n",
       "      <td>[[-1.9526169, -0.77610993, -1.026824, 0.719092...</td>\n",
       "      <td>the Ban bossy campaigners</td>\n",
       "      <td>[[2.3862607, 2.43561, 2.2959297, 2.2583227]]</td>\n",
       "      <td>...</td>\n",
       "      <td>the Oxford English Dictionary</td>\n",
       "      <td>[[2.4741068, 1.9389747, 1.8998454, 2.3113618]]</td>\n",
       "      <td>the Oxford English Dictionary</td>\n",
       "      <td>[[2.4741068, 1.9389747, 1.8998454, 2.3113618]]</td>\n",
       "      <td>high19651.txt</td>\n",
       "      <td>race</td>\n",
       "      <td>More evidence is provided to show\" bossy\" is m...</td>\n",
       "      <td>Face-book chief operating officer Sheryl Sandb...</td>\n",
       "      <td>[the Oxford English Dictionary, the Ban bossy ...</td>\n",
       "      <td>the Ban bossy campaigners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>race</td>\n",
       "      <td>2023-01-23 15:33:45.380745</td>\n",
       "      <td>her farther considers her that way</td>\n",
       "      <td>[[-3.906163, -7.774066, -7.0138483, -0.19719648]]</td>\n",
       "      <td>her farther considers her that way</td>\n",
       "      <td>[[-3.4221442, -7.8213654, -6.9444323, 0.162878...</td>\n",
       "      <td>she is expected to lead in her family</td>\n",
       "      <td>[[3.462913, 3.1268995, 3.134274, 3.453897]]</td>\n",
       "      <td>...</td>\n",
       "      <td>she is expected to lead in her family</td>\n",
       "      <td>[[2.6243415, 2.0399854, 2.255232, 2.3063152]]</td>\n",
       "      <td>she is expected to lead in her family</td>\n",
       "      <td>[[2.6243415, 2.0399854, 2.255232, 2.3063152]]</td>\n",
       "      <td>high19651.txt</td>\n",
       "      <td>race</td>\n",
       "      <td>Trim's family still consider her bossy because...</td>\n",
       "      <td>Face-book chief operating officer Sheryl Sandb...</td>\n",
       "      <td>[she is expected to lead in her family, she is...</td>\n",
       "      <td>she is a powerful and confident female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                skill             reader adapter                  timestamp  \\\n",
       "0     multiple-choice  bert-base-uncased  quartz 2023-01-23 14:05:46.014108   \n",
       "1     multiple-choice  bert-base-uncased  quartz 2023-01-23 14:05:46.371430   \n",
       "2     multiple-choice  bert-base-uncased  quartz 2023-01-23 14:05:46.770601   \n",
       "3     multiple-choice  bert-base-uncased  quartz 2023-01-23 14:05:47.174047   \n",
       "4     multiple-choice  bert-base-uncased  quartz 2023-01-23 14:05:47.519285   \n",
       "...               ...                ...     ...                        ...   \n",
       "1475  multiple-choice  bert-base-uncased    race 2023-01-23 15:33:21.106616   \n",
       "1476  multiple-choice  bert-base-uncased    race 2023-01-23 15:33:25.883003   \n",
       "1477  multiple-choice  bert-base-uncased    race 2023-01-23 15:33:30.686327   \n",
       "1478  multiple-choice  bert-base-uncased    race 2023-01-23 15:33:38.350756   \n",
       "1479  multiple-choice  bert-base-uncased    race 2023-01-23 15:33:45.380745   \n",
       "\n",
       "                                            answer_base  \\\n",
       "0                                              increase   \n",
       "1                                             decreased   \n",
       "2                                                  less   \n",
       "3                                                  open   \n",
       "4                                               younger   \n",
       "...                                                 ...   \n",
       "1475                      in the city's Royal Infirmary   \n",
       "1476  there were not enough ambulance in the Royal I...   \n",
       "1477           failing to send an ambulance to help her   \n",
       "1478                          some experts in education   \n",
       "1479                 her farther considers her that way   \n",
       "\n",
       "                                     logits_answer_base  \\\n",
       "0                          [[-0.32308546, -0.30430058]]   \n",
       "1                           [[-0.4190234, -0.41873103]]   \n",
       "2                          [[-0.23802754, -0.16951808]]   \n",
       "3                           [[-0.4421321, -0.43315184]]   \n",
       "4                          [[-0.25191066, -0.23725833]]   \n",
       "...                                                 ...   \n",
       "1475   [[-3.917631, -6.4893255, -5.9038916, -8.029111]]   \n",
       "1476   [[-4.259598, -6.2071323, -6.157572, -5.3511953]]   \n",
       "1477     [[-2.0323603, -9.8245, -5.6678953, -9.328723]]   \n",
       "1478  [[-2.3059714, -0.6309271, -1.1633444, 0.229082...   \n",
       "1479  [[-3.906163, -7.774066, -7.0138483, -0.19719648]]   \n",
       "\n",
       "                                 answer_quantized_model  \\\n",
       "0                                              decrease   \n",
       "1                                             increased   \n",
       "2                                                  less   \n",
       "3                                                  open   \n",
       "4                                               younger   \n",
       "...                                                 ...   \n",
       "1475                      in the city's Royal Infirmary   \n",
       "1476  there were not enough ambulance in the Royal I...   \n",
       "1477           failing to send an ambulance to help her   \n",
       "1478                          some experts in education   \n",
       "1479                 her farther considers her that way   \n",
       "\n",
       "                          logits_answer_quantized_model  \\\n",
       "0                            [[-0.308659, -0.31289622]]   \n",
       "1                          [[-0.41074574, -0.42236027]]   \n",
       "2                          [[-0.25703636, -0.19954418]]   \n",
       "3                          [[-0.43794847, -0.43287364]]   \n",
       "4                           [[-0.2438518, -0.21938437]]   \n",
       "...                                                 ...   \n",
       "1475   [[-4.3647966, -6.3341856, -5.713045, -8.156919]]   \n",
       "1476   [[-4.143508, -6.141632, -6.0479107, -5.3279276]]   \n",
       "1477   [[-2.2095993, -9.937094, -5.8011723, -8.906239]]   \n",
       "1478  [[-1.9526169, -0.77610993, -1.026824, 0.719092...   \n",
       "1479  [[-3.4221442, -7.8213654, -6.9444323, 0.162878...   \n",
       "\n",
       "                                      answer_onnx_model  \\\n",
       "0                                              increase   \n",
       "1                                             decreased   \n",
       "2                                                  more   \n",
       "3                                                  open   \n",
       "4                                                 older   \n",
       "...                                                 ...   \n",
       "1475                      in the city's Royal Infirmary   \n",
       "1476  there were not enough ambulance in the Royal I...   \n",
       "1477           failing to send an ambulance to help her   \n",
       "1478                          the Ban bossy campaigners   \n",
       "1479              she is expected to lead in her family   \n",
       "\n",
       "                               logits_answer_onnx_model  ...  \\\n",
       "0                           [[-0.4425696, -0.42104053]]  ...   \n",
       "1                           [[-0.3726902, -0.35832736]]  ...   \n",
       "2                          [[-0.14772616, -0.27151406]]  ...   \n",
       "3                           [[-0.4584921, -0.42407662]]  ...   \n",
       "4                          [[-0.29735819, -0.30204332]]  ...   \n",
       "...                                                 ...  ...   \n",
       "1475  [[-0.6763504, -0.72670203, -0.7026611, -0.7307...  ...   \n",
       "1476  [[-1.0495282, -1.0743983, -1.3698975, -1.27539...  ...   \n",
       "1477  [[-0.6847511, -0.8641702, -0.93433905, -0.7369...  ...   \n",
       "1478       [[2.3862607, 2.43561, 2.2959297, 2.2583227]]  ...   \n",
       "1479        [[3.462913, 3.1268995, 3.134274, 3.453897]]  ...   \n",
       "\n",
       "                                answer_quant_onnx_model  \\\n",
       "0                                              decrease   \n",
       "1                                             decreased   \n",
       "2                                                  more   \n",
       "3                                                  open   \n",
       "4                                               younger   \n",
       "...                                                 ...   \n",
       "1475                      in the city's Royal Infirmary   \n",
       "1476  the maternity ward said Ms Blake ought to call...   \n",
       "1477                  having killed her newly-born baby   \n",
       "1478                      the Oxford English Dictionary   \n",
       "1479              she is expected to lead in her family   \n",
       "\n",
       "                         logits_answer_quant_onnx_model  \\\n",
       "0                           [[-0.3296341, -0.37187508]]   \n",
       "1                         [[-0.09447962, -0.052512124]]   \n",
       "2                          [[0.04064788, -0.005649729]]   \n",
       "3                          [[-0.18492502, -0.16221972]]   \n",
       "4                          [[0.000687332, 0.018745586]]   \n",
       "...                                                 ...   \n",
       "1475  [[-1.1538754, -1.6065819, -1.6095581, -1.49463...   \n",
       "1476  [[-1.5933855, -1.8198922, -1.6915305, -1.33661...   \n",
       "1477  [[-1.7267761, -1.033859, -1.3351793, -1.3934815]]   \n",
       "1478     [[2.4741068, 1.9389747, 1.8998454, 2.3113618]]   \n",
       "1479      [[2.6243415, 2.0399854, 2.255232, 2.3063152]]   \n",
       "\n",
       "                            answer_quant_onnx_opt_model  \\\n",
       "0                                              decrease   \n",
       "1                                             decreased   \n",
       "2                                                  more   \n",
       "3                                                  open   \n",
       "4                                               younger   \n",
       "...                                                 ...   \n",
       "1475                      in the city's Royal Infirmary   \n",
       "1476  the maternity ward said Ms Blake ought to call...   \n",
       "1477                  having killed her newly-born baby   \n",
       "1478                      the Oxford English Dictionary   \n",
       "1479              she is expected to lead in her family   \n",
       "\n",
       "                     logits_answer_quant_onnx_opt_model            data_id  \\\n",
       "0                           [[-0.3296341, -0.37187508]]  QRQA-10372-1-flip   \n",
       "1                         [[-0.09447962, -0.052512124]]  QRQA-10371-4-flip   \n",
       "2                          [[0.04064788, -0.005649729]]  QRQA-10296-1-flip   \n",
       "3                          [[-0.18492502, -0.16221972]]       QRQA-10115-3   \n",
       "4                          [[0.000687332, 0.018745586]]       QRQA-10082-1   \n",
       "...                                                 ...                ...   \n",
       "1475  [[-1.1538754, -1.6065819, -1.6095581, -1.49463...       high4931.txt   \n",
       "1476  [[-1.5933855, -1.8198922, -1.6915305, -1.33661...       high4931.txt   \n",
       "1477  [[-1.7267761, -1.033859, -1.3351793, -1.3934815]]       high4931.txt   \n",
       "1478     [[2.4741068, 1.9389747, 1.8998454, 2.3113618]]      high19651.txt   \n",
       "1479      [[2.6243415, 2.0399854, 2.255232, 2.3063152]]      high19651.txt   \n",
       "\n",
       "     dataset                                           question  \\\n",
       "0     quartz  If Jim moves some particles of matter farther ...   \n",
       "1     quartz  Long ago the surface of Venus warmed enough th...   \n",
       "2     quartz  If less waters falls on an area of land it wil...   \n",
       "3     quartz  Rich applies a solution to the dish that incre...   \n",
       "4     quartz  Simon was digging in his yard and found that t...   \n",
       "...      ...                                                ...   \n",
       "1475    race  Carmen Blake, the 27-year-old mother, gave gir...   \n",
       "1476    race                      It can be inferred that  _  .   \n",
       "1477    race  Carmen Blake accused the Royal Infirmary of  _  .   \n",
       "1478    race  More evidence is provided to show\" bossy\" is m...   \n",
       "1479    race  Trim's family still consider her bossy because...   \n",
       "\n",
       "                                                context  \\\n",
       "0     When particles of matter are closer together, ...   \n",
       "1     An increase in greenhouse gases leads to great...   \n",
       "2     As more water covered the land, sand and silt ...   \n",
       "3     The increase in turgor pressure of the guard c...   \n",
       "4     Therefore, deeper rock layers must be older th...   \n",
       "...                                                 ...   \n",
       "1475  Mother-of-three Carmen Blake called her midwif...   \n",
       "1476  Mother-of-three Carmen Blake called her midwif...   \n",
       "1477  Mother-of-three Carmen Blake called her midwif...   \n",
       "1478  Face-book chief operating officer Sheryl Sandb...   \n",
       "1479  Face-book chief operating officer Sheryl Sandb...   \n",
       "\n",
       "                                                choices  \\\n",
       "0                                  [decrease, increase]   \n",
       "1                                [increased, decreased]   \n",
       "2                                          [more, less]   \n",
       "3                                         [close, open]   \n",
       "4                                      [older, younger]   \n",
       "...                                                 ...   \n",
       "1475  [in the city's Royal Infirmary, in the ambulan...   \n",
       "1476  [there were not enough ambulance in the Royal ...   \n",
       "1477  [failing to send an ambulance to help her, hav...   \n",
       "1478  [the Oxford English Dictionary, the Ban bossy ...   \n",
       "1479  [she is expected to lead in her family, she is...   \n",
       "\n",
       "                                         answer_dataset  \n",
       "0                                              decrease  \n",
       "1                                             decreased  \n",
       "2                                                  less  \n",
       "3                                                  open  \n",
       "4                                                 older  \n",
       "...                                                 ...  \n",
       "1475               in the street on her way to hospital  \n",
       "1476  the maternity ward said Ms Blake only needed a...  \n",
       "1477           failing to send an ambulance to help her  \n",
       "1478                          the Ban bossy campaigners  \n",
       "1479             she is a powerful and confident female  \n",
       "\n",
       "[1480 rows x 22 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(df, \"sim_base_to_onnx_mcq.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_skills = pd.read_csv(\"square_skills/impl_skills.csv\")\n",
    "skill = \"abstractive\"\n",
    "skills = load_skills(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "runs = 250\n",
    "reader = \"facebook/bart-base\"\n",
    "adapter = \"narrativeqa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset narrativeqa (/Users/michaelhermann/.cache/huggingface/datasets/narrativeqa/default/0.0.0/daef7ccc51ec258bef464658d11751bb20f033da9b4c219fd84563b3a4af0422)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: narrativeqa\n"
     ]
    }
   ],
   "source": [
    "#load adapter specific dataset\n",
    "data_set_name = adapter\n",
    "data = load_dataset(data_set_name, split=f\"validation[:{runs}]\")\n",
    "print(f\"Loaded dataset: {data_set_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 6 files: 100%|| 6/6 [00:00<00:00, 3303.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#load base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(reader)\n",
    "default_model = AutoModelWithHeads.from_pretrained(reader)\n",
    "adapter_name = default_model.load_adapter(f\"AdapterHub/{adapter}\", source=\"hf\", set_active=True)\n",
    "default_model.active_adapters = adapter_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_scoring(pred_list, true_val_list):\n",
    "    hit = 0\n",
    "    for pred, true_val in zip(pred_list, true_val_list):\n",
    "        if pred in true_val:\n",
    "            hit += 1\n",
    "    return hit/len(pred_list)\n",
    "\n",
    "def base_inference(tokenizer, model, data):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for example in data:\n",
    "        # print(i)\n",
    "        try:\n",
    "            text = example[\"document\"][\"summary\"][\"text\"]\n",
    "            question = example[\"question\"][\"text\"]\n",
    "            id = example[\"document\"][\"id\"]\n",
    "\n",
    "            prompt = question + \"</s>\" + text + \"</s>\"\n",
    "\n",
    "            if len(prompt.split()) > 1024:\n",
    "                continue\n",
    "            \n",
    "            encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "            input_ids = encoding['input_ids']\n",
    "            attention_mask = encoding['attention_mask']\n",
    "\n",
    "            answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "            answer = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "            results.append((i, id, answer, question))\n",
    "\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            results.append((i, \"\", \"\", \"\"))\n",
    "        i += 1\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def onnx_inference(onnx_model, tokenizer, data):\n",
    "    result = []\n",
    "    i = 0\n",
    "    for example in preped_data_set:\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "\n",
    "        text = example[\"document\"][\"summary\"][\"text\"]\n",
    "        question = example[\"question\"][\"text\"]\n",
    "\n",
    "\n",
    "        encoding = tokenizer(question, text, return_tensors='np')\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        \n",
    "        outputs = onnx_model.run(input_feed=dict(encoding), output_names=None)\n",
    "\n",
    "        answer_idx = np.argmax(outputs[0])\n",
    "        result.append(outputs)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = data[3][\"document\"][\"summary\"][\"text\"]\n",
    "# question = data[3][\"question\"][\"text\"]\n",
    "# id = data[3][\"document\"][\"id\"]\n",
    "\n",
    "# print(text)\n",
    "# print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "# Get base results\n",
    "base_model_result = base_inference(tokenizer, default_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "#load and eval quant model \n",
    "quantized_model = torch.quantization.quantize_dynamic(default_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "quant_base_model_result = base_inference(tokenizer, quantized_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval quant base \n",
    "scoring = accuracy_scoring([a[2] for a in base_model_result], [a[2] for a in quant_base_model_result])\n",
    "# result.append((\"Quantized Base Model\", skill, reader, adapter, scoring, data_set_name, runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: facebook/bart-base narrativeqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset narrativeqa (/Users/michaelhermann/.cache/huggingface/datasets/narrativeqa/default/0.0.0/daef7ccc51ec258bef464658d11751bb20f033da9b4c219fd84563b3a4af0422)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset: narrativeqa\n"
     ]
    }
   ],
   "source": [
    "#load onnx models\n",
    "model_onnx, model_onnx_quant = repo_builder(reader, adapter)\n",
    "onnx_models_list = load_model(model_onnx, model_onnx_quant, as_list=True)\n",
    "onnx_models_name_helper_list = [\"ONNX\", \"ONNX-OPT\", \"Quantized ONNX\", \"Quantized ONNX - OPT\"] \n",
    "\n",
    "for onnx_model, onnx_model_name in zip(onnx_models_list, onnx_models_name_helper_list):\n",
    "    onnx = onnx_inference(adapter, question_answering, onnx_model, data, tokenizer, preprocessing_kwargs, task_kwargs, model_kwargs)\n",
    "\n",
    "    scoring = accuracy_scoring([a[2] for a in base_model_result], onnx)\n",
    "\n",
    "    result.append((onnx_model_name, skill, reader, adapter, scoring, data_set_name, runs))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapterhub_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, May 24 2022, 21:28:31) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dff476688330005cfc33f1ee0f15c13ae533c265ccd041ab146cdb98ecc6219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
