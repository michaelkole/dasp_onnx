{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import QuestionAnsweringPipeline, AutoAdapterModel, AutoModelWithHeads, AutoTokenizer, AutoConfig\n",
    "from transformers.onnx import OnnxConfig, validate_model_outputs, export\n",
    "\n",
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "from huggingface_hub import HfApi, HfFolder, hf_hub_download\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Mapping, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings from HF AutoConfig (prepended Onnx to get AutoOnnxConfig)\n",
    "CONFIG_MAPPING_NAMES = OrderedDict(\n",
    "    [\n",
    "        # Add configs here\n",
    "        (\"albert\", \"AlbertOnnxConfig\"),\n",
    "        (\"audio-spectrogram-transformer\", \"ASTOnnxConfig\"),\n",
    "        (\"bart\", \"BartOnnxConfig\"),\n",
    "        (\"beit\", \"BeitOnnxConfig\"),\n",
    "        (\"bert\", \"BertOnnxConfig\"),\n",
    "        (\"bert-generation\", \"BertGenerationOnnxConfig\"),\n",
    "        (\"big_bird\", \"BigBirdOnnxConfig\"),\n",
    "        (\"bigbird_pegasus\", \"BigBirdPegasusOnnxConfig\"),\n",
    "        (\"blenderbot\", \"BlenderbotOnnxConfig\"),\n",
    "        (\"blenderbot-small\", \"BlenderbotSmallOnnxConfig\"),\n",
    "        (\"bloom\", \"BloomOnnxConfig\"),\n",
    "        (\"camembert\", \"CamembertOnnxConfig\"),\n",
    "        (\"canine\", \"CanineOnnxConfig\"),\n",
    "        (\"chinese_clip\", \"ChineseCLIPOnnxConfig\"),\n",
    "        (\"clip\", \"CLIPOnnxConfig\"),\n",
    "        (\"clipseg\", \"CLIPSegOnnxConfig\"),\n",
    "        (\"codegen\", \"CodeGenOnnxConfig\"),\n",
    "        (\"conditional_detr\", \"ConditionalDetrOnnxConfig\"),\n",
    "        (\"convbert\", \"ConvBertOnnxConfig\"),\n",
    "        (\"convnext\", \"ConvNextOnnxConfig\"),\n",
    "        (\"ctrl\", \"CTRLOnnxConfig\"),\n",
    "        (\"cvt\", \"CvtOnnxConfig\"),\n",
    "        (\"data2vec-audio\", \"Data2VecAudioOnnxConfig\"),\n",
    "        (\"data2vec-text\", \"Data2VecTextOnnxConfig\"),\n",
    "        (\"data2vec-vision\", \"Data2VecVisionOnnxConfig\"),\n",
    "        (\"deberta\", \"DebertaOnnxConfig\"),\n",
    "        (\"deberta-v2\", \"DebertaV2OnnxConfig\"),\n",
    "        (\"decision_transformer\", \"DecisionTransformerOnnxConfig\"),\n",
    "        (\"deformable_detr\", \"DeformableDetrOnnxConfig\"),\n",
    "        (\"deit\", \"DeiTOnnxConfig\"),\n",
    "        (\"detr\", \"DetrOnnxConfig\"),\n",
    "        (\"dinat\", \"DinatOnnxConfig\"),\n",
    "        (\"distilbert\", \"DistilBertOnnxConfig\"),\n",
    "        (\"donut-swin\", \"DonutSwinOnnxConfig\"),\n",
    "        (\"dpr\", \"DPROnnxConfig\"),\n",
    "        (\"dpt\", \"DPTOnnxConfig\"),\n",
    "        (\"electra\", \"ElectraOnnxConfig\"),\n",
    "        (\"encoder-decoder\", \"EncoderDecoderOnnxConfig\"),\n",
    "        (\"ernie\", \"ErnieOnnxConfig\"),\n",
    "        (\"esm\", \"EsmOnnxConfig\"),\n",
    "        (\"flaubert\", \"FlaubertOnnxConfig\"),\n",
    "        (\"flava\", \"FlavaOnnxConfig\"),\n",
    "        (\"fnet\", \"FNetOnnxConfig\"),\n",
    "        (\"fsmt\", \"FSMTOnnxConfig\"),\n",
    "        (\"funnel\", \"FunnelOnnxConfig\"),\n",
    "        (\"glpn\", \"GLPNOnnxConfig\"),\n",
    "        (\"gpt2\", \"GPT2OnnxConfig\"),\n",
    "        (\"gpt_neo\", \"GPTNeoOnnxConfig\"),\n",
    "        (\"gpt_neox\", \"GPTNeoXOnnxConfig\"),\n",
    "        (\"gpt_neox_japanese\", \"GPTNeoXJapaneseOnnxConfig\"),\n",
    "        (\"gptj\", \"GPTJOnnxConfig\"),\n",
    "        (\"groupvit\", \"GroupViTOnnxConfig\"),\n",
    "        (\"hubert\", \"HubertOnnxConfig\"),\n",
    "        (\"ibert\", \"IBertOnnxConfig\"),\n",
    "        (\"imagegpt\", \"ImageGPTOnnxConfig\"),\n",
    "        (\"jukebox\", \"JukeboxOnnxConfig\"),\n",
    "        (\"layoutlm\", \"LayoutLMOnnxConfig\"),\n",
    "        (\"layoutlmv2\", \"LayoutLMv2OnnxConfig\"),\n",
    "        (\"layoutlmv3\", \"LayoutLMv3OnnxConfig\"),\n",
    "        (\"led\", \"LEDOnnxConfig\"),\n",
    "        (\"levit\", \"LevitOnnxConfig\"),\n",
    "        (\"lilt\", \"LiltOnnxConfig\"),\n",
    "        (\"longformer\", \"LongformerOnnxConfig\"),\n",
    "        (\"longt5\", \"LongT5OnnxConfig\"),\n",
    "        (\"luke\", \"LukeOnnxConfig\"),\n",
    "        (\"lxmert\", \"LxmertOnnxConfig\"),\n",
    "        (\"m2m_100\", \"M2M100OnnxConfig\"),\n",
    "        (\"marian\", \"MarianOnnxConfig\"),\n",
    "        (\"markuplm\", \"MarkupLMOnnxConfig\"),\n",
    "        (\"maskformer\", \"MaskFormerOnnxConfig\"),\n",
    "        (\"maskformer-swin\", \"MaskFormerSwinOnnxConfig\"),\n",
    "        (\"mbart\", \"MBartOnnxConfig\"),\n",
    "        (\"mctct\", \"MCTCTOnnxConfig\"),\n",
    "        (\"megatron-bert\", \"MegatronBertOnnxConfig\"),\n",
    "        (\"mobilebert\", \"MobileBertOnnxConfig\"),\n",
    "        (\"mobilenet_v1\", \"MobileNetV1OnnxConfig\"),\n",
    "        (\"mobilenet_v2\", \"MobileNetV2OnnxConfig\"),\n",
    "        (\"mobilevit\", \"MobileViTOnnxConfig\"),\n",
    "        (\"mpnet\", \"MPNetOnnxConfig\"),\n",
    "        (\"mt5\", \"MT5OnnxConfig\"),\n",
    "        (\"mvp\", \"MvpOnnxConfig\"),\n",
    "        (\"nat\", \"NatOnnxConfig\"),\n",
    "        (\"nezha\", \"NezhaOnnxConfig\"),\n",
    "        (\"nystromformer\", \"NystromformerOnnxConfig\"),\n",
    "        (\"openai-gpt\", \"OpenAIGPTOnnxConfig\"),\n",
    "        (\"opt\", \"OPTOnnxConfig\"),\n",
    "        (\"owlvit\", \"OwlViTOnnxConfig\"),\n",
    "        (\"pegasus\", \"PegasusOnnxConfig\"),\n",
    "        (\"pegasus_x\", \"PegasusXOnnxConfig\"),\n",
    "        (\"perceiver\", \"PerceiverOnnxConfig\"),\n",
    "        (\"plbart\", \"PLBartOnnxConfig\"),\n",
    "        (\"poolformer\", \"PoolFormerOnnxConfig\"),\n",
    "        (\"prophetnet\", \"ProphetNetOnnxConfig\"),\n",
    "        (\"qdqbert\", \"QDQBertOnnxConfig\"),\n",
    "        (\"rag\", \"RagOnnxConfig\"),\n",
    "        (\"realm\", \"RealmOnnxConfig\"),\n",
    "        (\"reformer\", \"ReformerOnnxConfig\"),\n",
    "        (\"regnet\", \"RegNetOnnxConfig\"),\n",
    "        (\"rembert\", \"RemBertOnnxConfig\"),\n",
    "        (\"resnet\", \"ResNetOnnxConfig\"),\n",
    "        (\"retribert\", \"RetriBertOnnxConfig\"),\n",
    "        (\"roberta\", \"RobertaOnnxConfig\"),\n",
    "        (\"roc_bert\", \"RoCBertOnnxConfig\"),\n",
    "        (\"roformer\", \"RoFormerOnnxConfig\"),\n",
    "        (\"segformer\", \"SegformerOnnxConfig\"),\n",
    "        (\"sew\", \"SEWOnnxConfig\"),\n",
    "        (\"sew-d\", \"SEWDOnnxConfig\"),\n",
    "        (\"speech-encoder-decoder\", \"SpeechEncoderDecoderOnnxConfig\"),\n",
    "        (\"speech_to_text\", \"Speech2TextOnnxConfig\"),\n",
    "        (\"speech_to_text_2\", \"Speech2Text2OnnxConfig\"),\n",
    "        (\"splinter\", \"SplinterOnnxConfig\"),\n",
    "        (\"squeezebert\", \"SqueezeBertOnnxConfig\"),\n",
    "        (\"swin\", \"SwinOnnxConfig\"),\n",
    "        (\"swinv2\", \"Swinv2OnnxConfig\"),\n",
    "        (\"switch_transformers\", \"SwitchTransformersOnnxConfig\"),\n",
    "        (\"t5\", \"T5OnnxConfig\"),\n",
    "        (\"table-transformer\", \"TableTransformerOnnxConfig\"),\n",
    "        (\"tapas\", \"TapasOnnxConfig\"),\n",
    "        (\"time_series_transformer\", \"TimeSeriesTransformerOnnxConfig\"),\n",
    "        (\"trajectory_transformer\", \"TrajectoryTransformerOnnxConfig\"),\n",
    "        (\"transfo-xl\", \"TransfoXLOnnxConfig\"),\n",
    "        (\"trocr\", \"TrOCROnnxConfig\"),\n",
    "        (\"unispeech\", \"UniSpeechOnnxConfig\"),\n",
    "        (\"unispeech-sat\", \"UniSpeechSatOnnxConfig\"),\n",
    "        (\"van\", \"VanOnnxConfig\"),\n",
    "        (\"videomae\", \"VideoMAEOnnxConfig\"),\n",
    "        (\"vilt\", \"ViltOnnxConfig\"),\n",
    "        (\"vision-encoder-decoder\", \"VisionEncoderDecoderOnnxConfig\"),\n",
    "        (\"vision-text-dual-encoder\", \"VisionTextDualEncoderOnnxConfig\"),\n",
    "        (\"visual_bert\", \"VisualBertOnnxConfig\"),\n",
    "        (\"vit\", \"ViTOnnxConfig\"),\n",
    "        (\"vit_mae\", \"ViTMAEOnnxConfig\"),\n",
    "        (\"vit_msn\", \"ViTMSNOnnxConfig\"),\n",
    "        (\"wav2vec2\", \"Wav2Vec2OnnxConfig\"),\n",
    "        (\"wav2vec2-conformer\", \"Wav2Vec2ConformerOnnxConfig\"),\n",
    "        (\"wavlm\", \"WavLMOnnxConfig\"),\n",
    "        (\"whisper\", \"WhisperOnnxConfig\"),\n",
    "        (\"xclip\", \"XCLIPOnnxConfig\"),\n",
    "        (\"xglm\", \"XGLMOnnxConfig\"),\n",
    "        (\"xlm\", \"XLMOnnxConfig\"),\n",
    "        (\"xlm-prophetnet\", \"XLMProphetNetOnnxConfig\"),\n",
    "        (\"xlm-roberta\", \"XLMRobertaOnnxConfig\"),\n",
    "        (\"xlm-roberta-xl\", \"XLMRobertaXLOnnxConfig\"),\n",
    "        (\"xlnet\", \"XLNetOnnxConfig\"),\n",
    "        (\"yolos\", \"YolosOnnxConfig\"),\n",
    "        (\"yoso\", \"YosoOnnxConfig\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def auto_onnx_config(model_name: str, task: str) -> OnnxConfig:\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        identifier = model_name.split(\"/\")[-1].split(\"-\")[0]\n",
    "        config_name = CONFIG_MAPPING_NAMES[identifier]\n",
    "        config_class = import_module(f\"transformers.models.{identifier}\")\n",
    "        auto_onnx_config = getattr(config_class, config_name)\n",
    "        return auto_onnx_config.from_model_config(config, task=task)\n",
    "    except:\n",
    "        raise ValueError(f\"Could not find an AutoOnnxConfig for model {model_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_readme(directory_path, base_model, skill, model_id, adapter):\n",
    "    onnx_readme = \"{}/README.md\".format(directory_path)\n",
    "\n",
    "    if adapter is None:\n",
    "        readme_path = hf_hub_download(repo_id=base_model, filename=\"README.md\")\n",
    "\n",
    "        inserted_headline = False\n",
    "        with open(readme_path, 'r') as src, open(onnx_readme, 'w') as dst:\n",
    "            for line in src:\n",
    "                # Insert onnx tag\n",
    "                if line == 'tags:\\n':\n",
    "                    dst.write(\"inference: false\\n\")\n",
    "                    dst.write(line)\n",
    "                    dst.write('- onnx\\n')\n",
    "                    continue\n",
    "\n",
    "                if line.startswith(\"# \") and not inserted_headline:\n",
    "                    inserted_headline = True\n",
    "                    dst.write(\"# ONNX export of \" + base_model + \"\\n\")\n",
    "                    continue\n",
    "\n",
    "                dst.write(line)\n",
    "    else:\n",
    "        readme_path = hf_hub_download(repo_id=adapter, filename=\"README.md\")\n",
    "\n",
    "        skip = False\n",
    "        with open(readme_path, 'r') as src, open(onnx_readme, 'w') as dst:\n",
    "            for line in src:\n",
    "                # Insert onnx tag\n",
    "                if line == 'tags:\\n':\n",
    "                    dst.write(\"inference: false\\n\")\n",
    "                    dst.write(line)\n",
    "                    dst.write('- onnx\\n')\n",
    "                    continue\n",
    "\n",
    "                if line.startswith(\"# Adapter\"):\n",
    "                    skip = True\n",
    "\n",
    "                    # Insert custom README\n",
    "                    dst.write(\"# ONNX export of \" + line[2:])\n",
    "                    dst.write(f\"## Conversion of [{adapter}](https://huggingface.co/{adapter}) for UKP SQuARE\\n\\n\\n\")\n",
    "                    dst.write(\"## Usage\\n\")\n",
    "                    dst.write(\"```python\\n\")\n",
    "                    dst.write(f\"onnx_path = hf_hub_download(repo_id='UKP-SQuARE/{model_id}', filename='model.onnx') # or model_quant.onnx for quantization\\n\")\n",
    "                    dst.write(\"onnx_model = InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\\n\\n\")\n",
    "\n",
    "                    if (skill == \"span-extraction\"):\n",
    "                        dst.write(\"context = 'ONNX is an open format to represent models. The benefits of using ONNX include interoperability of frameworks and hardware optimization.'\\n\")\n",
    "                        dst.write(\"question = 'What are advantages of ONNX?'\\n\")\n",
    "                        dst.write(f\"tokenizer = AutoTokenizer.from_pretrained('UKP-SQuARE/{model_id}')\\n\\n\")\n",
    "                        dst.write(\"inputs = tokenizer(question, context, padding=True, truncation=True, return_tensors='np')\\n\")\n",
    "                        dst.write(\"outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\\n\")\n",
    "                        dst.write(\"```\\n\\n\")\n",
    "\n",
    "                    elif (skill == \"categorical\"):\n",
    "                        dst.write(\"context = 'English orthography typically represents vowel sounds with the five conventional vowel letters ⟨a, e, i, o, u⟩, as well as ⟨y⟩, which may also be a consonant depending on context. However, outside of abbreviations, there are a handful of words in English that do not have vowels, either because the vowel sounds are not written with vowel letters or because the words themselves are pronounced without vowel sounds'.\\n\")\n",
    "                        dst.write(\"question = 'can there be a word without a vowel'\\n\")\n",
    "                        dst.write(f\"tokenizer = AutoTokenizer.from_pretrained('UKP-SQuARE/{model_id}')\\n\\n\")\n",
    "                        dst.write(\"inputs = tokenizer(question, context, padding=True, truncation=True, return_tensors='np')\\n\")\n",
    "                        dst.write(\"outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\\n\")\n",
    "                        dst.write(\"```\\n\\n\")\n",
    "\n",
    "                    elif skill == \"multiple-choice\":\n",
    "                        dst.write(\"context = 'ONNX is an open format to represent models. The benefits of using ONNX include interoperability of frameworks and hardware optimization.'\\n\")\n",
    "                        dst.write(\"question = 'What are advantages of ONNX?'\\n\")\n",
    "                        dst.write('choices = [\"Cat\", \"Horse\", \"Tiger\", \"Fish\"]')\n",
    "\n",
    "                        dst.write(f\"tokenizer = AutoTokenizer.from_pretrained('UKP-SQuARE/{model_id}')\\n\\n\")\n",
    "\n",
    "                        dst.write(\"raw_input = [[context, question + \" \" + choice] for choice in choices]\\n\")\n",
    "                        dst.write('inputs = tokenizer(raw_input, padding=True, truncation=True, return_tensors=\"np\")\\n')\n",
    "\n",
    "                        dst.write(\"inputs['token_type_ids'] = np.expand_dims(inputs['token_type_ids'], axis=0)\\n\")\n",
    "                        dst.write(\"inputs['input_ids'] =  np.expand_dims(inputs['input_ids'], axis=0)\\n\")\n",
    "                        dst.write(\"inputs['attention_mask'] =  np.expand_dims(inputs['attention_mask'], axis=0)\\n\")\n",
    "                        dst.write(\"outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\\n\")\n",
    "\n",
    "                        dst.write(\"```\\n\\n\")\n",
    "\n",
    "                    elif skill == \"abstractive\":\n",
    "                        dst.write(\"context = 'ONNX is an open format to represent models. The benefits of using ONNX include interoperability of frameworks and hardware optimization.'\\n\")\n",
    "                        dst.write(\"question = 'What are advantages of ONNX?'\\n\")\n",
    "                        dst.write(f\"tokenizer = AutoTokenizer.from_pretrained('UKP-SQuARE/{model_id}')\\n\\n\")\n",
    "                        dst.write(\"inputs = tokenizer(question, context, padding=True, truncation=True, return_tensors='np')\\n\")\n",
    "                        dst.write(\"outputs = onnx_model.run(input_feed=dict(inputs), output_names=None)\\n\")\n",
    "                        dst.write(\"```\\n\\n\")\n",
    "\n",
    "\n",
    "                # Continue with normal model card\n",
    "                if line.startswith(\"## Architecture & Training\"): \n",
    "                    skip = False\n",
    "\n",
    "                if not skip: \n",
    "                    dst.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_hub(save_dir, repository_id):\n",
    "    huggingface_token = HfFolder.get_token()\n",
    "    api = HfApi()\n",
    "\n",
    "    api.create_repo(\n",
    "        token=huggingface_token,\n",
    "        repo_id=f'UKP-SQuARE/{repository_id}',\n",
    "        exist_ok=True,\n",
    "        private=False\n",
    "    )\n",
    "\n",
    "    for path, subdirs, files in os.walk(save_dir):\n",
    "        for name in files:\n",
    "            local_file_path = os.path.join(path, name)\n",
    "            _, hub_file_path = os.path.split(local_file_path)\n",
    "            try:\n",
    "                api.upload_file(\n",
    "                    token=huggingface_token,\n",
    "                    repo_id=f\"UKP-SQuARE/{repository_id}\",\n",
    "                    path_or_fileobj=os.path.join(os.getcwd(), local_file_path),\n",
    "                    path_in_repo=hub_file_path,\n",
    "                )\n",
    "            except KeyError:\n",
    "                pass\n",
    "            except NameError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_export(model_name, skill, quantize_model=True, adapter_id=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelWithHeads.from_pretrained(model_name)\n",
    "\n",
    "    model_slur = model_name.split(\"/\")[-1]\n",
    "\n",
    "    if adapter_id is not None:\n",
    "        adapter = f\"AdapterHub/{model_slur}-pf-{adapter_id}\"\n",
    "        adapter_name = model.load_adapter(adapter, source=\"hf\")\n",
    "        model.active_adapters = adapter_name\n",
    "        model_id = adapter.split(\"/\")[-1]+\"-onnx\"\n",
    "    else:\n",
    "        model_id = model_slur+\"-onnx\"\n",
    "\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    onnx_config = auto_onnx_config(model_name, skill)\n",
    "    \n",
    "    # Generate the local directory in onnx/\n",
    "    directory_path = Path(\"onnx/{}\".format(model_id))\n",
    "    directory_path.mkdir(parents=True, exist_ok=True)\n",
    "    onnx_model_path = Path(\"{}/model.onnx\".format(directory_path))\n",
    "\n",
    "    # Export ONNX model\n",
    "    export(tokenizer, model, onnx_config, onnx_config.default_onnx_opset, onnx_model_path)\n",
    "\n",
    "    # Create config.json of vanilla model\n",
    "    model.save_pretrained(directory_path)\n",
    "    os.remove(directory_path / \"pytorch_model.bin\")\n",
    "\n",
    "    # Save tokenizer\n",
    "    tokenizer.save_pretrained(directory_path)\n",
    "\n",
    "    # Create README.md\n",
    "    generate_readme(directory_path, model_name, skill, model_id, adapter if adapter_id is not None else None)\n",
    "\n",
    "    if quantize_model:\n",
    "        quantized_model_path = \"{}/model_quant.onnx\".format(directory_path)\n",
    "        quantize_dynamic(onnx_model_path, quantized_model_path, weight_type=QuantType.QInt8)\n",
    "\n",
    "    print(\"Uploading model to hub... (may take a few minutes)\")\n",
    "    push_to_hub(\n",
    "        save_dir = directory_path,\n",
    "        repository_id = model_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:269: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bert/adapter_model.py:247: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/composition.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and hidden_states.shape[0] != tensor.shape[0]:\n",
      "Downloading: 100%|██████████| 10.5k/10.5k [00:00<00:00, 5.83MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.0/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.0/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.1/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.1/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.2/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.2/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.3/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.3/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.4/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.4/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.5/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.5/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.6/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.6/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.7/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.7/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.8/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.8/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.9/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.9/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.10/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.10/attention/self/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.11/attention/self/MatMul]\n",
      "Ignore MatMul due to non constant B: /[/bert/encoder/layer.11/attention/self/MatMul_1]\n",
      "Uploading model to hub... (may take a few minutes)\n"
     ]
    }
   ],
   "source": [
    "onnx_export('bert-base-uncased', 'default')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a7f5a2c07603db35bc4e52cfd5b475adbf202ae824ea4c5e531d495460257f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
