# Repository for ONNX Model Optimization

Export Models to Huggingface:

- onnx_export.ipynb

Multicore Inference Python Scripts:

- inference_mcq.py
- inference_span_extraction.py
- inference_categorical.py

Prep files: eval_prep_data.ipynb

Eval results: eval_prep_data.ipynb

Result files on drive:

<https://drive.google.com/drive/folders/1dbiIsb_3OHiSg8w6a1BjjaMyR6dkBf0_?usp=sharing>

Prototyping:

- multiple_choice.ipynb
- categorical_prototype.ipynb
- qa_abstractive.ipynb

Code related to ONNX export and metrics tracking:
onnx_prototype.ipynb

Archive:
qa_pipeline.ipynb: Extractive QA model inference pipeline

share_model_hf.ipynb: Push ONNX model to HuggingFace

onnx_import.ipynb: Download ONNX model and run inference