{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import QuestionAnsweringPipeline, AutoAdapterModel, AutoModelWithHeads, AutoTokenizer, AutoConfig\n",
    "from transformers.onnx import OnnxConfig, validate_model_outputs, export\n",
    "from transformers.models.bert import BertOnnxConfig\n",
    "from transformers.models.bart import BartOnnxConfig\n",
    "\n",
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from onnxruntime import InferenceSession\n",
    "import onnxruntime\n",
    "\n",
    "from onnx_opcounter import calculate_params\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric, load_dataset\n",
    "\n",
    "from typing import Mapping, OrderedDict\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:246: FutureWarning: This class has been renamed to `BartAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:224: FutureWarning: This class has been renamed to `BartAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 5180.28it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = AutoModelWithHeads.from_pretrained(\"facebook/bart-base\")\n",
    "adapter_name = model.load_adapter(\"AdapterHub/narrativeqa\", source=\"hf\", set_active=True)\n",
    "model.set_active_adapters(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Taxes \\n'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question, text = \"What does Sara hate?\", \"Sara hates taxes. She loves vanilla ice cream.\"\n",
    "prompt = text + \"</s>\" + question + \"</s>\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "answer = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Anaides \\n'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second test \n",
    "\n",
    "question = \"WHAT NAME WAS CYNTHIA MORE FAMOUSLY KNOWN BY?\"\n",
    "text = 'The play begins with three pages disputing over the black cloak usually worn by the actor who delivers the prologue. They draw lots for the cloak, and one of the losers, Anaides, starts telling the audience what happens in the play to come; the others try to suppress him, interrupting him and putting their hands over his mouth. Soon they are fighting over the cloak and criticizing the author and the spectators as well. In the play proper, the goddess Diana, also called Cynthia, has ordained a \"solemn revels\" in the valley of Gargaphie in Greece. The gods Cupid and Mercury appear, and they too start to argue. Mercury has awakened Echo, who weeps for Narcissus, and states that a drink from Narcissus\\'s spring causes the drinkers to \"Grow dotingly enamored of themselves.\" The courtiers and ladies assembled for the Cynthia\\'s revels all drink from the spring. Asotus, a foolish spendthrift who longs to become a courtier and a master of fashion and manners, also drinks from the spring; emboldened by vanity and self-love, he challenges all comers to a competition of \"court compliment.\" The competition is held, in four phases, and the courtiers are beaten. Two symbolic masques are performed within the play for the assembled revelers. At their conclusion, Cynthia (representing Queen Elizabeth) has the dancers unmask and shows that vices have masqueraded as virtues. She sentences them to make reparation and to purify themselves by bathing in the spring at Mount Helicon. The figure of Actaeon in the play may represent Robert Devereux, 2nd Earl of Essex, while Cynthia\\'s lady in waiting Arete may be Lucy, Countess of Bedford, one of Elizabeth\\'s ladies in waiting as well as Jonson\\'s patroness\\' The play is notably rich in music, as is typical for the theatre of the boys\\' companies, which originated as church choirs.'\n",
    "\n",
    "prompt = text + \"</s>\" + question + \"</s>\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "answer = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Anaides and Anaides \\n'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_2 = \"WHO DOES ECHO WEEP FOR?\"\n",
    "\n",
    "prompt = text + \"</s>\" + question_2 + \"</s>\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "answer = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' They are fighting over the cloak. \\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_3 = \"WHAT DOES A DRINK FROM NARCISSUS'S SPRING CAUSE THE DRINKER TO DO?\"\n",
    "\n",
    "prompt = text + \"</s>\" + question_3 + \"</s>\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "answer1 = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([433, 50265])\n",
      "tensor(1115979)\n"
     ]
    }
   ],
   "source": [
    "logits = model(input_ids, attention_mask=attention_mask).logits[0]\n",
    "print(logits.shape)\n",
    "print(logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_len = 0\n",
    "max_length = 10\n",
    "eos_token_id = (\n",
    "    tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n",
    ")\n",
    "features = encoding\n",
    "input_ids = logits\n",
    "generated_ids = []\n",
    "unfinished_sequences = input_ids.new(input_ids.shape[0]).fill_(1)\n",
    "scores = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need manual generation for the ONNX model (greedy generation)\n",
    "# https://github.com/huggingface/transformers/blob/main/examples/research_projects/onnx/summarization/bart_onnx/generation_onnx.py\n",
    "while cur_len < max_length:\n",
    "    input_data = features.copy()\n",
    "    input_data[\"input_ids\"] = torch.cat(\n",
    "        (\n",
    "            features[\"input_ids\"],\n",
    "            torch.tensor(generated_ids, dtype=int).unsqueeze(dim=0),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    "    input_data[\"attention_mask\"] = torch.ones(input_data[\"input_ids\"].shape, dtype=torch.int64)\n",
    "\n",
    "    predictions = model(input_data[\"input_ids\"], attention_mask=input_data[\"attention_mask\"])\n",
    "    \n",
    "    next_token_logits = predictions[\"logits\"][:, -1, :]\n",
    "    scores += (next_token_logits,)\n",
    "\n",
    "    # argmax\n",
    "    next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "    # update generated ids, model inputs, and length for next step\n",
    "    generated_ids.append(next_tokens[:, None].item())\n",
    "    cur_len = cur_len + 1\n",
    "    \n",
    "    if eos_token_id is not None:\n",
    "        unfinished_sequences = unfinished_sequences.mul((next_tokens != eos_token_id).long())\n",
    "        # stop when each sentence is finished, or if we exceed the maximum length\n",
    "    if unfinished_sequences.max() == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:250: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:257: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:289: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/layer.py:49: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if context.output_adapter_gating_scores:\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/composition.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and hidden_states.shape[0] != tensor.shape[0]:\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:944: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1:\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:107: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/context.py:117: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if getattr(ctx, \"output_\" + attr, False):\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:95: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_ids is not None and x.shape[1] == input_ids.shape[1]:\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:98: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  if len(torch.unique(eos_mask.sum(1))) > 1:\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"facebook/bart-base\")\n",
    "onnx_config = BartOnnxConfig.from_model_config(config, task=\"causal-lm\")\n",
    "\n",
    "onnx_path = Path(\"onnx/narrativeqabart/model.onnx\")\n",
    "\n",
    "onnx_inputs, onnx_outputs = export(tokenizer, model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = InferenceSession(\n",
    "    str(onnx_path), providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "encoding = tokenizer(question, text, return_tensors='np')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "outputs = onnx_model.run(input_feed=dict(encoding), output_names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('logits', {0: 'batch', 1: 'sequence'})])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_config.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 44628, 42374, 26817, 32854,   487,  3732,  2889,  3001,\n",
       "        32113,  5061, 11160,   975, 30105, 14356, 10786,   116,     2,\n",
       "            2,   133,   310,  3772,    19,   130,  6052,  2982, 34618,\n",
       "           81,     5,   909, 40725,  2333, 10610,    30,     5,  2701,\n",
       "           54,  8806,     5, 41255, 10149,     4,   252,  2451,  3739,\n",
       "           13,     5, 40725,     6,     8,    65,     9,     5, 19113,\n",
       "            6, 14493,  4376,     6,  2012,  2758,     5,  2437,    99,\n",
       "         2594,    11,     5,   310,     7,   283,   131,     5,   643,\n",
       "          860,     7, 23192,   123,     6, 22749,   154,   123,     8,\n",
       "         2057,    49,  1420,    81,    39,  6085,     4,  9561,    51,\n",
       "           32,  2190,    81,     5, 40725,     8, 18384,     5,  2730,\n",
       "            8,     5, 17596,    25,   157,     4,    96,     5,   310,\n",
       "         4692,     6,     5, 34293, 10670,     6,    67,   373, 16589,\n",
       "            6,    34, 36433,    10,    22, 37870, 17673, 20853,    29,\n",
       "          113,    11,     5, 15044,     9, 30156,  8258,   324,    11,\n",
       "         4644,     4,    20, 25779,   968,   808,     8, 15933,  2082,\n",
       "            6,     8,    51,   350,   386,     7,  5848,     4, 15933,\n",
       "           34, 40593, 11348,     6,    54,    52, 26378,    13, 28908,\n",
       "         3006,   687,     6,     8,   982,    14,    10,  4076,    31,\n",
       "        28908,  3006,   687,    18,  2428,  4685,     5, 32571,     7,\n",
       "           22,   534,  4610, 16007,  7790,  1177,   424,  3995,     9,\n",
       "         1235,    72,    20,   461,  4733,     8, 10717, 14525,    13,\n",
       "            5, 16589,    18, 20853,    29,    70,  4076,    31,     5,\n",
       "         2428,     4,   287,  1242,   687,     6,    10, 22789,  1930,\n",
       "          212, 23203,    54,   251,    29,     7,   555,    10,   461,\n",
       "          906,     8,    10,  4710,     9,  2734,     8, 35217,     6,\n",
       "           67,  6696,    31,     5,  2428,   131, 24762,  4490,    30,\n",
       "        36827,     8,  1403,    12, 17693,     6,    37,  2019,    70,\n",
       "         3137,   268,     7,    10,  1465,     9,    22,  8953, 19389,\n",
       "           72,    20,  1465,    16,   547,     6,    11,   237, 17369,\n",
       "            6,     8,     5,   461,  4733,    32,  6432,     4,  1596,\n",
       "        16868, 11705, 15017,    32,  3744,   624,     5,   310,    13,\n",
       "            5, 14525, 20853,   268,     4,   497,    49,  6427,     6,\n",
       "        16589,    36, 35213,   154,  3929,  4690,    43,    34,     5,\n",
       "        14855, 30780,  4970,     8,   924,    14,   748,  6355,    33,\n",
       "        11705, 18756,  7560,    25, 33975,     4,   264, 11305,   106,\n",
       "            7,   146,  2851, 36466,     8,     7,  9695,  4591,  1235,\n",
       "           30, 30260,    11,     5,  2428,    23,  5455,  6851, 17505,\n",
       "            4,    20,  1955,     9,  1783,  4791,   261,    11,     5,\n",
       "          310,   189,  3594,  1738,   926, 12081,  7073,     6,   132,\n",
       "         1187, 16814,     9, 15252,     6,   150, 16589,    18,  6429,\n",
       "           11,  2445,  3945,   859,   189,    28, 14309,     6, 12440,\n",
       "         3361,     9, 21923,     6,    65,     9,  4690,    18, 10717,\n",
       "           11,  2445,    25,   157,    25,   344, 26942,    18, 18528,\n",
       "         3361,   108,    20,   310,    16, 10030,  4066,    11,   930,\n",
       "            6,    25,    16,  6097,    13,     5,  8870,     9,     5,\n",
       "         2786,   108,   451,     6,    61, 19575,    25,  2352, 14310,\n",
       "        21098,     4,     2]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_beams = 4\n",
    "    ort_out = onnx_model.run(\n",
    "        None,\n",
    "        {\n",
    "            \"input_ids\": encoding[\"input_ids\"],\n",
    "            \"attention_mask\": encoding[\"attention_mask\"],\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ort_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, max_length=1024, return_tensors=\"pt\").to(model.device)\n",
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    num_beams=num_beams,\n",
    "    max_length=max_length,\n",
    "    early_stopping=True,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    2,     0,   252,    32,  2190,    81,     5, 40725,     8,\n",
       "            2]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_ids.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' suscept', '-', 'abled', ' \"', ' \\xad', ' �', 'GoldMagikarp', ' ', 'OK', ' OK', 'inged']\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "next_token_logits = torch.Tensor(outputs[0][:, -1, :])\n",
    "top_k = 12\n",
    "top_n_logits, top_n_tokens = torch.topk(next_token_logits, top_k, dim=1)\n",
    "top_n_probs = F.softmax(top_n_logits, dim=-1)\n",
    "words = [\n",
    "    tokenizer.decode(x, skip_special_tokens=True)\n",
    "    for x in top_n_tokens[0]\n",
    "]\n",
    "new_past = np.array(outputs[1:])\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=0.001\n\n(shapes (1, 10), (1, 426, 50265) mismatch)\n x: array([[    2,     0,   252,    32,  2190,    81,     5, 40725,     8,\n            2]])\n y: array([[[30.044197,  3.914951, 11.842628, ...,  3.704317,  3.88825 ,\n         -3.931822],\n        [-6.724422, -5.136206,  1.204158, ..., -4.670123, -4.980473,...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [294], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mtesting\u001b[39m.\u001b[39;49massert_allclose(summary_ids\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), ort_out[\u001b[39m0\u001b[39;49m], rtol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, atol\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/numpy/testing/_private/utils.py:763\u001b[0m, in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cond:\n\u001b[1;32m    758\u001b[0m     msg \u001b[39m=\u001b[39m build_err_msg([x, y],\n\u001b[1;32m    759\u001b[0m                         err_msg\n\u001b[1;32m    760\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m(shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m mismatch)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    761\u001b[0m                         verbose\u001b[39m=\u001b[39mverbose, header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m    762\u001b[0m                         names\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m), precision\u001b[39m=\u001b[39mprecision)\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(msg)\n\u001b[1;32m    765\u001b[0m flagged \u001b[39m=\u001b[39m bool_(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    766\u001b[0m \u001b[39mif\u001b[39;00m isnumber(x) \u001b[39mand\u001b[39;00m isnumber(y):\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=0.001\n\n(shapes (1, 10), (1, 426, 50265) mismatch)\n x: array([[    2,     0,   252,    32,  2190,    81,     5, 40725,     8,\n            2]])\n y: array([[[30.044197,  3.914951, 11.842628, ...,  3.704317,  3.88825 ,\n         -3.931822],\n        [-6.724422, -5.136206,  1.204158, ..., -4.670123, -4.980473,..."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9881, 4.2705, 3.8324, 3.7781, 3.7627, 3.6943, 3.6371, 3.5584, 3.4352,\n",
       "         3.3904, 3.3634, 3.3491]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' They are fighting over the cloak. \\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(answer[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapterhub_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, May 24 2022, 21:28:31) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dff476688330005cfc33f1ee0f15c13ae533c265ccd041ab146cdb98ecc6219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
