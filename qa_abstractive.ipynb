{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import QuestionAnsweringPipeline, AutoAdapterModel, AutoModelWithHeads, AutoTokenizer, AutoConfig\n",
    "from transformers.onnx import OnnxConfig, validate_model_outputs, export\n",
    "from transformers.models.bert import BertOnnxConfig\n",
    "from transformers.models.bart import BartOnnxConfig\n",
    "\n",
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from onnxruntime import InferenceSession\n",
    "import onnxruntime\n",
    "\n",
    "from onnx_opcounter import calculate_params\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_metric, load_dataset\n",
    "\n",
    "from typing import Mapping, OrderedDict\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:248: FutureWarning: This class has been renamed to `BartAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:226: FutureWarning: This class has been renamed to `BartAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 4138.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = AutoModelWithHeads.from_pretrained(\"facebook/bart-base\")\n",
    "adapter_name = model.load_adapter(\"AdapterHub/narrativeqa\", source=\"hf\", set_active=True)\n",
    "model.set_active_adapters(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Taxes \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question, text = \"What does Sara hate?\", \"Sara hates taxes. She loves vanilla ice cream.\"\n",
    "prompt = text + \"</s>\" + question + \"</s>\"\n",
    "\n",
    "encoding = tokenizer(prompt, return_tensors='pt', padding=False)\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "answer = model.generate(input_ids, attention_mask=attention_mask, num_beams=4, max_length=128, early_stopping=True)\n",
    "answer = tokenizer.decode(answer[0], skip_special_tokens=True)\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 50265])\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(input_ids, attention_mask=attention_mask).logits[0]\n",
    "print(logits.shape)\n",
    "print(logits.argmax())\n",
    "\n",
    "tokenizer.decode(logits[-1:, :].argmax(dim=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_len = 0\n",
    "max_length = 10\n",
    "eos_token_id = (\n",
    "    tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id\n",
    ")\n",
    "features = encoding\n",
    "input_ids = logits\n",
    "generated_ids = []\n",
    "unfinished_sequences = input_ids.new(input_ids.shape[0]).fill_(1)\n",
    "scores = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need manual generation for the ONNX model (greedy generation)\n",
    "while cur_len < max_length:\n",
    "    input_data = features.copy()\n",
    "    input_data[\"input_ids\"] = torch.cat(\n",
    "        (\n",
    "            features[\"input_ids\"],\n",
    "            torch.tensor(generated_ids, dtype=int).unsqueeze(dim=0),\n",
    "        ),\n",
    "        dim=1,\n",
    "    )\n",
    "    input_data[\"attention_mask\"] = torch.ones(input_data[\"input_ids\"].shape, dtype=torch.int64)\n",
    "\n",
    "    predictions = model(input_data[\"input_ids\"], attention_mask=input_data[\"attention_mask\"])\n",
    "\n",
    "    next_token_logits = predictions[\"logits\"][:, -1, :]\n",
    "    scores += (next_token_logits,)\n",
    "\n",
    "    # argmax\n",
    "    next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "    # update generated ids, model inputs, and length for next step\n",
    "    generated_ids.append(next_tokens[:, None].item())\n",
    "    cur_len = cur_len + 1\n",
    "\n",
    "    if eos_token_id is not None:\n",
    "        unfinished_sequences = unfinished_sequences.mul((next_tokens != eos_token_id).long())\n",
    "        # stop when each sentence is finished, or if we exceed the maximum length\n",
    "    if unfinished_sequences.max() == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:250: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:257: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:289: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/layer.py:49: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if context.output_adapter_gating_scores:\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/composition.py:203: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if tensor is not None and hidden_states.shape[0] != tensor.shape[0]:\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:944: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1:\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/models/bart/modeling_bart.py:107: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask = torch.full((tgt_len, tgt_len), torch.tensor(torch.finfo(dtype).min))\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/context.py:117: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if getattr(ctx, \"output_\" + attr, False):\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:96: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_ids is not None and x.shape[1] == input_ids.shape[1]:\n",
      "/home/daedalus/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/adapters/models/bart/adapter_model.py:99: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.\n",
      "  if len(torch.unique(eos_mask.sum(1))) > 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m onnx_config \u001b[39m=\u001b[39m BartOnnxConfig\u001b[39m.\u001b[39mfrom_model_config(config, task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcausal-lm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m onnx_path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39monnx/narrativeqabart/model.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m onnx_inputs, onnx_outputs \u001b[39m=\u001b[39m export(tokenizer, model, onnx_config, onnx_config\u001b[39m.\u001b[39;49mdefault_onnx_opset, onnx_path)\n\u001b[1;32m      8\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(onnx_path)\n\u001b[1;32m      9\u001b[0m onnx\u001b[39m.\u001b[39mchecker\u001b[39m.\u001b[39mcheck_model(onnx_model)\n",
      "File \u001b[0;32m~/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/onnx/convert.py:336\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(preprocessor, model, config, opset, output, tokenizer, device)\u001b[0m\n\u001b[1;32m    330\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    331\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported PyTorch version for this model. Minimum required is \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mtorch_onnx_minimum_version\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m got: \u001b[39m\u001b[39m{\u001b[39;00mtorch_version\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    333\u001b[0m         )\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available() \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(model), PreTrainedModel):\n\u001b[0;32m--> 336\u001b[0m     \u001b[39mreturn\u001b[39;00m export_pytorch(preprocessor, model, config, opset, output, tokenizer\u001b[39m=\u001b[39;49mtokenizer, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    337\u001b[0m \u001b[39melif\u001b[39;00m is_tf_available() \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mtype\u001b[39m(model), TFPreTrainedModel):\n\u001b[1;32m    338\u001b[0m     \u001b[39mreturn\u001b[39;00m export_tensorflow(preprocessor, model, config, opset, output, tokenizer\u001b[39m=\u001b[39mtokenizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/adapter/lib/python3.9/site-packages/transformers/onnx/convert.py:191\u001b[0m, in \u001b[0;36mexport_pytorch\u001b[0;34m(preprocessor, model, config, opset, output, tokenizer, device)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    190\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m             onnx_export(\n\u001b[1;32m    192\u001b[0m                 model,\n\u001b[1;32m    193\u001b[0m                 (model_inputs,),\n\u001b[1;32m    194\u001b[0m                 f\u001b[39m=\u001b[39;49moutput\u001b[39m.\u001b[39;49mas_posix(),\n\u001b[1;32m    195\u001b[0m                 input_names\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(config\u001b[39m.\u001b[39;49minputs\u001b[39m.\u001b[39;49mkeys()),\n\u001b[1;32m    196\u001b[0m                 output_names\u001b[39m=\u001b[39;49monnx_outputs,\n\u001b[1;32m    197\u001b[0m                 dynamic_axes\u001b[39m=\u001b[39;49m{name: axes \u001b[39mfor\u001b[39;49;00m name, axes \u001b[39min\u001b[39;49;00m chain(config\u001b[39m.\u001b[39;49minputs\u001b[39m.\u001b[39;49mitems(), config\u001b[39m.\u001b[39;49moutputs\u001b[39m.\u001b[39;49mitems())},\n\u001b[1;32m    198\u001b[0m                 do_constant_folding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    199\u001b[0m                 opset_version\u001b[39m=\u001b[39;49mopset,\n\u001b[1;32m    200\u001b[0m             )\n\u001b[1;32m    202\u001b[0m         config\u001b[39m.\u001b[39mrestore_ops()\n\u001b[1;32m    204\u001b[0m \u001b[39mreturn\u001b[39;00m matched_inputs, onnx_outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/adapter/lib/python3.9/site-packages/torch/onnx/utils.py:504\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    188\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    205\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     _export(\n\u001b[1;32m    505\u001b[0m         model,\n\u001b[1;32m    506\u001b[0m         args,\n\u001b[1;32m    507\u001b[0m         f,\n\u001b[1;32m    508\u001b[0m         export_params,\n\u001b[1;32m    509\u001b[0m         verbose,\n\u001b[1;32m    510\u001b[0m         training,\n\u001b[1;32m    511\u001b[0m         input_names,\n\u001b[1;32m    512\u001b[0m         output_names,\n\u001b[1;32m    513\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    514\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    515\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    516\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    517\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    518\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    519\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    520\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/adapter/lib/python3.9/site-packages/torch/onnx/utils.py:1529\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1527\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1529\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1530\u001b[0m     model,\n\u001b[1;32m   1531\u001b[0m     args,\n\u001b[1;32m   1532\u001b[0m     verbose,\n\u001b[1;32m   1533\u001b[0m     input_names,\n\u001b[1;32m   1534\u001b[0m     output_names,\n\u001b[1;32m   1535\u001b[0m     operator_export_type,\n\u001b[1;32m   1536\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1537\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1538\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1539\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1542\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1544\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1545\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/adapter/lib/python3.9/site-packages/torch/onnx/utils.py:1178\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     _C\u001b[39m.\u001b[39m_jit_pass_dce_allow_deleting_nodes_with_side_effects(graph)\n\u001b[1;32m   1177\u001b[0m \u001b[39mif\u001b[39;00m GLOBALS\u001b[39m.\u001b[39monnx_shape_inference:\n\u001b[0;32m-> 1178\u001b[0m     _C\u001b[39m.\u001b[39;49m_jit_pass_onnx_graph_shape_type_inference(\n\u001b[1;32m   1179\u001b[0m         graph, params_dict, GLOBALS\u001b[39m.\u001b[39;49mexport_onnx_opset_version\n\u001b[1;32m   1180\u001b[0m     )\n\u001b[1;32m   1182\u001b[0m params_dict \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_jit_pass_onnx_eliminate_unused_items(graph, params_dict)\n\u001b[1;32m   1184\u001b[0m \u001b[39m# For ONNX opset < 9, constants only have three data types: float16, float, double.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m \u001b[39m# In this pass transform constants of other data types to float/double + cast operator.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"facebook/bart-base\")\n",
    "onnx_config = BartOnnxConfig.from_model_config(config, task=\"causal-lm\")\n",
    "\n",
    "onnx_path = Path(\"onnx/narrativeqabart/model.onnx\")\n",
    "\n",
    "onnx_inputs, onnx_outputs = export(tokenizer, model, onnx_config, onnx_config.default_onnx_opset, onnx_path)\n",
    "\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[30.675707  ,  3.679289  , 11.935048  , ...,  3.3267808 ,\n",
       "           3.516271  , -3.3814769 ],\n",
       "         [-8.085179  , -5.7296076 , -1.669905  , ..., -5.304813  ,\n",
       "          -5.4988723 , -5.624103  ],\n",
       "         [-5.5636964 , -4.7784514 ,  2.1397166 , ..., -4.5751605 ,\n",
       "          -4.6781487 ,  0.81019855],\n",
       "         ...,\n",
       "         [ 0.41185176,  4.9883056 ,  1.7541847 , ...,  2.3238065 ,\n",
       "           2.1625607 , -8.073326  ],\n",
       "         [ 0.41218436,  4.988228  ,  1.7548296 , ...,  2.323756  ,\n",
       "           2.1624923 , -8.073664  ],\n",
       "         [ 0.41163564,  4.9882956 ,  1.7547405 , ...,  2.3238852 ,\n",
       "           2.1626616 , -8.0732    ]]], dtype=float32),\n",
       " array([[[-0.03363782,  0.00642321, -0.01001072, ..., -0.00211524,\n",
       "          -0.01134961,  0.02103707],\n",
       "         [ 0.00783383,  0.17353505,  0.08948383, ...,  0.10017681,\n",
       "          -0.02552552, -0.25290546],\n",
       "         [-0.05093537,  0.21927737, -0.26953176, ..., -0.03408422,\n",
       "           0.02267775, -0.14877988],\n",
       "         ...,\n",
       "         [ 0.21313739,  0.04274432, -0.13357584, ..., -0.21443734,\n",
       "          -0.24533191, -0.17374931],\n",
       "         [ 0.00272601,  0.00799653,  0.1704676 , ..., -0.04175884,\n",
       "          -0.17373921,  0.12362748],\n",
       "         [ 0.02827514,  0.07999783,  0.06470053, ..., -0.08228873,\n",
       "          -0.12523077,  0.11767629]]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model = InferenceSession(\n",
    "    str(onnx_path), providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "encoding = tokenizer(question, text, return_tensors='np')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "outputs = onnx_model.run(input_feed=dict(encoding), output_names=None)\n",
    "\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a7f5a2c07603db35bc4e52cfd5b475adbf202ae824ea4c5e531d495460257f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
