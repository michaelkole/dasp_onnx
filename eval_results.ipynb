{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eval_files/categorical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head(5)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df[df[\"skill\"] == \"categorical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_diff_of_logits(datafr, model_name):\n",
    "    l = datafr[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "\n",
    "    float_list = []\n",
    "    for v in l:\n",
    "        s = v.split()\n",
    "        float_list.append([float(s[0]), float(s[1])])\n",
    "\n",
    "    r_list = []\n",
    "    for fe in float_list:\n",
    "        r = fe[0] - fe[1]\n",
    "        r_list.append(r)\n",
    "        \n",
    "    mean_diff = sum(r_list) / len(r_list)\n",
    "    return abs(mean_diff) # return only pos. value\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to gold label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_dataset\"\n",
    "model_name_answer_column_list = [\"answer_base\", \"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_base\", \"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "Hits for bert-base-uncased boolq answer_base is: 0.7339449541284404. T: 2400. F: 870.\n",
      "Hits for bert-base-uncased boolq answer_quantized_model is: 0.7363914373088685. T: 2408. F: 862.\n",
      "Hits for bert-base-uncased boolq answer_onnx_model is: 0.6174311926605505. T: 2019. F: 1251.\n",
      "Hits for bert-base-uncased boolq answer_onnx_opt_model is: 0.6174311926605505. T: 2019. F: 1251.\n",
      "Hits for bert-base-uncased boolq answer_quant_onnx_model is: 0.5376146788990825. T: 1758. F: 1512.\n",
      "Hits for bert-base-uncased boolq answer_quant_onnx_opt_model is: 0.5376146788990825. T: 1758. F: 1512.\n",
      "Loading: roberta-base boolq\n",
      "Hits for roberta-base boolq answer_base is: 0.789908256880734. T: 2583. F: 687.\n",
      "Hits for roberta-base boolq answer_quantized_model is: 0.791743119266055. T: 2589. F: 681.\n",
      "Hits for roberta-base boolq answer_onnx_model is: 0.7660550458715596. T: 2505. F: 765.\n",
      "Hits for roberta-base boolq answer_onnx_opt_model is: 0.7660550458715596. T: 2505. F: 765.\n",
      "Hits for roberta-base boolq answer_quant_onnx_model is: 0.7535168195718654. T: 2464. F: 806.\n",
      "Hits for roberta-base boolq answer_quant_onnx_opt_model is: 0.7535168195718654. T: 2464. F: 806.\n"
     ]
    }
   ],
   "source": [
    "r_df = pd.DataFrame(columns=[\n",
    "    \"adapter\", \"reader\", \"column_name\", \n",
    "    \"accuracy\", \"total_true\", \"total_false\", \"total_amount\",\n",
    "    \"precision\", \"recall\", \"f1\"\n",
    "])\n",
    "\n",
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        total_amount = len(reader_adapter_cat_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            y_pred = reader_adapter_cat_df[column_name].to_list()\n",
    "            y_true = reader_adapter_cat_df[gold_label_column_name].to_list()\n",
    "\n",
    "            hits = (total_true)/total_amount\n",
    "\n",
    "            # micro\n",
    "            # macro \n",
    "            # weighted\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "            print(f\"Hits for {reader} {adapter} {column_name} is: {hits}. T: {total_true}. F: {total_false}.\")\n",
    "\n",
    "            r_df.loc[len(r_df)] = [\n",
    "                adapter, reader, column_name, \n",
    "                hits, total_true, total_false, total_amount,\n",
    "                precision, recall, f1\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total_true</th>\n",
       "      <th>total_false</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_base</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>2400</td>\n",
       "      <td>870</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.761348</td>\n",
       "      <td>0.833251</td>\n",
       "      <td>0.795679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.736391</td>\n",
       "      <td>2408</td>\n",
       "      <td>862</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.762203</td>\n",
       "      <td>0.837186</td>\n",
       "      <td>0.797937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.617431</td>\n",
       "      <td>2019</td>\n",
       "      <td>1251</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.692611</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.692099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.617431</td>\n",
       "      <td>2019</td>\n",
       "      <td>1251</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.692611</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>0.692099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.537615</td>\n",
       "      <td>1758</td>\n",
       "      <td>1512</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.747388</td>\n",
       "      <td>0.387113</td>\n",
       "      <td>0.510045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.537615</td>\n",
       "      <td>1758</td>\n",
       "      <td>1512</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.747388</td>\n",
       "      <td>0.387113</td>\n",
       "      <td>0.510045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_base</td>\n",
       "      <td>0.789908</td>\n",
       "      <td>2583</td>\n",
       "      <td>687</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.824181</td>\n",
       "      <td>0.841613</td>\n",
       "      <td>0.832806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.791743</td>\n",
       "      <td>2589</td>\n",
       "      <td>681</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.824376</td>\n",
       "      <td>0.845057</td>\n",
       "      <td>0.834588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.766055</td>\n",
       "      <td>2505</td>\n",
       "      <td>765</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.824823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.766055</td>\n",
       "      <td>2505</td>\n",
       "      <td>765</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.824823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.753517</td>\n",
       "      <td>2464</td>\n",
       "      <td>806</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.760510</td>\n",
       "      <td>0.880964</td>\n",
       "      <td>0.816317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.753517</td>\n",
       "      <td>2464</td>\n",
       "      <td>806</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.760510</td>\n",
       "      <td>0.880964</td>\n",
       "      <td>0.816317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adapter             reader                  column_name  accuracy  \\\n",
       "0    boolq  bert-base-uncased                  answer_base  0.733945   \n",
       "1    boolq  bert-base-uncased       answer_quantized_model  0.736391   \n",
       "2    boolq  bert-base-uncased            answer_onnx_model  0.617431   \n",
       "3    boolq  bert-base-uncased        answer_onnx_opt_model  0.617431   \n",
       "4    boolq  bert-base-uncased      answer_quant_onnx_model  0.537615   \n",
       "5    boolq  bert-base-uncased  answer_quant_onnx_opt_model  0.537615   \n",
       "6    boolq       roberta-base                  answer_base  0.789908   \n",
       "7    boolq       roberta-base       answer_quantized_model  0.791743   \n",
       "8    boolq       roberta-base            answer_onnx_model  0.766055   \n",
       "9    boolq       roberta-base        answer_onnx_opt_model  0.766055   \n",
       "10   boolq       roberta-base      answer_quant_onnx_model  0.753517   \n",
       "11   boolq       roberta-base  answer_quant_onnx_opt_model  0.753517   \n",
       "\n",
       "    total_true  total_false  total_amount  precision    recall        f1  \n",
       "0         2400          870          3270   0.761348  0.833251  0.795679  \n",
       "1         2408          862          3270   0.762203  0.837186  0.797937  \n",
       "2         2019         1251          3270   0.692611  0.691589  0.692099  \n",
       "3         2019         1251          3270   0.692611  0.691589  0.692099  \n",
       "4         1758         1512          3270   0.747388  0.387113  0.510045  \n",
       "5         1758         1512          3270   0.747388  0.387113  0.510045  \n",
       "6         2583          687          3270   0.824181  0.841613  0.832806  \n",
       "7         2589          681          3270   0.824376  0.845057  0.834588  \n",
       "8         2505          765          3270   0.771637  0.885883  0.824823  \n",
       "9         2505          765          3270   0.771637  0.885883  0.824823  \n",
       "10        2464          806          3270   0.760510  0.880964  0.816317  \n",
       "11        2464          806          3270   0.760510  0.880964  0.816317  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc diff of logits (of binary) if pred is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_diff_of_logits_2(datafr, model_name):\n",
    "    l = datafr[model_name].str.replace(\"([\\[\\]'])\", \"\", regex=True)\n",
    "\n",
    "    float_list = []\n",
    "    for v in l:\n",
    "        s = v.split(\", \")\n",
    "        float_list.append([float(s[0]), float(s[1])])\n",
    "\n",
    "    r_list = []\n",
    "    for fe in float_list:\n",
    "        r = fe[0] - fe[1]\n",
    "        r_list.append(r)\n",
    "        \n",
    "    mean_diff = sum(r_list) / len(r_list)\n",
    "    return abs(mean_diff) # return only pos. value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16006458114519867\n",
      "1.3025332073218743\n",
      "1.0647809442903062\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "t = df.index[df[\"answer_base\"] == df[\"answer_onnx_model\"]]\n",
    "f = df.index[df[\"answer_base\"] != df[\"answer_onnx_model\"]]\n",
    "\n",
    "false_onnx = df.iloc[f]\n",
    "true_onnx = df.iloc[t]\n",
    "\n",
    "#get result for false results for onnx model\n",
    "model_name_logits = model_name_logits_column_list[2]\n",
    "mean_diff_false_results = get_mean_diff_of_logits_2(false_onnx, model_name_logits)\n",
    "print(mean_diff_false_results)\n",
    "mean_diff_true_results = get_mean_diff_of_logits_2(true_onnx, model_name_logits)\n",
    "print(mean_diff_true_results)\n",
    "mean_diff_all_results = get_mean_diff_of_logits_2(df, model_name_logits)\n",
    "print(mean_diff_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_base 0.5527182899770107\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_base 1.2831902399541695\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.5779924959446868\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quantized_model 1.2983542962500025\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_model 0.10977075498867121\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_model 0.7066019500930119\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 0.10977075498867121\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 0.7066019500930119\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.5516529688425929\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 0.2652241823093903\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.5516529688425929\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 0.2652241823093903\n",
      "______\n",
      "\n",
      "Loading: roberta-base boolq\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_base 0.4040738217959158\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_base 1.5820329910375497\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.4107911646475421\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quantized_model 1.5999649035225951\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_model 1.0890937720261429\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_model 1.822977280770459\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 1.0890937720261429\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 1.822977280770459\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.9949980646277912\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 1.573846568120941\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.9949980646277912\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 1.573846568120941\n",
      "______\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            column_name_logits = model_name_logits_column_list[model_name_answer_column_list.index(column_name)]\n",
    "            false_pred_df = reader_adapter_cat_df.iloc[f]\n",
    "            true_pred_df = reader_adapter_cat_df.iloc[t]\n",
    "\n",
    "            mean_diff_false_results = get_mean_diff_of_logits_2(false_pred_df, column_name_logits)\n",
    "            mean_diff_true_results = get_mean_diff_of_logits_2(true_pred_df, column_name_logits)\n",
    "            print(f\"{reader} {adapter}. Mean diff logits wrong answer: {column_name_logits} {mean_diff_false_results}\")\n",
    "            print(f\"{reader} {adapter}. Mean diff logits right answer: {column_name_logits} {mean_diff_true_results}\")\n",
    "\n",
    "            print(\"______\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Base pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_base\"\n",
    "model_name_answer_column_list = [\"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame(columns=[\n",
    "    \"adapter\", \"reader\", \"column_name\", \n",
    "    \"accuracy\", \"total_true\", \"total_false\", \"total_amount\",\n",
    "    \"precision\", \"recall\", \"f1\"\n",
    "])\n",
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        # print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        total_amount = len(reader_adapter_cat_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "            \n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            y_pred = reader_adapter_cat_df[column_name].to_list()\n",
    "            y_true = reader_adapter_cat_df[gold_label_column_name].to_list()\n",
    "\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "            r_df.loc[len(r_df)] = [\n",
    "                adapter, reader, column_name, \n",
    "                accuracy, total_true, total_false, total_amount,\n",
    "                precision, recall, f1\n",
    "            ]\n",
    "            # print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total_true</th>\n",
       "      <th>total_false</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.991437</td>\n",
       "      <td>3242</td>\n",
       "      <td>28</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>0.995506</td>\n",
       "      <td>0.993719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.709174</td>\n",
       "      <td>2319</td>\n",
       "      <td>951</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.742472</td>\n",
       "      <td>0.776498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.709174</td>\n",
       "      <td>2319</td>\n",
       "      <td>951</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.742472</td>\n",
       "      <td>0.776498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.556575</td>\n",
       "      <td>1820</td>\n",
       "      <td>1450</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.867996</td>\n",
       "      <td>0.410787</td>\n",
       "      <td>0.557657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boolq</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.556575</td>\n",
       "      <td>1820</td>\n",
       "      <td>1450</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.867996</td>\n",
       "      <td>0.410787</td>\n",
       "      <td>0.557657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.987768</td>\n",
       "      <td>3230</td>\n",
       "      <td>40</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.990385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.874618</td>\n",
       "      <td>2860</td>\n",
       "      <td>410</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.856898</td>\n",
       "      <td>0.963391</td>\n",
       "      <td>0.907029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.874618</td>\n",
       "      <td>2860</td>\n",
       "      <td>410</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.856898</td>\n",
       "      <td>0.963391</td>\n",
       "      <td>0.907029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>2775</td>\n",
       "      <td>495</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.835669</td>\n",
       "      <td>0.947977</td>\n",
       "      <td>0.888287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>boolq</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.848624</td>\n",
       "      <td>2775</td>\n",
       "      <td>495</td>\n",
       "      <td>3270</td>\n",
       "      <td>0.835669</td>\n",
       "      <td>0.947977</td>\n",
       "      <td>0.888287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adapter             reader                  column_name  accuracy  \\\n",
       "0   boolq  bert-base-uncased       answer_quantized_model  0.991437   \n",
       "1   boolq  bert-base-uncased            answer_onnx_model  0.709174   \n",
       "2   boolq  bert-base-uncased        answer_onnx_opt_model  0.709174   \n",
       "3   boolq  bert-base-uncased      answer_quant_onnx_model  0.556575   \n",
       "4   boolq  bert-base-uncased  answer_quant_onnx_opt_model  0.556575   \n",
       "5   boolq       roberta-base       answer_quantized_model  0.987768   \n",
       "6   boolq       roberta-base            answer_onnx_model  0.874618   \n",
       "7   boolq       roberta-base        answer_onnx_opt_model  0.874618   \n",
       "8   boolq       roberta-base      answer_quant_onnx_model  0.848624   \n",
       "9   boolq       roberta-base  answer_quant_onnx_opt_model  0.848624   \n",
       "\n",
       "   total_true  total_false  total_amount  precision    recall        f1  \n",
       "0        3242           28          3270   0.991939  0.995506  0.993719  \n",
       "1        2319          951          3270   0.813793  0.742472  0.776498  \n",
       "2        2319          951          3270   0.813793  0.742472  0.776498  \n",
       "3        1820         1450          3270   0.867996  0.410787  0.557657  \n",
       "4        1820         1450          3270   0.867996  0.410787  0.557657  \n",
       "5        3230           40          3270   0.988484  0.992293  0.990385  \n",
       "6        2860          410          3270   0.856898  0.963391  0.907029  \n",
       "7        2860          410          3270   0.856898  0.963391  0.907029  \n",
       "8        2775          495          3270   0.835669  0.947977  0.888287  \n",
       "9        2775          495          3270   0.835669  0.947977  0.888287  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r_df.head()\n",
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adapter in cat_df[\"adapter\"].unique():\n",
    "#     adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "#     for reader in adapter_cat_df[\"reader\"].unique():\n",
    "#         reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "#         print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "#         for column_name in model_name_answer_column_list:\n",
    "#             t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "#             f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "#             column_name_logits = model_name_logits_column_list[model_name_answer_column_list.index(column_name)]\n",
    "#             false_pred_df = reader_adapter_cat_df.iloc[f]\n",
    "#             true_pred_df = reader_adapter_cat_df.iloc[t]\n",
    "\n",
    "#             mean_diff_false_results = get_mean_diff_of_logits(false_pred_df, column_name_logits)\n",
    "#             mean_diff_true_results = get_mean_diff_of_logits(true_pred_df, column_name_logits)\n",
    "            \n",
    "            \n",
    "#             print(f\"{reader} {adapter}. Mean diff logits wrong answer: {column_name_logits} {mean_diff_false_results}\")\n",
    "#             print(f\"{reader} {adapter}. Mean diff logits right answer: {column_name_logits} {mean_diff_true_results}\")\n",
    "\n",
    "#             print(\"______\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Mcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"eval_files/multiple_choice.csv\")\n",
    "mcq_df = df[df[\"skill\"] == \"multiple-choice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_dataset\"\n",
    "model_name_answer_column_list = [\"answer_base\", \"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_base\", \"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame(columns=[\n",
    "    \"adapter\", \"reader\", \"column_name\", \n",
    "    \"accuracy\", \"total_true\", \"total_false\", \"total_amount\",\n",
    "    \"precision\", \"recall\", \"f1\"\n",
    "])\n",
    "\n",
    "for adapter in mcq_df[\"adapter\"].unique():\n",
    "    adapter_mcq_df = mcq_df[mcq_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_mcq_df[\"reader\"].unique():\n",
    "        # print(f\"Loading: {reader} {adapter}\")\n",
    "        reader_adapter_mcq_df = adapter_mcq_df[adapter_mcq_df[\"reader\"] == reader].reset_index()\n",
    "\n",
    "        total_amount = len(reader_adapter_mcq_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_mcq_df.index[reader_adapter_mcq_df[\"answer_dataset\"] == reader_adapter_mcq_df[column_name]]\n",
    "            f = reader_adapter_mcq_df.index[reader_adapter_mcq_df[\"answer_dataset\"] != reader_adapter_mcq_df[column_name]]\n",
    "\n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            y_pred = reader_adapter_cat_df[column_name].to_list()\n",
    "            y_true = reader_adapter_cat_df[gold_label_column_name].to_list()\n",
    "\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "            r_df.loc[len(r_df)] = [\n",
    "                adapter, reader, column_name, \n",
    "                accuracy, total_true, total_false, total_amount,\n",
    "                precision, recall, f1\n",
    "            ]\n",
    "            \n",
    "            # print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total_true</th>\n",
       "      <th>total_false</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_base</td>\n",
       "      <td>0.783854</td>\n",
       "      <td>301</td>\n",
       "      <td>83</td>\n",
       "      <td>384</td>\n",
       "      <td>0.824181</td>\n",
       "      <td>0.841613</td>\n",
       "      <td>0.832806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.778646</td>\n",
       "      <td>299</td>\n",
       "      <td>85</td>\n",
       "      <td>384</td>\n",
       "      <td>0.824376</td>\n",
       "      <td>0.845057</td>\n",
       "      <td>0.834588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>258</td>\n",
       "      <td>126</td>\n",
       "      <td>384</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.824823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>258</td>\n",
       "      <td>126</td>\n",
       "      <td>384</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.885883</td>\n",
       "      <td>0.824823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>252</td>\n",
       "      <td>132</td>\n",
       "      <td>384</td>\n",
       "      <td>0.760510</td>\n",
       "      <td>0.880964</td>\n",
       "      <td>0.816317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adapter        reader              column_name  accuracy  total_true  \\\n",
       "0  quartz  roberta-base              answer_base  0.783854         301   \n",
       "1  quartz  roberta-base   answer_quantized_model  0.778646         299   \n",
       "2  quartz  roberta-base        answer_onnx_model  0.671875         258   \n",
       "3  quartz  roberta-base    answer_onnx_opt_model  0.671875         258   \n",
       "4  quartz  roberta-base  answer_quant_onnx_model  0.656250         252   \n",
       "\n",
       "   total_false  total_amount  precision    recall        f1  \n",
       "0           83           384   0.824181  0.841613  0.832806  \n",
       "1           85           384   0.824376  0.845057  0.834588  \n",
       "2          126           384   0.771637  0.885883  0.824823  \n",
       "3          126           384   0.771637  0.885883  0.824823  \n",
       "4          132           384   0.760510  0.880964  0.816317  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_base\"\n",
    "model_name_answer_column_list = [\"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/michaelhermann/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "r_df = pd.DataFrame(columns=[\n",
    "    \"adapter\", \"reader\", \"column_name\", \n",
    "    \"accuracy\", \"total_true\", \"total_false\", \"total_amount\",\n",
    "    \"precision\", \"recall\", \"f1\"\n",
    "])\n",
    "for adapter in mcq_df[\"adapter\"].unique():\n",
    "    adapter_mcq_df = mcq_df[mcq_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_mcq_df[\"reader\"].unique():\n",
    "        reader_adapter_mcq_df = adapter_mcq_df[adapter_mcq_df[\"reader\"] == reader].reset_index()\n",
    "        # print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        total_amount = len(reader_adapter_mcq_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_mcq_df.index[reader_adapter_mcq_df[gold_label_column_name] == reader_adapter_mcq_df[column_name]]\n",
    "            f = reader_adapter_mcq_df.index[reader_adapter_mcq_df[gold_label_column_name] != reader_adapter_mcq_df[column_name]]\n",
    "            \n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            y_pred = reader_adapter_mcq_df[column_name].to_list()\n",
    "            y_true = reader_adapter_mcq_df[gold_label_column_name].to_list()\n",
    "\n",
    "            precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "            recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "            f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "            r_df.loc[len(r_df)] = [\n",
    "                adapter, reader, column_name, \n",
    "                accuracy, total_true, total_false, total_amount,\n",
    "                precision, recall, f1\n",
    "            ]\n",
    "            # print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>column_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total_true</th>\n",
       "      <th>total_false</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>368</td>\n",
       "      <td>16</td>\n",
       "      <td>384</td>\n",
       "      <td>0.927064</td>\n",
       "      <td>0.934821</td>\n",
       "      <td>0.925619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>277</td>\n",
       "      <td>107</td>\n",
       "      <td>384</td>\n",
       "      <td>0.589933</td>\n",
       "      <td>0.662096</td>\n",
       "      <td>0.602677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>277</td>\n",
       "      <td>107</td>\n",
       "      <td>384</td>\n",
       "      <td>0.589933</td>\n",
       "      <td>0.662096</td>\n",
       "      <td>0.602677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>279</td>\n",
       "      <td>105</td>\n",
       "      <td>384</td>\n",
       "      <td>0.636490</td>\n",
       "      <td>0.670749</td>\n",
       "      <td>0.632701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quartz</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>279</td>\n",
       "      <td>105</td>\n",
       "      <td>384</td>\n",
       "      <td>0.636490</td>\n",
       "      <td>0.670749</td>\n",
       "      <td>0.632701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>quartz</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>290</td>\n",
       "      <td>94</td>\n",
       "      <td>384</td>\n",
       "      <td>0.618211</td>\n",
       "      <td>0.555243</td>\n",
       "      <td>0.569021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quartz</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>194</td>\n",
       "      <td>190</td>\n",
       "      <td>384</td>\n",
       "      <td>0.367831</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.362298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quartz</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.505208</td>\n",
       "      <td>194</td>\n",
       "      <td>190</td>\n",
       "      <td>384</td>\n",
       "      <td>0.367831</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.362298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quartz</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.513021</td>\n",
       "      <td>197</td>\n",
       "      <td>187</td>\n",
       "      <td>384</td>\n",
       "      <td>0.422830</td>\n",
       "      <td>0.355577</td>\n",
       "      <td>0.370302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quartz</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.513021</td>\n",
       "      <td>197</td>\n",
       "      <td>187</td>\n",
       "      <td>384</td>\n",
       "      <td>0.422830</td>\n",
       "      <td>0.355577</td>\n",
       "      <td>0.370302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>race</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.964674</td>\n",
       "      <td>355</td>\n",
       "      <td>13</td>\n",
       "      <td>368</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.930481</td>\n",
       "      <td>0.930481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>race</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.557065</td>\n",
       "      <td>205</td>\n",
       "      <td>163</td>\n",
       "      <td>368</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>0.387492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>race</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.557065</td>\n",
       "      <td>205</td>\n",
       "      <td>163</td>\n",
       "      <td>368</td>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>0.387492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>race</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.480978</td>\n",
       "      <td>177</td>\n",
       "      <td>191</td>\n",
       "      <td>368</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.320183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>race</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.480978</td>\n",
       "      <td>177</td>\n",
       "      <td>191</td>\n",
       "      <td>368</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.321101</td>\n",
       "      <td>0.320183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>race</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.964674</td>\n",
       "      <td>355</td>\n",
       "      <td>13</td>\n",
       "      <td>368</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.930108</td>\n",
       "      <td>0.930108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>race</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.448370</td>\n",
       "      <td>165</td>\n",
       "      <td>203</td>\n",
       "      <td>368</td>\n",
       "      <td>0.292646</td>\n",
       "      <td>0.293852</td>\n",
       "      <td>0.292345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>race</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.448370</td>\n",
       "      <td>165</td>\n",
       "      <td>203</td>\n",
       "      <td>368</td>\n",
       "      <td>0.292646</td>\n",
       "      <td>0.293852</td>\n",
       "      <td>0.292345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>race</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>132</td>\n",
       "      <td>236</td>\n",
       "      <td>368</td>\n",
       "      <td>0.220412</td>\n",
       "      <td>0.222985</td>\n",
       "      <td>0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>race</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>132</td>\n",
       "      <td>236</td>\n",
       "      <td>368</td>\n",
       "      <td>0.220412</td>\n",
       "      <td>0.222985</td>\n",
       "      <td>0.220983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.960469</td>\n",
       "      <td>2867</td>\n",
       "      <td>118</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.924958</td>\n",
       "      <td>0.924969</td>\n",
       "      <td>0.924785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.732328</td>\n",
       "      <td>2186</td>\n",
       "      <td>799</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.607158</td>\n",
       "      <td>0.606411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.732328</td>\n",
       "      <td>2186</td>\n",
       "      <td>799</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.607270</td>\n",
       "      <td>0.607158</td>\n",
       "      <td>0.606411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.697822</td>\n",
       "      <td>2083</td>\n",
       "      <td>902</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.564130</td>\n",
       "      <td>0.563303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.697822</td>\n",
       "      <td>2083</td>\n",
       "      <td>902</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.564130</td>\n",
       "      <td>0.563303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.969179</td>\n",
       "      <td>2893</td>\n",
       "      <td>92</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.943825</td>\n",
       "      <td>0.943839</td>\n",
       "      <td>0.943586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.597655</td>\n",
       "      <td>1784</td>\n",
       "      <td>1201</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.454568</td>\n",
       "      <td>0.455066</td>\n",
       "      <td>0.453545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.597655</td>\n",
       "      <td>1784</td>\n",
       "      <td>1201</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.454568</td>\n",
       "      <td>0.455066</td>\n",
       "      <td>0.453545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.464657</td>\n",
       "      <td>1387</td>\n",
       "      <td>1598</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.322777</td>\n",
       "      <td>0.321002</td>\n",
       "      <td>0.320582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.464657</td>\n",
       "      <td>1387</td>\n",
       "      <td>1598</td>\n",
       "      <td>2985</td>\n",
       "      <td>0.322777</td>\n",
       "      <td>0.321002</td>\n",
       "      <td>0.320582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>quail</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.883549</td>\n",
       "      <td>1912</td>\n",
       "      <td>252</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.783328</td>\n",
       "      <td>0.783490</td>\n",
       "      <td>0.782588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>quail</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.538817</td>\n",
       "      <td>1166</td>\n",
       "      <td>998</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.401987</td>\n",
       "      <td>0.400980</td>\n",
       "      <td>0.400108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>quail</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.538817</td>\n",
       "      <td>1166</td>\n",
       "      <td>998</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.401987</td>\n",
       "      <td>0.400980</td>\n",
       "      <td>0.400108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>quail</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.468577</td>\n",
       "      <td>1014</td>\n",
       "      <td>1150</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.329811</td>\n",
       "      <td>0.329050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>quail</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.468577</td>\n",
       "      <td>1014</td>\n",
       "      <td>1150</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.331250</td>\n",
       "      <td>0.329811</td>\n",
       "      <td>0.329050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>quail</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quantized_model</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>2102</td>\n",
       "      <td>62</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>0.940528</td>\n",
       "      <td>0.940066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>quail</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_model</td>\n",
       "      <td>0.531885</td>\n",
       "      <td>1151</td>\n",
       "      <td>1013</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.387645</td>\n",
       "      <td>0.390231</td>\n",
       "      <td>0.387376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>quail</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_onnx_opt_model</td>\n",
       "      <td>0.531885</td>\n",
       "      <td>1151</td>\n",
       "      <td>1013</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.387645</td>\n",
       "      <td>0.390231</td>\n",
       "      <td>0.387376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>quail</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_model</td>\n",
       "      <td>0.402033</td>\n",
       "      <td>870</td>\n",
       "      <td>1294</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.272962</td>\n",
       "      <td>0.271970</td>\n",
       "      <td>0.271282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>quail</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>answer_quant_onnx_opt_model</td>\n",
       "      <td>0.402033</td>\n",
       "      <td>870</td>\n",
       "      <td>1294</td>\n",
       "      <td>2164</td>\n",
       "      <td>0.272962</td>\n",
       "      <td>0.271970</td>\n",
       "      <td>0.271282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      adapter             reader                  column_name  accuracy  \\\n",
       "0      quartz       roberta-base       answer_quantized_model  0.958333   \n",
       "1      quartz       roberta-base            answer_onnx_model  0.721354   \n",
       "2      quartz       roberta-base        answer_onnx_opt_model  0.721354   \n",
       "3      quartz       roberta-base      answer_quant_onnx_model  0.726562   \n",
       "4      quartz       roberta-base  answer_quant_onnx_opt_model  0.726562   \n",
       "5      quartz  bert-base-uncased       answer_quantized_model  0.755208   \n",
       "6      quartz  bert-base-uncased            answer_onnx_model  0.505208   \n",
       "7      quartz  bert-base-uncased        answer_onnx_opt_model  0.505208   \n",
       "8      quartz  bert-base-uncased      answer_quant_onnx_model  0.513021   \n",
       "9      quartz  bert-base-uncased  answer_quant_onnx_opt_model  0.513021   \n",
       "10       race       roberta-base       answer_quantized_model  0.964674   \n",
       "11       race       roberta-base            answer_onnx_model  0.557065   \n",
       "12       race       roberta-base        answer_onnx_opt_model  0.557065   \n",
       "13       race       roberta-base      answer_quant_onnx_model  0.480978   \n",
       "14       race       roberta-base  answer_quant_onnx_opt_model  0.480978   \n",
       "15       race  bert-base-uncased       answer_quantized_model  0.964674   \n",
       "16       race  bert-base-uncased            answer_onnx_model  0.448370   \n",
       "17       race  bert-base-uncased        answer_onnx_opt_model  0.448370   \n",
       "18       race  bert-base-uncased      answer_quant_onnx_model  0.358696   \n",
       "19       race  bert-base-uncased  answer_quant_onnx_opt_model  0.358696   \n",
       "20  cosmos_qa       roberta-base       answer_quantized_model  0.960469   \n",
       "21  cosmos_qa       roberta-base            answer_onnx_model  0.732328   \n",
       "22  cosmos_qa       roberta-base        answer_onnx_opt_model  0.732328   \n",
       "23  cosmos_qa       roberta-base      answer_quant_onnx_model  0.697822   \n",
       "24  cosmos_qa       roberta-base  answer_quant_onnx_opt_model  0.697822   \n",
       "25  cosmos_qa  bert-base-uncased       answer_quantized_model  0.969179   \n",
       "26  cosmos_qa  bert-base-uncased            answer_onnx_model  0.597655   \n",
       "27  cosmos_qa  bert-base-uncased        answer_onnx_opt_model  0.597655   \n",
       "28  cosmos_qa  bert-base-uncased      answer_quant_onnx_model  0.464657   \n",
       "29  cosmos_qa  bert-base-uncased  answer_quant_onnx_opt_model  0.464657   \n",
       "30      quail       roberta-base       answer_quantized_model  0.883549   \n",
       "31      quail       roberta-base            answer_onnx_model  0.538817   \n",
       "32      quail       roberta-base        answer_onnx_opt_model  0.538817   \n",
       "33      quail       roberta-base      answer_quant_onnx_model  0.468577   \n",
       "34      quail       roberta-base  answer_quant_onnx_opt_model  0.468577   \n",
       "35      quail  bert-base-uncased       answer_quantized_model  0.971349   \n",
       "36      quail  bert-base-uncased            answer_onnx_model  0.531885   \n",
       "37      quail  bert-base-uncased        answer_onnx_opt_model  0.531885   \n",
       "38      quail  bert-base-uncased      answer_quant_onnx_model  0.402033   \n",
       "39      quail  bert-base-uncased  answer_quant_onnx_opt_model  0.402033   \n",
       "\n",
       "    total_true  total_false  total_amount  precision    recall        f1  \n",
       "0          368           16           384   0.927064  0.934821  0.925619  \n",
       "1          277          107           384   0.589933  0.662096  0.602677  \n",
       "2          277          107           384   0.589933  0.662096  0.602677  \n",
       "3          279          105           384   0.636490  0.670749  0.632701  \n",
       "4          279          105           384   0.636490  0.670749  0.632701  \n",
       "5          290           94           384   0.618211  0.555243  0.569021  \n",
       "6          194          190           384   0.367831  0.380743  0.362298  \n",
       "7          194          190           384   0.367831  0.380743  0.362298  \n",
       "8          197          187           384   0.422830  0.355577  0.370302  \n",
       "9          197          187           384   0.422830  0.355577  0.370302  \n",
       "10         355           13           368   0.930481  0.930481  0.930481  \n",
       "11         205          163           368   0.389749  0.386847  0.387492  \n",
       "12         205          163           368   0.389749  0.386847  0.387492  \n",
       "13         177          191           368   0.321101  0.321101  0.320183  \n",
       "14         177          191           368   0.321101  0.321101  0.320183  \n",
       "15         355           13           368   0.930108  0.930108  0.930108  \n",
       "16         165          203           368   0.292646  0.293852  0.292345  \n",
       "17         165          203           368   0.292646  0.293852  0.292345  \n",
       "18         132          236           368   0.220412  0.222985  0.220983  \n",
       "19         132          236           368   0.220412  0.222985  0.220983  \n",
       "20        2867          118          2985   0.924958  0.924969  0.924785  \n",
       "21        2186          799          2985   0.607270  0.607158  0.606411  \n",
       "22        2186          799          2985   0.607270  0.607158  0.606411  \n",
       "23        2083          902          2985   0.565194  0.564130  0.563303  \n",
       "24        2083          902          2985   0.565194  0.564130  0.563303  \n",
       "25        2893           92          2985   0.943825  0.943839  0.943586  \n",
       "26        1784         1201          2985   0.454568  0.455066  0.453545  \n",
       "27        1784         1201          2985   0.454568  0.455066  0.453545  \n",
       "28        1387         1598          2985   0.322777  0.321002  0.320582  \n",
       "29        1387         1598          2985   0.322777  0.321002  0.320582  \n",
       "30        1912          252          2164   0.783328  0.783490  0.782588  \n",
       "31        1166          998          2164   0.401987  0.400980  0.400108  \n",
       "32        1166          998          2164   0.401987  0.400980  0.400108  \n",
       "33        1014         1150          2164   0.331250  0.329811  0.329050  \n",
       "34        1014         1150          2164   0.331250  0.329811  0.329050  \n",
       "35        2102           62          2164   0.940100  0.940528  0.940066  \n",
       "36        1151         1013          2164   0.387645  0.390231  0.387376  \n",
       "37        1151         1013          2164   0.387645  0.390231  0.387376  \n",
       "38         870         1294          2164   0.272962  0.271970  0.271282  \n",
       "39         870         1294          2164   0.272962  0.271970  0.271282  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'choices', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_adapter_mcq_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = 0\n",
    "\n",
    "l = mcq_df[\"choices\"].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "choices = l.iloc[test_ind].split(\"', '\")\n",
    "choices[0] = choices[0][1:]\n",
    "choices[-1] = choices[-1][:-1]\n",
    "\n",
    "choice = mcq_df.iloc[test_ind][\"choices\"]\n",
    "\n",
    "golden_answer = mcq_df.iloc[test_ind][\"answer_dataset\"]\n",
    "base_answer = mcq_df.iloc[test_ind][\"answer_base\"]\n",
    "onnx_answer = mcq_df.iloc[test_ind][\"answer_onnx_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_of_golden_answer = choices.index(golden_answer)\n",
    "index_of_base_answer = choices.index(base_answer)\n",
    "index_of_onnx_answer = choices.index(onnx_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = mcq_df[\"logits_answer_base\"].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "l3 = mcq_df[\"logits_answer_onnx_model\"].str.replace(\"([\\[\\]])\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_base = [float(e) for e in l2.iloc[test_ind].split()]\n",
    "re_onnx = [float(e) for e in l3.iloc[test_ind].split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22903556\n"
     ]
    }
   ],
   "source": [
    "logits_base_answer = re_base[index_of_base_answer]\n",
    "logits_onnx_answer = re_onnx[index_of_onnx_answer]\n",
    "\n",
    "# print(logits_base_answer)\n",
    "# print(logits_onnx_answer)\n",
    "\n",
    "diff = abs(logits_base_answer - logits_onnx_answer)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_answer_onnx_model\n"
     ]
    }
   ],
   "source": [
    "model_name = model_name_logits_column_list[2]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = reader_adapter_mcq_df[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = []\n",
    "for v in l:\n",
    "    s = v.split()\n",
    "    float_list.append([float(s[r]) for r in range(len(s))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO find right answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list = []\n",
    "for fe in float_list:\n",
    "    r = fe[0] - fe[1]\n",
    "    r_list.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_diff_of_logits(datafr, model_name):\n",
    "    l = datafr[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "\n",
    "    float_list = []\n",
    "    for v in l:\n",
    "        s = v.split()\n",
    "        float_list.append([float(s[0]), float(s[1])])\n",
    "\n",
    "    r_list = []\n",
    "    for fe in float_list:\n",
    "        r = fe[0] - fe[1]\n",
    "        r_list.append(r)\n",
    "        \n",
    "    mean_diff = sum(r_list) / len(r_list)\n",
    "    return abs(mean_diff) # return only pos. value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"inference_time_categorical.csv\")\n",
    "# df = pd.read_csv(\"inference_time_extractive.csv\")\n",
    "# df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>mean_time_per_token</th>\n",
       "      <th>median_time_per_token</th>\n",
       "      <th>min_time_per_token</th>\n",
       "      <th>max_time_per_token</th>\n",
       "      <th>runs</th>\n",
       "      <th>time_unique_values</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>129.511690</td>\n",
       "      <td>116.297960</td>\n",
       "      <td>100.482702</td>\n",
       "      <td>190.842867</td>\n",
       "      <td>0.824915</td>\n",
       "      <td>0.740751</td>\n",
       "      <td>100.482702</td>\n",
       "      <td>190.842867</td>\n",
       "      <td>5</td>\n",
       "      <td>[116.29796028137208, 190.842866897583, 108.004...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Who scored the first touchdown of the game?</td>\n",
       "      <td>f37e81fa-ef7b-4583-b671-762fc433faa9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>118.036652</td>\n",
       "      <td>101.804018</td>\n",
       "      <td>88.285923</td>\n",
       "      <td>202.951193</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.648433</td>\n",
       "      <td>88.285923</td>\n",
       "      <td>202.951193</td>\n",
       "      <td>5</td>\n",
       "      <td>[106.0810089111328, 202.95119285583496, 88.285...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did Kris Brown kick?</td>\n",
       "      <td>ac6ba235-3024-4f63-a6ab-730a14def4cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>127.039289</td>\n",
       "      <td>119.737864</td>\n",
       "      <td>104.492188</td>\n",
       "      <td>150.061131</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.762662</td>\n",
       "      <td>104.492188</td>\n",
       "      <td>150.061131</td>\n",
       "      <td>5</td>\n",
       "      <td>[117.91324615478516, 150.06113052368164, 104.4...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Which team won the game?</td>\n",
       "      <td>2c7c93f6-69ed-47cc-a5af-94a00c185a26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>119.862890</td>\n",
       "      <td>109.892130</td>\n",
       "      <td>100.628376</td>\n",
       "      <td>161.371231</td>\n",
       "      <td>0.763458</td>\n",
       "      <td>0.699950</td>\n",
       "      <td>100.628376</td>\n",
       "      <td>161.371231</td>\n",
       "      <td>5</td>\n",
       "      <td>[119.31896209716795, 161.37123107910156, 109.8...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did both teams kick in th...</td>\n",
       "      <td>7dfd2b64-f39e-4bb4-aeb0-1900adda6018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>111.079550</td>\n",
       "      <td>109.916925</td>\n",
       "      <td>101.395845</td>\n",
       "      <td>126.971960</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.700108</td>\n",
       "      <td>101.395845</td>\n",
       "      <td>126.971960</td>\n",
       "      <td>5</td>\n",
       "      <td>[126.97196006774902, 113.73090744018556, 103.3...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many more yards was Kris Browns's first fi...</td>\n",
       "      <td>121a8f57-7752-4373-a9ba-748b2c577cd2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 adapter             reader model_name   mean_time  median_time  \\\n",
       "0           0    drop  bert-base-uncased       Base  129.511690   116.297960   \n",
       "1           1    drop  bert-base-uncased       Base  118.036652   101.804018   \n",
       "2           2    drop  bert-base-uncased       Base  127.039289   119.737864   \n",
       "3           3    drop  bert-base-uncased       Base  119.862890   109.892130   \n",
       "4           4    drop  bert-base-uncased       Base  111.079550   109.916925   \n",
       "\n",
       "     min_time    max_time  mean_time_per_token  median_time_per_token  \\\n",
       "0  100.482702  190.842867             0.824915               0.740751   \n",
       "1   88.285923  202.951193             0.751826               0.648433   \n",
       "2  104.492188  150.061131             0.809167               0.762662   \n",
       "3  100.628376  161.371231             0.763458               0.699950   \n",
       "4  101.395845  126.971960             0.707513               0.700108   \n",
       "\n",
       "   min_time_per_token  max_time_per_token  runs  \\\n",
       "0          100.482702          190.842867     5   \n",
       "1           88.285923          202.951193     5   \n",
       "2          104.492188          150.061131     5   \n",
       "3          100.628376          161.371231     5   \n",
       "4          101.395845          126.971960     5   \n",
       "\n",
       "                                  time_unique_values  seq_length  \\\n",
       "0  [116.29796028137208, 190.842866897583, 108.004...         157   \n",
       "1  [106.0810089111328, 202.95119285583496, 88.285...         157   \n",
       "2  [117.91324615478516, 150.06113052368164, 104.4...         157   \n",
       "3  [119.31896209716795, 161.37123107910156, 109.8...         157   \n",
       "4  [126.97196006774902, 113.73090744018556, 103.3...         157   \n",
       "\n",
       "                                             context  \\\n",
       "0   Hoping to rebound from their loss to the Patr...   \n",
       "1   Hoping to rebound from their loss to the Patr...   \n",
       "2   Hoping to rebound from their loss to the Patr...   \n",
       "3   Hoping to rebound from their loss to the Patr...   \n",
       "4   Hoping to rebound from their loss to the Patr...   \n",
       "\n",
       "                                            question  \\\n",
       "0        Who scored the first touchdown of the game?   \n",
       "1          How many field goals did Kris Brown kick?   \n",
       "2                           Which team won the game?   \n",
       "3  How many field goals did both teams kick in th...   \n",
       "4  How many more yards was Kris Browns's first fi...   \n",
       "\n",
       "                                data_id  \n",
       "0  f37e81fa-ef7b-4583-b671-762fc433faa9  \n",
       "1  ac6ba235-3024-4f63-a6ab-730a14def4cb  \n",
       "2  2c7c93f6-69ed-47cc-a5af-94a00c185a26  \n",
       "3  7dfd2b64-f39e-4bb4-aeb0-1900adda6018  \n",
       "4  121a8f57-7752-4373-a9ba-748b2c577cd2  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time once (ms)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time once (ms)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mtime_per_token\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mtime once (ms)\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m/\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mseq_length\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time once (ms)'"
     ]
    }
   ],
   "source": [
    "df[\"time_per_token\"] = df[\"time once (ms)\"]/df[\"seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reader</th>\n",
       "      <th>adapter</th>\n",
       "      <th>model_name</th>\n",
       "      <th>time once (ms)</th>\n",
       "      <th>average_time 50 times (ms)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>data_id</th>\n",
       "      <th>time_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>43.093204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Where did Harold II die?</td>\n",
       "      <td>56de16ca4396321400ee25c5</td>\n",
       "      <td>0.448888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>38.706064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Who killed Harold II?</td>\n",
       "      <td>56de16ca4396321400ee25c6</td>\n",
       "      <td>0.403188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>37.344933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>When was the Battle of Hastings?</td>\n",
       "      <td>56de16ca4396321400ee25c7</td>\n",
       "      <td>0.389010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>40.225029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Who was the ruling class ahead of the Normans?</td>\n",
       "      <td>56de16ca4396321400ee25c8</td>\n",
       "      <td>0.419011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>37.925959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>When did King Harold II conquer England?</td>\n",
       "      <td>5ad3f4b1604f3c001a3ff951</td>\n",
       "      <td>0.395062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reader   adapter          model_name  time once (ms)  \\\n",
       "23995  roberta-base  squad_v2  ONNX-OPT Quantized       43.093204   \n",
       "23996  roberta-base  squad_v2  ONNX-OPT Quantized       38.706064   \n",
       "23997  roberta-base  squad_v2  ONNX-OPT Quantized       37.344933   \n",
       "23998  roberta-base  squad_v2  ONNX-OPT Quantized       40.225029   \n",
       "23999  roberta-base  squad_v2  ONNX-OPT Quantized       37.925959   \n",
       "\n",
       "       average_time 50 times (ms)  seq_length  \\\n",
       "23995                         NaN          96   \n",
       "23996                         NaN          96   \n",
       "23997                         NaN          96   \n",
       "23998                         NaN          96   \n",
       "23999                         NaN          96   \n",
       "\n",
       "                                                 context  \\\n",
       "23995  In 1066, Duke William II of Normandy conquered...   \n",
       "23996  In 1066, Duke William II of Normandy conquered...   \n",
       "23997  In 1066, Duke William II of Normandy conquered...   \n",
       "23998  In 1066, Duke William II of Normandy conquered...   \n",
       "23999  In 1066, Duke William II of Normandy conquered...   \n",
       "\n",
       "                                             question  \\\n",
       "23995                        Where did Harold II die?   \n",
       "23996                          Who killed Harold II?    \n",
       "23997                When was the Battle of Hastings?   \n",
       "23998  Who was the ruling class ahead of the Normans?   \n",
       "23999        When did King Harold II conquer England?   \n",
       "\n",
       "                        data_id  time_per_token  \n",
       "23995  56de16ca4396321400ee25c5        0.448888  \n",
       "23996  56de16ca4396321400ee25c6        0.403188  \n",
       "23997  56de16ca4396321400ee25c7        0.389010  \n",
       "23998  56de16ca4396321400ee25c8        0.419011  \n",
       "23999  5ad3f4b1604f3c001a3ff951        0.395062  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "# df.head()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id_list = df[\"data_id\"].unique().tolist()\n",
    "adapter_list = df[\"adapter\"].unique().tolist()\n",
    "reader_list = df[\"reader\"].unique().tolist()\n",
    "model_name_list = df[\"model_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"mean_time\",\"median_time\", \"min_time\", \"max_time\", \"mean_time_per_token\", \"median_time_per_token\", \"min_time_per_token\", \"max_time_per_token\", \"runs\", \"time_unique_values\", \"seq_length\", \"context\", \"question\", \"data_id\"])\n",
    "df_overall = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"mean_time\",\"median_time\", \"min_time\", \"max_time\", \"mean_time_per_token\", \"median_time_per_token\", \"min_time_per_token\", \"max_time_per_token\", \"runs\", \"av_seq_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adapter in adapter_list:\n",
    "    # print(f\"Doing {adapter}\")\n",
    "    df_adapter = df[df[\"adapter\"] == adapter]\n",
    "    \n",
    "    for reader in reader_list:\n",
    "        # print(f\"Doing {reader}\")\n",
    "        df_reader = df_adapter[df_adapter[\"reader\"] == reader]\n",
    "        \n",
    "        for model_name in model_name_list:\n",
    "            # print(f\"Doing {model_name}\")\n",
    "            df_model = df_reader[df_reader[\"model_name\"]== model_name]\n",
    "\n",
    "            for data_id in data_id_list:\n",
    "                df_data_id = df_model[df_model[\"data_id\"] == data_id]\n",
    "                if df_data_id.empty:\n",
    "                    continue\n",
    "                # print(f\"Doing {data_id}\")\n",
    "                \n",
    "                time_unique_values = df_data_id[\"time once (ms)\"].tolist()\n",
    "                runs = len(time_unique_values)\n",
    "\n",
    "                mean_time = df_data_id[\"time once (ms)\"].mean()\n",
    "                median_time = df_data_id[\"time once (ms)\"].median()\n",
    "                min_time = df_data_id[\"time once (ms)\"].min()\n",
    "                max_time = df_data_id[\"time once (ms)\"].max()\n",
    "                \n",
    "                mean_time_per_token = df_data_id[\"time_per_token\"].mean()\n",
    "                median_time_per_token = df_data_id[\"time_per_token\"].median()\n",
    "                min_time_per_token = df_data_id[\"time once (ms)\"].min()\n",
    "                max_time_per_token = df_data_id[\"time once (ms)\"].max()\n",
    "\n",
    "                # add question, context. \n",
    "                seq_length = df_data_id[\"seq_length\"].unique()[0]\n",
    "                context = df_data_id[\"context\"].unique()[0]\n",
    "                question = df_data_id[\"question\"].unique()[0]\n",
    "\n",
    "\n",
    "                df_fin.loc[len(df_fin)] = [adapter, reader, model_name, mean_time,median_time, min_time, max_time, mean_time_per_token, median_time_per_token, min_time_per_token, max_time_per_token, runs, time_unique_values, seq_length, context, question, data_id]\n",
    "\n",
    "            \n",
    "\n",
    "            runs = len(df_model[\"time once (ms)\"].tolist())\n",
    "\n",
    "            overall_mean_time = df_model[\"time once (ms)\"].mean()\n",
    "            overall_median_time = df_model[\"time once (ms)\"].median()\n",
    "            overall_min_time = df_model[\"time once (ms)\"].min()\n",
    "            overall_max_time = df_model[\"time once (ms)\"].max()\n",
    "\n",
    "            overall_mean_time_per_token = df_model[\"time_per_token\"].mean()\n",
    "            overall_median_time_per_token = df_model[\"time_per_token\"].median()\n",
    "            overall_min_time_per_token = df_model[\"time once (ms)\"].min()\n",
    "            overall_max_time_per_token = df_model[\"time once (ms)\"].max()\n",
    "            av_seq_length = df_model[\"seq_length\"].sum()/len(df_model[\"seq_length\"])\n",
    "            \n",
    "            df_overall.loc[len(df_fin)] = [adapter, reader, model_name, mean_time, median_time, min_time, max_time, mean_time_per_token, median_time_per_token, min_time_per_token, max_time_per_token, runs, av_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall.to_csv(f\"inference_time_{skill}_overall.csv\")\n",
    "df_overall.to_excel(f\"inference_time_{skill}_overall.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv(f\"inference_time_{skill}_overall.csv\")\n",
    "df_fin.to_excel(f\"inference_time_{skill}_overall.xlsx\") # drop duplicates - currently manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n"
     ]
    }
   ],
   "source": [
    "for data_id in df[\"data_id\"]:\n",
    "    print(len(df))\n",
    "\n",
    "    rows = df.loc[df[\"data_id\"] == data_id]\n",
    "\n",
    "    for model_name in df['model_name'].unique():\n",
    "        \n",
    "        model = rows[rows[\"model_name\"] == model_name]\n",
    "        \n",
    "        try: \n",
    "            runs = len(model)\n",
    "\n",
    "            run_min = model[\"time once (ms)\"].min()\n",
    "            run_max = model[\"time once (ms)\"].max()\n",
    "            run_median = model[\"time once (ms)\"].median()\n",
    "\n",
    "            seq_length = model[\"seq_length\"].values[0]\n",
    "\n",
    "            min_time_per_token = run_min/seq_length\n",
    "            max_time_per_token = run_max/seq_length\n",
    "            median_time_per_token = run_median/seq_length\n",
    "            \n",
    "            context = model[\"context\"].values[0]\n",
    "            question = model[\"question\"].values[0]\n",
    "        \n",
    "\n",
    "            df_fin.loc[len(df_fin)] = [model_name, \"\", run_min, run_max, run_median, runs, seq_length, min_time_per_token, max_time_per_token, median_time_per_token, context, question, data_id]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"error\")\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        break\n",
    "    break\n",
    "\n",
    "    \n",
    "    \n",
    "    df = df.drop(df.loc[df[\"data_id\"] == data_id].index) #reduce search space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>time once (ms)</th>\n",
       "      <th>average_time 50 times (ms)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>data_id</th>\n",
       "      <th>data_set_name</th>\n",
       "      <th>time_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>258.271933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Do i need to go for a legal divorce ? I wanted...</td>\n",
       "      <td>Why is this person asking about divorce ?</td>\n",
       "      <td>['If he gets married in the church he wo nt ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>2.807304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Base</td>\n",
       "      <td>299.651861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Do i need to go for a legal divorce ? I wanted...</td>\n",
       "      <td>Why is this person asking about divorce ?</td>\n",
       "      <td>['If he gets married in the church he wo nt ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>3.257085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Base</td>\n",
       "      <td>1240.674257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "      <td>Candy watched the bearded man drive his silver...</td>\n",
       "      <td>How long was Candy trying to seduce Larry?</td>\n",
       "      <td>['about 10 minutes', 'about 2 hours', 'not eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>quail</td>\n",
       "      <td>4.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>Base</td>\n",
       "      <td>1662.490129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "      <td>Candy watched the bearded man drive his silver...</td>\n",
       "      <td>How long was Candy trying to seduce Larry?</td>\n",
       "      <td>['about 10 minutes', 'about 2 hours', 'not eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>quail</td>\n",
       "      <td>5.362871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>Base</td>\n",
       "      <td>62.294006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>When particles of matter are closer together, ...</td>\n",
       "      <td>If Jim moves some particles of matter farther ...</td>\n",
       "      <td>['decrease', 'increase']</td>\n",
       "      <td>0</td>\n",
       "      <td>quartz</td>\n",
       "      <td>3.278632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>Base</td>\n",
       "      <td>1608.655930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>What did the writer think of Timothy after lea...</td>\n",
       "      <td>['Timothy was very hardworking.', 'Timothy was...</td>\n",
       "      <td>0</td>\n",
       "      <td>race</td>\n",
       "      <td>4.745298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>Base</td>\n",
       "      <td>1163.430929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>What did the writer think of Timothy after lea...</td>\n",
       "      <td>['Timothy was very hardworking.', 'Timothy was...</td>\n",
       "      <td>0</td>\n",
       "      <td>race</td>\n",
       "      <td>3.431950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  time once (ms)  average_time 50 times (ms)  seq_length  \\\n",
       "0          Base      258.271933                         NaN          92   \n",
       "600        Base      299.651861                         NaN          92   \n",
       "1200       Base     1240.674257                         NaN         310   \n",
       "1800       Base     1662.490129                         NaN         310   \n",
       "2400       Base       62.294006                         NaN          19   \n",
       "3000       Base     1608.655930                         NaN         339   \n",
       "3600       Base     1163.430929                         NaN         339   \n",
       "\n",
       "                                                context  \\\n",
       "0     Do i need to go for a legal divorce ? I wanted...   \n",
       "600   Do i need to go for a legal divorce ? I wanted...   \n",
       "1200  Candy watched the bearded man drive his silver...   \n",
       "1800  Candy watched the bearded man drive his silver...   \n",
       "2400  When particles of matter are closer together, ...   \n",
       "3000  I am a psychologist. I first met Timothy, a qu...   \n",
       "3600  I am a psychologist. I first met Timothy, a qu...   \n",
       "\n",
       "                                               question  \\\n",
       "0             Why is this person asking about divorce ?   \n",
       "600           Why is this person asking about divorce ?   \n",
       "1200         How long was Candy trying to seduce Larry?   \n",
       "1800         How long was Candy trying to seduce Larry?   \n",
       "2400  If Jim moves some particles of matter farther ...   \n",
       "3000  What did the writer think of Timothy after lea...   \n",
       "3600  What did the writer think of Timothy after lea...   \n",
       "\n",
       "                                                choices  data_id  \\\n",
       "0     ['If he gets married in the church he wo nt ha...        0   \n",
       "600   ['If he gets married in the church he wo nt ha...        0   \n",
       "1200  ['about 10 minutes', 'about 2 hours', 'not eno...        0   \n",
       "1800  ['about 10 minutes', 'about 2 hours', 'not eno...        0   \n",
       "2400                           ['decrease', 'increase']        0   \n",
       "3000  ['Timothy was very hardworking.', 'Timothy was...        0   \n",
       "3600  ['Timothy was very hardworking.', 'Timothy was...        0   \n",
       "\n",
       "     data_set_name  time_per_token  \n",
       "0        cosmos_qa        2.807304  \n",
       "600      cosmos_qa        3.257085  \n",
       "1200         quail        4.002175  \n",
       "1800         quail        5.362871  \n",
       "2400        quartz        3.278632  \n",
       "3000          race        4.745298  \n",
       "3600          race        3.431950  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv(\"inference_time_categorical.csv\")\n",
    "df_fin.to_excel(\"inference_time_categorical.xlsx\") # drop duplicates - currently manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274708\n"
     ]
    }
   ],
   "source": [
    "print(len(df_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_droped = df_fin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_droped.to_csv(\"analyse4.csv\")\n",
    "df_droped.to_excel(\"analyse4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('adapterhub_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dff476688330005cfc33f1ee0f15c13ae533c265ccd041ab146cdb98ecc6219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
