{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sim_base_to_onnx_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head(5)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df[df[\"skill\"] == \"categorical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_diff_of_logits(datafr, model_name):\n",
    "    l = datafr[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "\n",
    "    float_list = []\n",
    "    for v in l:\n",
    "        s = v.split()\n",
    "        float_list.append([float(s[0]), float(s[1])])\n",
    "\n",
    "    r_list = []\n",
    "    for fe in float_list:\n",
    "        r = fe[0] - fe[1]\n",
    "        r_list.append(r)\n",
    "        \n",
    "    mean_diff = sum(r_list) / len(r_list)\n",
    "    return abs(mean_diff) # return only pos. value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to gold label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_dataset\"\n",
    "model_name_answer_column_list = [\"answer_base\", \"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_base\", \"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "Accuracy for bert-base-uncased boolq answer_base is: 0.7339449541284404. T: 2400. F: 870.\n",
      "Accuracy for bert-base-uncased boolq answer_quantized_model is: 0.7363914373088685. T: 2408. F: 862.\n",
      "Accuracy for bert-base-uncased boolq answer_onnx_model is: 0.6174311926605505. T: 2019. F: 1251.\n",
      "Accuracy for bert-base-uncased boolq answer_onnx_opt_model is: 0.6174311926605505. T: 2019. F: 1251.\n",
      "Accuracy for bert-base-uncased boolq answer_quant_onnx_model is: 0.5376146788990825. T: 1758. F: 1512.\n",
      "Accuracy for bert-base-uncased boolq answer_quant_onnx_opt_model is: 0.5376146788990825. T: 1758. F: 1512.\n",
      "Loading: roberta-base boolq\n",
      "Accuracy for roberta-base boolq answer_base is: 0.789908256880734. T: 2583. F: 687.\n",
      "Accuracy for roberta-base boolq answer_quantized_model is: 0.791743119266055. T: 2589. F: 681.\n",
      "Accuracy for roberta-base boolq answer_onnx_model is: 0.7660550458715596. T: 2505. F: 765.\n",
      "Accuracy for roberta-base boolq answer_onnx_opt_model is: 0.7660550458715596. T: 2505. F: 765.\n",
      "Accuracy for roberta-base boolq answer_quant_onnx_model is: 0.7535168195718654. T: 2464. F: 806.\n",
      "Accuracy for roberta-base boolq answer_quant_onnx_opt_model is: 0.7535168195718654. T: 2464. F: 806.\n"
     ]
    }
   ],
   "source": [
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        total_amount = len(reader_adapter_cat_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "\n",
    "            print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc diff of logits (of binary) if pred is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "# t = df.index[df[\"answer_base\"] == df[\"answer_onnx_model\"]]\n",
    "# f = df.index[df[\"answer_base\"] != df[\"answer_onnx_model\"]]\n",
    "\n",
    "# false_onnx = df.iloc[f]\n",
    "# true_onnx = df.iloc[t]\n",
    "\n",
    "# #get result for false results for onnx model\n",
    "# model_name_logits = model_name_logits_column_list[2]\n",
    "# mean_diff_false_results = get_mean_diff_of_logits(false_onnx, model_name_logits)\n",
    "# print(mean_diff_false_results)\n",
    "# mean_diff_true_results = get_mean_diff_of_logits(true_onnx, model_name_logits)\n",
    "# print(mean_diff_true_results)\n",
    "# mean_diff_all_results = get_mean_diff_of_logits(df, model_name_logits)\n",
    "# print(mean_diff_all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_base 0.5527182899770107\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_base 1.2831902399541695\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.5779924959446868\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quantized_model 1.2983542962500025\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_model 0.10977075498867121\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_model 0.7066019500930119\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 0.10977075498867121\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 0.7066019500930119\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.5516529688425929\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 0.2652241823093903\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.5516529688425929\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 0.2652241823093903\n",
      "______\n",
      "\n",
      "Loading: roberta-base boolq\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_base 0.4040738217959158\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_base 1.5820329910375497\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.4107911646475421\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quantized_model 1.5999649035225951\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_model 1.0890937720261429\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_model 1.822977280770459\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 1.0890937720261429\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 1.822977280770459\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.9949980646277912\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 1.573846568120941\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.9949980646277912\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 1.573846568120941\n",
      "______\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            column_name_logits = model_name_logits_column_list[model_name_answer_column_list.index(column_name)]\n",
    "            false_pred_df = reader_adapter_cat_df.iloc[f]\n",
    "            true_pred_df = reader_adapter_cat_df.iloc[t]\n",
    "\n",
    "            mean_diff_false_results = get_mean_diff_of_logits(false_pred_df, column_name_logits)\n",
    "            mean_diff_true_results = get_mean_diff_of_logits(true_pred_df, column_name_logits)\n",
    "            print(f\"{reader} {adapter}. Mean diff logits wrong answer: {column_name_logits} {mean_diff_false_results}\")\n",
    "            print(f\"{reader} {adapter}. Mean diff logits right answer: {column_name_logits} {mean_diff_true_results}\")\n",
    "\n",
    "            print(\"______\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare to Base pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_base\"\n",
    "model_name_answer_column_list = [\"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "Accuracy for bert-base-uncased boolq answer_quantized_model is: 0.9914373088685016. T: 3242. F: 28.\n",
      "Accuracy for bert-base-uncased boolq answer_onnx_model is: 0.7091743119266055. T: 2319. F: 951.\n",
      "Accuracy for bert-base-uncased boolq answer_onnx_opt_model is: 0.7091743119266055. T: 2319. F: 951.\n",
      "Accuracy for bert-base-uncased boolq answer_quant_onnx_model is: 0.5565749235474006. T: 1820. F: 1450.\n",
      "Accuracy for bert-base-uncased boolq answer_quant_onnx_opt_model is: 0.5565749235474006. T: 1820. F: 1450.\n",
      "Loading: roberta-base boolq\n",
      "Accuracy for roberta-base boolq answer_quantized_model is: 0.9877675840978594. T: 3230. F: 40.\n",
      "Accuracy for roberta-base boolq answer_onnx_model is: 0.8746177370030581. T: 2860. F: 410.\n",
      "Accuracy for roberta-base boolq answer_onnx_opt_model is: 0.8746177370030581. T: 2860. F: 410.\n",
      "Accuracy for roberta-base boolq answer_quant_onnx_model is: 0.8486238532110092. T: 2775. F: 495.\n",
      "Accuracy for roberta-base boolq answer_quant_onnx_opt_model is: 0.8486238532110092. T: 2775. F: 495.\n"
     ]
    }
   ],
   "source": [
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "\n",
    "        total_amount = len(reader_adapter_cat_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "\n",
    "            print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased boolq\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.011839845357142859\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quantized_model 1.1179318819260728\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_model 0.1826791926197525\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_model 0.7493231840922832\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 0.1826791926197525\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 0.7493231840922832\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.6219549973655173\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 0.21897178857687236\n",
      "______\n",
      "\n",
      "bert-base-uncased boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.6219549973655173\n",
      "bert-base-uncased boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 0.21897178857687236\n",
      "______\n",
      "\n",
      "Loading: roberta-base boolq\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quantized_model 0.041417001875600004\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quantized_model 1.3695710831021681\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_model 0.9550629441951214\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_model 1.751097558325175\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_onnx_opt_model 0.9550629441951214\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_onnx_opt_model 1.751097558325175\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_model 0.9022634659595957\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_model 1.5255156642486498\n",
      "______\n",
      "\n",
      "roberta-base boolq. Mean diff logits wrong answer: logits_answer_quant_onnx_opt_model 0.9022634659595957\n",
      "roberta-base boolq. Mean diff logits right answer: logits_answer_quant_onnx_opt_model 1.5255156642486498\n",
      "______\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for adapter in cat_df[\"adapter\"].unique():\n",
    "    adapter_cat_df = cat_df[cat_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_cat_df[\"reader\"].unique():\n",
    "        reader_adapter_cat_df = adapter_cat_df[adapter_cat_df[\"reader\"] == reader].reset_index()\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        \n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] == reader_adapter_cat_df[column_name]]\n",
    "            f = reader_adapter_cat_df.index[reader_adapter_cat_df[gold_label_column_name] != reader_adapter_cat_df[column_name]]\n",
    "\n",
    "            column_name_logits = model_name_logits_column_list[model_name_answer_column_list.index(column_name)]\n",
    "            false_pred_df = reader_adapter_cat_df.iloc[f]\n",
    "            true_pred_df = reader_adapter_cat_df.iloc[t]\n",
    "\n",
    "            mean_diff_false_results = get_mean_diff_of_logits(false_pred_df, column_name_logits)\n",
    "            mean_diff_true_results = get_mean_diff_of_logits(true_pred_df, column_name_logits)\n",
    "            print(f\"{reader} {adapter}. Mean diff logits wrong answer: {column_name_logits} {mean_diff_false_results}\")\n",
    "            print(f\"{reader} {adapter}. Mean diff logits right answer: {column_name_logits} {mean_diff_true_results}\")\n",
    "\n",
    "            print(\"______\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Mcq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sim_base_to_onnx_mcq.csv\")\n",
    "mcq_df = df[df[\"skill\"] == \"multiple-choice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skill', 'reader', 'adapter', 'timestamp', 'answer_base',\n",
       "       'logits_answer_base', 'answer_quantized_model',\n",
       "       'logits_answer_quantized_model', 'answer_onnx_model',\n",
       "       'logits_answer_onnx_model', 'answer_onnx_opt_model',\n",
       "       'logits_answer_onnx_opt_model', 'answer_quant_onnx_model',\n",
       "       'logits_answer_quant_onnx_model', 'answer_quant_onnx_opt_model',\n",
       "       'logits_answer_quant_onnx_opt_model', 'data_id', 'dataset', 'question',\n",
       "       'context', 'choices', 'answer_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_label_column_name = \"answer_dataset\"\n",
    "model_name_answer_column_list = [\"answer_base\", \"answer_quantized_model\", \"answer_onnx_model\", \"answer_onnx_opt_model\", \"answer_quant_onnx_model\", \"answer_quant_onnx_opt_model\"]\n",
    "model_name_logits_column_list = [\"logits_answer_base\", \"logits_answer_quantized_model\", \"logits_answer_onnx_model\", \"logits_answer_onnx_opt_model\", \"logits_answer_quant_onnx_model\", \"logits_answer_quant_onnx_opt_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: bert-base-uncased cosmos_qa\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_base is: 0.6050251256281407. T: 1806. F: 1179.\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_quantized_model is: 0.6053601340033501. T: 1807. F: 1178.\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_onnx_model is: 0.5149078726968174. T: 1537. F: 1448.\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_onnx_opt_model is: 0.5149078726968174. T: 1537. F: 1448.\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_quant_onnx_model is: 0.4123953098827471. T: 1231. F: 1754.\n",
      "Accuracy for bert-base-uncased cosmos_qa answer_quant_onnx_opt_model is: 0.4123953098827471. T: 1231. F: 1754.\n",
      "Loading: roberta-base cosmos_qa\n",
      "Accuracy for roberta-base cosmos_qa answer_base is: 0.7078726968174205. T: 2113. F: 872.\n",
      "Accuracy for roberta-base cosmos_qa answer_quantized_model is: 0.7065326633165829. T: 2109. F: 876.\n",
      "Accuracy for roberta-base cosmos_qa answer_onnx_model is: 0.6100502512562814. T: 1821. F: 1164.\n",
      "Accuracy for roberta-base cosmos_qa answer_onnx_opt_model is: 0.6100502512562814. T: 1821. F: 1164.\n",
      "Accuracy for roberta-base cosmos_qa answer_quant_onnx_model is: 0.580569514237856. T: 1733. F: 1252.\n",
      "Accuracy for roberta-base cosmos_qa answer_quant_onnx_opt_model is: 0.580569514237856. T: 1733. F: 1252.\n",
      "Loading: bert-base-uncased quail\n",
      "Accuracy for bert-base-uncased quail answer_base is: 0.6081330868761553. T: 1316. F: 848.\n",
      "Accuracy for bert-base-uncased quail answer_quantized_model is: 0.6104436229205176. T: 1321. F: 843.\n",
      "Accuracy for bert-base-uncased quail answer_onnx_model is: 0.42744916820702406. T: 925. F: 1239.\n",
      "Accuracy for bert-base-uncased quail answer_onnx_opt_model is: 0.42744916820702406. T: 925. F: 1239.\n",
      "Accuracy for bert-base-uncased quail answer_quant_onnx_model is: 0.34473197781885395. T: 746. F: 1418.\n",
      "Accuracy for bert-base-uncased quail answer_quant_onnx_opt_model is: 0.34473197781885395. T: 746. F: 1418.\n",
      "Loading: bert-base-uncased quartz\n",
      "Accuracy for bert-base-uncased quartz answer_base is: 0.53125. T: 204. F: 180.\n",
      "Accuracy for bert-base-uncased quartz answer_quantized_model is: 0.5104166666666666. T: 196. F: 188.\n",
      "Accuracy for bert-base-uncased quartz answer_onnx_model is: 0.484375. T: 186. F: 198.\n",
      "Accuracy for bert-base-uncased quartz answer_onnx_opt_model is: 0.484375. T: 186. F: 198.\n",
      "Accuracy for bert-base-uncased quartz answer_quant_onnx_model is: 0.4765625. T: 183. F: 201.\n",
      "Accuracy for bert-base-uncased quartz answer_quant_onnx_opt_model is: 0.4765625. T: 183. F: 201.\n",
      "Loading: roberta-base quartz\n",
      "Accuracy for roberta-base quartz answer_base is: 0.7838541666666666. T: 301. F: 83.\n",
      "Accuracy for roberta-base quartz answer_quantized_model is: 0.7786458333333334. T: 299. F: 85.\n",
      "Accuracy for roberta-base quartz answer_onnx_model is: 0.671875. T: 258. F: 126.\n",
      "Accuracy for roberta-base quartz answer_onnx_opt_model is: 0.671875. T: 258. F: 126.\n",
      "Accuracy for roberta-base quartz answer_quant_onnx_model is: 0.65625. T: 252. F: 132.\n",
      "Accuracy for roberta-base quartz answer_quant_onnx_opt_model is: 0.65625. T: 252. F: 132.\n"
     ]
    }
   ],
   "source": [
    "for adapter in mcq_df[\"adapter\"].unique():\n",
    "    adapter_mcq_df = mcq_df[mcq_df[\"adapter\"] == adapter]\n",
    "    for reader in adapter_mcq_df[\"reader\"].unique():\n",
    "        print(f\"Loading: {reader} {adapter}\")\n",
    "        reader_adapter_mcq_df = adapter_mcq_df[adapter_mcq_df[\"reader\"] == reader].reset_index()\n",
    "\n",
    "        total_amount = len(reader_adapter_mcq_df)\n",
    "        for column_name in model_name_answer_column_list:\n",
    "            t = reader_adapter_mcq_df.index[reader_adapter_mcq_df[\"answer_dataset\"] == reader_adapter_mcq_df[column_name]]\n",
    "            f = reader_adapter_mcq_df.index[reader_adapter_mcq_df[\"answer_dataset\"] != reader_adapter_mcq_df[column_name]]\n",
    "\n",
    "            total_true = len(t)\n",
    "            total_false = len(f)\n",
    "\n",
    "            accuracy = (total_true)/total_amount\n",
    "\n",
    "            print(f\"Accuracy for {reader} {adapter} {column_name} is: {accuracy}. T: {total_true}. F: {total_false}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>skill</th>\n",
       "      <th>reader</th>\n",
       "      <th>adapter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>answer_base</th>\n",
       "      <th>logits_answer_base</th>\n",
       "      <th>answer_quantized_model</th>\n",
       "      <th>logits_answer_quantized_model</th>\n",
       "      <th>answer_onnx_model</th>\n",
       "      <th>...</th>\n",
       "      <th>answer_quant_onnx_model</th>\n",
       "      <th>logits_answer_quant_onnx_model</th>\n",
       "      <th>answer_quant_onnx_opt_model</th>\n",
       "      <th>logits_answer_quant_onnx_opt_model</th>\n",
       "      <th>data_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>choices</th>\n",
       "      <th>answer_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8518</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:14:36.334767</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[ 1.5967226 -1.6974251]]</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[ 1.5605446 -1.6843979]]</td>\n",
       "      <td>decrease</td>\n",
       "      <td>...</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[-1.0959533 -2.387991 ]]</td>\n",
       "      <td>decrease</td>\n",
       "      <td>[[-1.0959533 -2.387991 ]]</td>\n",
       "      <td>QRQA-10372-1-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>If Jim moves some particles of matter farther ...</td>\n",
       "      <td>When particles of matter are closer together, ...</td>\n",
       "      <td>['decrease', 'increase']</td>\n",
       "      <td>decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8519</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:14:36.664558</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[-1.4991442 -1.7471755]]</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[-1.4956504 -1.7537297]]</td>\n",
       "      <td>decreased</td>\n",
       "      <td>...</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-2.2649467 -1.5029308]]</td>\n",
       "      <td>decreased</td>\n",
       "      <td>[[-2.2649467 -1.5029308]]</td>\n",
       "      <td>QRQA-10371-4-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Long ago the surface of Venus warmed enough th...</td>\n",
       "      <td>An increase in greenhouse gases leads to great...</td>\n",
       "      <td>['increased', 'decreased']</td>\n",
       "      <td>decreased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8520</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:14:37.048579</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.04023071  1.9518709 ]]</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.07223731  1.977018  ]]</td>\n",
       "      <td>less</td>\n",
       "      <td>...</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.7888222  -0.02593471]]</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.7888222  -0.02593471]]</td>\n",
       "      <td>QRQA-10296-1-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>If less waters falls on an area of land it wil...</td>\n",
       "      <td>As more water covered the land, sand and silt ...</td>\n",
       "      <td>['more', 'less']</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8521</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:14:37.443374</td>\n",
       "      <td>open</td>\n",
       "      <td>[[1.9225118 3.9954627]]</td>\n",
       "      <td>open</td>\n",
       "      <td>[[2.0977662 3.9687064]]</td>\n",
       "      <td>open</td>\n",
       "      <td>...</td>\n",
       "      <td>open</td>\n",
       "      <td>[[3.340151  3.5526862]]</td>\n",
       "      <td>open</td>\n",
       "      <td>[[3.340151  3.5526862]]</td>\n",
       "      <td>QRQA-10115-3</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Rich applies a solution to the dish that incre...</td>\n",
       "      <td>The increase in turgor pressure of the guard c...</td>\n",
       "      <td>['close', 'open']</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8522</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:14:37.793810</td>\n",
       "      <td>older</td>\n",
       "      <td>[[ 0.64913607 -0.49488717]]</td>\n",
       "      <td>older</td>\n",
       "      <td>[[ 0.67850906 -0.53324205]]</td>\n",
       "      <td>older</td>\n",
       "      <td>...</td>\n",
       "      <td>older</td>\n",
       "      <td>[[ 0.42830256 -0.4287805 ]]</td>\n",
       "      <td>older</td>\n",
       "      <td>[[ 0.42830256 -0.4287805 ]]</td>\n",
       "      <td>QRQA-10082-1</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Simon was digging in his yard and found that t...</td>\n",
       "      <td>Therefore, deeper rock layers must be older th...</td>\n",
       "      <td>['older', 'younger']</td>\n",
       "      <td>older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>8897</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:17:19.857484</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>[[1.6974237 1.4413342]]</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>[[1.7165381 1.5000093]]</td>\n",
       "      <td>Mars</td>\n",
       "      <td>...</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>[[-1.6023277 -1.7910004]]</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>[[-1.6023277 -1.7910004]]</td>\n",
       "      <td>QRQA-10106-5-flip</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Which planet has the least gravity exerted on ...</td>\n",
       "      <td>Objects that are closer together have a strong...</td>\n",
       "      <td>['Mercury', 'Mars']</td>\n",
       "      <td>Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>8898</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:17:20.281529</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-1.1857404  2.4406533]]</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-1.27052    2.5250819]]</td>\n",
       "      <td>less</td>\n",
       "      <td>...</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.47397986  0.09450573]]</td>\n",
       "      <td>less</td>\n",
       "      <td>[[-0.47397986  0.09450573]]</td>\n",
       "      <td>QRQA-10345-2</td>\n",
       "      <td>quartz</td>\n",
       "      <td>When you get further from the sun are planets ...</td>\n",
       "      <td>When valence electrons are farther from the nu...</td>\n",
       "      <td>['more', 'less']</td>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>8899</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:17:20.749195</td>\n",
       "      <td>larger</td>\n",
       "      <td>[[ 1.1175296 -0.8436286]]</td>\n",
       "      <td>larger</td>\n",
       "      <td>[[ 1.2071087 -0.8636759]]</td>\n",
       "      <td>larger</td>\n",
       "      <td>...</td>\n",
       "      <td>larger</td>\n",
       "      <td>[[ 1.0533252 -1.0935922]]</td>\n",
       "      <td>larger</td>\n",
       "      <td>[[ 1.0533252 -1.0935922]]</td>\n",
       "      <td>QRQA-10357-4</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Don is watching rocks be eroded by water. Sinc...</td>\n",
       "      <td>In erosion, the more energy the water has, the...</td>\n",
       "      <td>['larger', 'smaller']</td>\n",
       "      <td>larger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>8900</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:17:21.178662</td>\n",
       "      <td>increases</td>\n",
       "      <td>[[ 3.5217798  -0.75384456]]</td>\n",
       "      <td>increases</td>\n",
       "      <td>[[ 3.4947906  -0.75599843]]</td>\n",
       "      <td>increases</td>\n",
       "      <td>...</td>\n",
       "      <td>increases</td>\n",
       "      <td>[[2.5232887  0.26663825]]</td>\n",
       "      <td>increases</td>\n",
       "      <td>[[2.5232887  0.26663825]]</td>\n",
       "      <td>QRQA-10257-1</td>\n",
       "      <td>quartz</td>\n",
       "      <td>If Milo is growing some plants in his garden a...</td>\n",
       "      <td>Increases the sheen on leaves to make them mor...</td>\n",
       "      <td>['increases', 'decreases']</td>\n",
       "      <td>increases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>8901</td>\n",
       "      <td>multiple-choice</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>quartz</td>\n",
       "      <td>2023-01-23 14:17:21.565832</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[ 2.907     -1.6038558]]</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[ 2.9252257 -1.7001299]]</td>\n",
       "      <td>increased</td>\n",
       "      <td>...</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[ 1.2232442 -1.1402262]]</td>\n",
       "      <td>increased</td>\n",
       "      <td>[[ 1.2232442 -1.1402262]]</td>\n",
       "      <td>QRQA-10371-4</td>\n",
       "      <td>quartz</td>\n",
       "      <td>Long ago the surface of Venus warmed enough th...</td>\n",
       "      <td>An increase in greenhouse gases leads to great...</td>\n",
       "      <td>['increased', 'decreased']</td>\n",
       "      <td>increased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index            skill        reader adapter                   timestamp  \\\n",
       "0     8518  multiple-choice  roberta-base  quartz  2023-01-23 14:14:36.334767   \n",
       "1     8519  multiple-choice  roberta-base  quartz  2023-01-23 14:14:36.664558   \n",
       "2     8520  multiple-choice  roberta-base  quartz  2023-01-23 14:14:37.048579   \n",
       "3     8521  multiple-choice  roberta-base  quartz  2023-01-23 14:14:37.443374   \n",
       "4     8522  multiple-choice  roberta-base  quartz  2023-01-23 14:14:37.793810   \n",
       "..     ...              ...           ...     ...                         ...   \n",
       "379   8897  multiple-choice  roberta-base  quartz  2023-01-23 14:17:19.857484   \n",
       "380   8898  multiple-choice  roberta-base  quartz  2023-01-23 14:17:20.281529   \n",
       "381   8899  multiple-choice  roberta-base  quartz  2023-01-23 14:17:20.749195   \n",
       "382   8900  multiple-choice  roberta-base  quartz  2023-01-23 14:17:21.178662   \n",
       "383   8901  multiple-choice  roberta-base  quartz  2023-01-23 14:17:21.565832   \n",
       "\n",
       "    answer_base           logits_answer_base answer_quantized_model  \\\n",
       "0      decrease    [[ 1.5967226 -1.6974251]]               decrease   \n",
       "1     increased    [[-1.4991442 -1.7471755]]              increased   \n",
       "2          less  [[-0.04023071  1.9518709 ]]                   less   \n",
       "3          open      [[1.9225118 3.9954627]]                   open   \n",
       "4         older  [[ 0.64913607 -0.49488717]]                  older   \n",
       "..          ...                          ...                    ...   \n",
       "379     Mercury      [[1.6974237 1.4413342]]                Mercury   \n",
       "380        less    [[-1.1857404  2.4406533]]                   less   \n",
       "381      larger    [[ 1.1175296 -0.8436286]]                 larger   \n",
       "382   increases  [[ 3.5217798  -0.75384456]]              increases   \n",
       "383   increased    [[ 2.907     -1.6038558]]              increased   \n",
       "\n",
       "    logits_answer_quantized_model answer_onnx_model  ...  \\\n",
       "0       [[ 1.5605446 -1.6843979]]          decrease  ...   \n",
       "1       [[-1.4956504 -1.7537297]]         decreased  ...   \n",
       "2     [[-0.07223731  1.977018  ]]              less  ...   \n",
       "3         [[2.0977662 3.9687064]]              open  ...   \n",
       "4     [[ 0.67850906 -0.53324205]]             older  ...   \n",
       "..                            ...               ...  ...   \n",
       "379       [[1.7165381 1.5000093]]              Mars  ...   \n",
       "380     [[-1.27052    2.5250819]]              less  ...   \n",
       "381     [[ 1.2071087 -0.8636759]]            larger  ...   \n",
       "382   [[ 3.4947906  -0.75599843]]         increases  ...   \n",
       "383     [[ 2.9252257 -1.7001299]]         increased  ...   \n",
       "\n",
       "    answer_quant_onnx_model logits_answer_quant_onnx_model  \\\n",
       "0                  decrease      [[-1.0959533 -2.387991 ]]   \n",
       "1                 decreased      [[-2.2649467 -1.5029308]]   \n",
       "2                      less    [[-0.7888222  -0.02593471]]   \n",
       "3                      open        [[3.340151  3.5526862]]   \n",
       "4                     older    [[ 0.42830256 -0.4287805 ]]   \n",
       "..                      ...                            ...   \n",
       "379                 Mercury      [[-1.6023277 -1.7910004]]   \n",
       "380                    less    [[-0.47397986  0.09450573]]   \n",
       "381                  larger      [[ 1.0533252 -1.0935922]]   \n",
       "382               increases      [[2.5232887  0.26663825]]   \n",
       "383               increased      [[ 1.2232442 -1.1402262]]   \n",
       "\n",
       "    answer_quant_onnx_opt_model logits_answer_quant_onnx_opt_model  \\\n",
       "0                      decrease          [[-1.0959533 -2.387991 ]]   \n",
       "1                     decreased          [[-2.2649467 -1.5029308]]   \n",
       "2                          less        [[-0.7888222  -0.02593471]]   \n",
       "3                          open            [[3.340151  3.5526862]]   \n",
       "4                         older        [[ 0.42830256 -0.4287805 ]]   \n",
       "..                          ...                                ...   \n",
       "379                     Mercury          [[-1.6023277 -1.7910004]]   \n",
       "380                        less        [[-0.47397986  0.09450573]]   \n",
       "381                      larger          [[ 1.0533252 -1.0935922]]   \n",
       "382                   increases          [[2.5232887  0.26663825]]   \n",
       "383                   increased          [[ 1.2232442 -1.1402262]]   \n",
       "\n",
       "               data_id dataset  \\\n",
       "0    QRQA-10372-1-flip  quartz   \n",
       "1    QRQA-10371-4-flip  quartz   \n",
       "2    QRQA-10296-1-flip  quartz   \n",
       "3         QRQA-10115-3  quartz   \n",
       "4         QRQA-10082-1  quartz   \n",
       "..                 ...     ...   \n",
       "379  QRQA-10106-5-flip  quartz   \n",
       "380       QRQA-10345-2  quartz   \n",
       "381       QRQA-10357-4  quartz   \n",
       "382       QRQA-10257-1  quartz   \n",
       "383       QRQA-10371-4  quartz   \n",
       "\n",
       "                                              question  \\\n",
       "0    If Jim moves some particles of matter farther ...   \n",
       "1    Long ago the surface of Venus warmed enough th...   \n",
       "2    If less waters falls on an area of land it wil...   \n",
       "3    Rich applies a solution to the dish that incre...   \n",
       "4    Simon was digging in his yard and found that t...   \n",
       "..                                                 ...   \n",
       "379  Which planet has the least gravity exerted on ...   \n",
       "380  When you get further from the sun are planets ...   \n",
       "381  Don is watching rocks be eroded by water. Sinc...   \n",
       "382  If Milo is growing some plants in his garden a...   \n",
       "383  Long ago the surface of Venus warmed enough th...   \n",
       "\n",
       "                                               context  \\\n",
       "0    When particles of matter are closer together, ...   \n",
       "1    An increase in greenhouse gases leads to great...   \n",
       "2    As more water covered the land, sand and silt ...   \n",
       "3    The increase in turgor pressure of the guard c...   \n",
       "4    Therefore, deeper rock layers must be older th...   \n",
       "..                                                 ...   \n",
       "379  Objects that are closer together have a strong...   \n",
       "380  When valence electrons are farther from the nu...   \n",
       "381  In erosion, the more energy the water has, the...   \n",
       "382  Increases the sheen on leaves to make them mor...   \n",
       "383  An increase in greenhouse gases leads to great...   \n",
       "\n",
       "                        choices answer_dataset  \n",
       "0      ['decrease', 'increase']       decrease  \n",
       "1    ['increased', 'decreased']      decreased  \n",
       "2              ['more', 'less']           less  \n",
       "3             ['close', 'open']           open  \n",
       "4          ['older', 'younger']          older  \n",
       "..                          ...            ...  \n",
       "379         ['Mercury', 'Mars']           Mars  \n",
       "380            ['more', 'less']           less  \n",
       "381       ['larger', 'smaller']         larger  \n",
       "382  ['increases', 'decreases']      increases  \n",
       "383  ['increased', 'decreased']      increased  \n",
       "\n",
       "[384 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader_adapter_mcq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_name_logits_column_list[2]\n",
    "\n",
    "l = datafr[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_diff_of_logits(datafr, model_name):\n",
    "    l = datafr[model_name].str.replace(\"([\\[\\]])\", \"\", regex=True)\n",
    "\n",
    "    float_list = []\n",
    "    for v in l:\n",
    "        s = v.split()\n",
    "        float_list.append([float(s[0]), float(s[1])])\n",
    "\n",
    "    r_list = []\n",
    "    for fe in float_list:\n",
    "        r = fe[0] - fe[1]\n",
    "        r_list.append(r)\n",
    "        \n",
    "    mean_diff = sum(r_list) / len(r_list)\n",
    "    return abs(mean_diff) # return only pos. value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"inference_time_categorical.csv\")\n",
    "# df = pd.read_csv(\"inference_time_extractive.csv\")\n",
    "# df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adapter</th>\n",
       "      <th>reader</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>median_time</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>mean_time_per_token</th>\n",
       "      <th>median_time_per_token</th>\n",
       "      <th>min_time_per_token</th>\n",
       "      <th>max_time_per_token</th>\n",
       "      <th>runs</th>\n",
       "      <th>time_unique_values</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>129.511690</td>\n",
       "      <td>116.297960</td>\n",
       "      <td>100.482702</td>\n",
       "      <td>190.842867</td>\n",
       "      <td>0.824915</td>\n",
       "      <td>0.740751</td>\n",
       "      <td>100.482702</td>\n",
       "      <td>190.842867</td>\n",
       "      <td>5</td>\n",
       "      <td>[116.29796028137208, 190.842866897583, 108.004...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Who scored the first touchdown of the game?</td>\n",
       "      <td>f37e81fa-ef7b-4583-b671-762fc433faa9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>118.036652</td>\n",
       "      <td>101.804018</td>\n",
       "      <td>88.285923</td>\n",
       "      <td>202.951193</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.648433</td>\n",
       "      <td>88.285923</td>\n",
       "      <td>202.951193</td>\n",
       "      <td>5</td>\n",
       "      <td>[106.0810089111328, 202.95119285583496, 88.285...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did Kris Brown kick?</td>\n",
       "      <td>ac6ba235-3024-4f63-a6ab-730a14def4cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>127.039289</td>\n",
       "      <td>119.737864</td>\n",
       "      <td>104.492188</td>\n",
       "      <td>150.061131</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.762662</td>\n",
       "      <td>104.492188</td>\n",
       "      <td>150.061131</td>\n",
       "      <td>5</td>\n",
       "      <td>[117.91324615478516, 150.06113052368164, 104.4...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>Which team won the game?</td>\n",
       "      <td>2c7c93f6-69ed-47cc-a5af-94a00c185a26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>119.862890</td>\n",
       "      <td>109.892130</td>\n",
       "      <td>100.628376</td>\n",
       "      <td>161.371231</td>\n",
       "      <td>0.763458</td>\n",
       "      <td>0.699950</td>\n",
       "      <td>100.628376</td>\n",
       "      <td>161.371231</td>\n",
       "      <td>5</td>\n",
       "      <td>[119.31896209716795, 161.37123107910156, 109.8...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many field goals did both teams kick in th...</td>\n",
       "      <td>7dfd2b64-f39e-4bb4-aeb0-1900adda6018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>drop</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>Base</td>\n",
       "      <td>111.079550</td>\n",
       "      <td>109.916925</td>\n",
       "      <td>101.395845</td>\n",
       "      <td>126.971960</td>\n",
       "      <td>0.707513</td>\n",
       "      <td>0.700108</td>\n",
       "      <td>101.395845</td>\n",
       "      <td>126.971960</td>\n",
       "      <td>5</td>\n",
       "      <td>[126.97196006774902, 113.73090744018556, 103.3...</td>\n",
       "      <td>157</td>\n",
       "      <td>Hoping to rebound from their loss to the Patr...</td>\n",
       "      <td>How many more yards was Kris Browns's first fi...</td>\n",
       "      <td>121a8f57-7752-4373-a9ba-748b2c577cd2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 adapter             reader model_name   mean_time  median_time  \\\n",
       "0           0    drop  bert-base-uncased       Base  129.511690   116.297960   \n",
       "1           1    drop  bert-base-uncased       Base  118.036652   101.804018   \n",
       "2           2    drop  bert-base-uncased       Base  127.039289   119.737864   \n",
       "3           3    drop  bert-base-uncased       Base  119.862890   109.892130   \n",
       "4           4    drop  bert-base-uncased       Base  111.079550   109.916925   \n",
       "\n",
       "     min_time    max_time  mean_time_per_token  median_time_per_token  \\\n",
       "0  100.482702  190.842867             0.824915               0.740751   \n",
       "1   88.285923  202.951193             0.751826               0.648433   \n",
       "2  104.492188  150.061131             0.809167               0.762662   \n",
       "3  100.628376  161.371231             0.763458               0.699950   \n",
       "4  101.395845  126.971960             0.707513               0.700108   \n",
       "\n",
       "   min_time_per_token  max_time_per_token  runs  \\\n",
       "0          100.482702          190.842867     5   \n",
       "1           88.285923          202.951193     5   \n",
       "2          104.492188          150.061131     5   \n",
       "3          100.628376          161.371231     5   \n",
       "4          101.395845          126.971960     5   \n",
       "\n",
       "                                  time_unique_values  seq_length  \\\n",
       "0  [116.29796028137208, 190.842866897583, 108.004...         157   \n",
       "1  [106.0810089111328, 202.95119285583496, 88.285...         157   \n",
       "2  [117.91324615478516, 150.06113052368164, 104.4...         157   \n",
       "3  [119.31896209716795, 161.37123107910156, 109.8...         157   \n",
       "4  [126.97196006774902, 113.73090744018556, 103.3...         157   \n",
       "\n",
       "                                             context  \\\n",
       "0   Hoping to rebound from their loss to the Patr...   \n",
       "1   Hoping to rebound from their loss to the Patr...   \n",
       "2   Hoping to rebound from their loss to the Patr...   \n",
       "3   Hoping to rebound from their loss to the Patr...   \n",
       "4   Hoping to rebound from their loss to the Patr...   \n",
       "\n",
       "                                            question  \\\n",
       "0        Who scored the first touchdown of the game?   \n",
       "1          How many field goals did Kris Brown kick?   \n",
       "2                           Which team won the game?   \n",
       "3  How many field goals did both teams kick in th...   \n",
       "4  How many more yards was Kris Browns's first fi...   \n",
       "\n",
       "                                data_id  \n",
       "0  f37e81fa-ef7b-4583-b671-762fc433faa9  \n",
       "1  ac6ba235-3024-4f63-a6ab-730a14def4cb  \n",
       "2  2c7c93f6-69ed-47cc-a5af-94a00c185a26  \n",
       "3  7dfd2b64-f39e-4bb4-aeb0-1900adda6018  \n",
       "4  121a8f57-7752-4373-a9ba-748b2c577cd2  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time once (ms)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time once (ms)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mtime_per_token\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mtime once (ms)\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m/\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mseq_length\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Source/DASP/code/dasp_onnx/adapterhub_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'time once (ms)'"
     ]
    }
   ],
   "source": [
    "df[\"time_per_token\"] = df[\"time once (ms)\"]/df[\"seq_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reader</th>\n",
       "      <th>adapter</th>\n",
       "      <th>model_name</th>\n",
       "      <th>time once (ms)</th>\n",
       "      <th>average_time 50 times (ms)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>data_id</th>\n",
       "      <th>time_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>43.093204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Where did Harold II die?</td>\n",
       "      <td>56de16ca4396321400ee25c5</td>\n",
       "      <td>0.448888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>38.706064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Who killed Harold II?</td>\n",
       "      <td>56de16ca4396321400ee25c6</td>\n",
       "      <td>0.403188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>37.344933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>When was the Battle of Hastings?</td>\n",
       "      <td>56de16ca4396321400ee25c7</td>\n",
       "      <td>0.389010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>40.225029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>Who was the ruling class ahead of the Normans?</td>\n",
       "      <td>56de16ca4396321400ee25c8</td>\n",
       "      <td>0.419011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>squad_v2</td>\n",
       "      <td>ONNX-OPT Quantized</td>\n",
       "      <td>37.925959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96</td>\n",
       "      <td>In 1066, Duke William II of Normandy conquered...</td>\n",
       "      <td>When did King Harold II conquer England?</td>\n",
       "      <td>5ad3f4b1604f3c001a3ff951</td>\n",
       "      <td>0.395062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reader   adapter          model_name  time once (ms)  \\\n",
       "23995  roberta-base  squad_v2  ONNX-OPT Quantized       43.093204   \n",
       "23996  roberta-base  squad_v2  ONNX-OPT Quantized       38.706064   \n",
       "23997  roberta-base  squad_v2  ONNX-OPT Quantized       37.344933   \n",
       "23998  roberta-base  squad_v2  ONNX-OPT Quantized       40.225029   \n",
       "23999  roberta-base  squad_v2  ONNX-OPT Quantized       37.925959   \n",
       "\n",
       "       average_time 50 times (ms)  seq_length  \\\n",
       "23995                         NaN          96   \n",
       "23996                         NaN          96   \n",
       "23997                         NaN          96   \n",
       "23998                         NaN          96   \n",
       "23999                         NaN          96   \n",
       "\n",
       "                                                 context  \\\n",
       "23995  In 1066, Duke William II of Normandy conquered...   \n",
       "23996  In 1066, Duke William II of Normandy conquered...   \n",
       "23997  In 1066, Duke William II of Normandy conquered...   \n",
       "23998  In 1066, Duke William II of Normandy conquered...   \n",
       "23999  In 1066, Duke William II of Normandy conquered...   \n",
       "\n",
       "                                             question  \\\n",
       "23995                        Where did Harold II die?   \n",
       "23996                          Who killed Harold II?    \n",
       "23997                When was the Battle of Hastings?   \n",
       "23998  Who was the ruling class ahead of the Normans?   \n",
       "23999        When did King Harold II conquer England?   \n",
       "\n",
       "                        data_id  time_per_token  \n",
       "23995  56de16ca4396321400ee25c5        0.448888  \n",
       "23996  56de16ca4396321400ee25c6        0.403188  \n",
       "23997  56de16ca4396321400ee25c7        0.389010  \n",
       "23998  56de16ca4396321400ee25c8        0.419011  \n",
       "23999  5ad3f4b1604f3c001a3ff951        0.395062  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "# df.head()\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id_list = df[\"data_id\"].unique().tolist()\n",
    "adapter_list = df[\"adapter\"].unique().tolist()\n",
    "reader_list = df[\"reader\"].unique().tolist()\n",
    "model_name_list = df[\"model_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"mean_time\",\"median_time\", \"min_time\", \"max_time\", \"mean_time_per_token\", \"median_time_per_token\", \"min_time_per_token\", \"max_time_per_token\", \"runs\", \"time_unique_values\", \"seq_length\", \"context\", \"question\", \"data_id\"])\n",
    "df_overall = pd.DataFrame(columns=[\"adapter\", \"reader\", \"model_name\", \"mean_time\",\"median_time\", \"min_time\", \"max_time\", \"mean_time_per_token\", \"median_time_per_token\", \"min_time_per_token\", \"max_time_per_token\", \"runs\", \"av_seq_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "for adapter in adapter_list:\n",
    "    # print(f\"Doing {adapter}\")\n",
    "    df_adapter = df[df[\"adapter\"] == adapter]\n",
    "    \n",
    "    for reader in reader_list:\n",
    "        # print(f\"Doing {reader}\")\n",
    "        df_reader = df_adapter[df_adapter[\"reader\"] == reader]\n",
    "        \n",
    "        for model_name in model_name_list:\n",
    "            # print(f\"Doing {model_name}\")\n",
    "            df_model = df_reader[df_reader[\"model_name\"]== model_name]\n",
    "\n",
    "            for data_id in data_id_list:\n",
    "                df_data_id = df_model[df_model[\"data_id\"] == data_id]\n",
    "                if df_data_id.empty:\n",
    "                    continue\n",
    "                # print(f\"Doing {data_id}\")\n",
    "                \n",
    "                time_unique_values = df_data_id[\"time once (ms)\"].tolist()\n",
    "                runs = len(time_unique_values)\n",
    "\n",
    "                mean_time = df_data_id[\"time once (ms)\"].mean()\n",
    "                median_time = df_data_id[\"time once (ms)\"].median()\n",
    "                min_time = df_data_id[\"time once (ms)\"].min()\n",
    "                max_time = df_data_id[\"time once (ms)\"].max()\n",
    "                \n",
    "                mean_time_per_token = df_data_id[\"time_per_token\"].mean()\n",
    "                median_time_per_token = df_data_id[\"time_per_token\"].median()\n",
    "                min_time_per_token = df_data_id[\"time once (ms)\"].min()\n",
    "                max_time_per_token = df_data_id[\"time once (ms)\"].max()\n",
    "\n",
    "                # add question, context. \n",
    "                seq_length = df_data_id[\"seq_length\"].unique()[0]\n",
    "                context = df_data_id[\"context\"].unique()[0]\n",
    "                question = df_data_id[\"question\"].unique()[0]\n",
    "\n",
    "\n",
    "                df_fin.loc[len(df_fin)] = [adapter, reader, model_name, mean_time,median_time, min_time, max_time, mean_time_per_token, median_time_per_token, min_time_per_token, max_time_per_token, runs, time_unique_values, seq_length, context, question, data_id]\n",
    "\n",
    "            \n",
    "\n",
    "            runs = len(df_model[\"time once (ms)\"].tolist())\n",
    "\n",
    "            overall_mean_time = df_model[\"time once (ms)\"].mean()\n",
    "            overall_median_time = df_model[\"time once (ms)\"].median()\n",
    "            overall_min_time = df_model[\"time once (ms)\"].min()\n",
    "            overall_max_time = df_model[\"time once (ms)\"].max()\n",
    "\n",
    "            overall_mean_time_per_token = df_model[\"time_per_token\"].mean()\n",
    "            overall_median_time_per_token = df_model[\"time_per_token\"].median()\n",
    "            overall_min_time_per_token = df_model[\"time once (ms)\"].min()\n",
    "            overall_max_time_per_token = df_model[\"time once (ms)\"].max()\n",
    "            av_seq_length = df_model[\"seq_length\"].sum()/len(df_model[\"seq_length\"])\n",
    "            \n",
    "            df_overall.loc[len(df_fin)] = [adapter, reader, model_name, mean_time, median_time, min_time, max_time, mean_time_per_token, median_time_per_token, min_time_per_token, max_time_per_token, runs, av_seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall.to_csv(f\"inference_time_{skill}_overall.csv\")\n",
    "df_overall.to_excel(f\"inference_time_{skill}_overall.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv(f\"inference_time_{skill}_overall.csv\")\n",
    "df_fin.to_excel(f\"inference_time_{skill}_overall.xlsx\") # drop duplicates - currently manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n"
     ]
    }
   ],
   "source": [
    "for data_id in df[\"data_id\"]:\n",
    "    print(len(df))\n",
    "\n",
    "    rows = df.loc[df[\"data_id\"] == data_id]\n",
    "\n",
    "    for model_name in df['model_name'].unique():\n",
    "        \n",
    "        model = rows[rows[\"model_name\"] == model_name]\n",
    "        \n",
    "        try: \n",
    "            runs = len(model)\n",
    "\n",
    "            run_min = model[\"time once (ms)\"].min()\n",
    "            run_max = model[\"time once (ms)\"].max()\n",
    "            run_median = model[\"time once (ms)\"].median()\n",
    "\n",
    "            seq_length = model[\"seq_length\"].values[0]\n",
    "\n",
    "            min_time_per_token = run_min/seq_length\n",
    "            max_time_per_token = run_max/seq_length\n",
    "            median_time_per_token = run_median/seq_length\n",
    "            \n",
    "            context = model[\"context\"].values[0]\n",
    "            question = model[\"question\"].values[0]\n",
    "        \n",
    "\n",
    "            df_fin.loc[len(df_fin)] = [model_name, \"\", run_min, run_max, run_median, runs, seq_length, min_time_per_token, max_time_per_token, median_time_per_token, context, question, data_id]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"error\")\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        break\n",
    "    break\n",
    "\n",
    "    \n",
    "    \n",
    "    df = df.drop(df.loc[df[\"data_id\"] == data_id].index) #reduce search space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>time once (ms)</th>\n",
       "      <th>average_time 50 times (ms)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>data_id</th>\n",
       "      <th>data_set_name</th>\n",
       "      <th>time_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base</td>\n",
       "      <td>258.271933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Do i need to go for a legal divorce ? I wanted...</td>\n",
       "      <td>Why is this person asking about divorce ?</td>\n",
       "      <td>['If he gets married in the church he wo nt ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>2.807304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Base</td>\n",
       "      <td>299.651861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Do i need to go for a legal divorce ? I wanted...</td>\n",
       "      <td>Why is this person asking about divorce ?</td>\n",
       "      <td>['If he gets married in the church he wo nt ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>3.257085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Base</td>\n",
       "      <td>1240.674257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "      <td>Candy watched the bearded man drive his silver...</td>\n",
       "      <td>How long was Candy trying to seduce Larry?</td>\n",
       "      <td>['about 10 minutes', 'about 2 hours', 'not eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>quail</td>\n",
       "      <td>4.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>Base</td>\n",
       "      <td>1662.490129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310</td>\n",
       "      <td>Candy watched the bearded man drive his silver...</td>\n",
       "      <td>How long was Candy trying to seduce Larry?</td>\n",
       "      <td>['about 10 minutes', 'about 2 hours', 'not eno...</td>\n",
       "      <td>0</td>\n",
       "      <td>quail</td>\n",
       "      <td>5.362871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>Base</td>\n",
       "      <td>62.294006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>When particles of matter are closer together, ...</td>\n",
       "      <td>If Jim moves some particles of matter farther ...</td>\n",
       "      <td>['decrease', 'increase']</td>\n",
       "      <td>0</td>\n",
       "      <td>quartz</td>\n",
       "      <td>3.278632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>Base</td>\n",
       "      <td>1608.655930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>What did the writer think of Timothy after lea...</td>\n",
       "      <td>['Timothy was very hardworking.', 'Timothy was...</td>\n",
       "      <td>0</td>\n",
       "      <td>race</td>\n",
       "      <td>4.745298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>Base</td>\n",
       "      <td>1163.430929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>What did the writer think of Timothy after lea...</td>\n",
       "      <td>['Timothy was very hardworking.', 'Timothy was...</td>\n",
       "      <td>0</td>\n",
       "      <td>race</td>\n",
       "      <td>3.431950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  time once (ms)  average_time 50 times (ms)  seq_length  \\\n",
       "0          Base      258.271933                         NaN          92   \n",
       "600        Base      299.651861                         NaN          92   \n",
       "1200       Base     1240.674257                         NaN         310   \n",
       "1800       Base     1662.490129                         NaN         310   \n",
       "2400       Base       62.294006                         NaN          19   \n",
       "3000       Base     1608.655930                         NaN         339   \n",
       "3600       Base     1163.430929                         NaN         339   \n",
       "\n",
       "                                                context  \\\n",
       "0     Do i need to go for a legal divorce ? I wanted...   \n",
       "600   Do i need to go for a legal divorce ? I wanted...   \n",
       "1200  Candy watched the bearded man drive his silver...   \n",
       "1800  Candy watched the bearded man drive his silver...   \n",
       "2400  When particles of matter are closer together, ...   \n",
       "3000  I am a psychologist. I first met Timothy, a qu...   \n",
       "3600  I am a psychologist. I first met Timothy, a qu...   \n",
       "\n",
       "                                               question  \\\n",
       "0             Why is this person asking about divorce ?   \n",
       "600           Why is this person asking about divorce ?   \n",
       "1200         How long was Candy trying to seduce Larry?   \n",
       "1800         How long was Candy trying to seduce Larry?   \n",
       "2400  If Jim moves some particles of matter farther ...   \n",
       "3000  What did the writer think of Timothy after lea...   \n",
       "3600  What did the writer think of Timothy after lea...   \n",
       "\n",
       "                                                choices  data_id  \\\n",
       "0     ['If he gets married in the church he wo nt ha...        0   \n",
       "600   ['If he gets married in the church he wo nt ha...        0   \n",
       "1200  ['about 10 minutes', 'about 2 hours', 'not eno...        0   \n",
       "1800  ['about 10 minutes', 'about 2 hours', 'not eno...        0   \n",
       "2400                           ['decrease', 'increase']        0   \n",
       "3000  ['Timothy was very hardworking.', 'Timothy was...        0   \n",
       "3600  ['Timothy was very hardworking.', 'Timothy was...        0   \n",
       "\n",
       "     data_set_name  time_per_token  \n",
       "0        cosmos_qa        2.807304  \n",
       "600      cosmos_qa        3.257085  \n",
       "1200         quail        4.002175  \n",
       "1800         quail        5.362871  \n",
       "2400        quartz        3.278632  \n",
       "3000          race        4.745298  \n",
       "3600          race        3.431950  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv(\"inference_time_categorical.csv\")\n",
    "df_fin.to_excel(\"inference_time_categorical.xlsx\") # drop duplicates - currently manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274708\n"
     ]
    }
   ],
   "source": [
    "print(len(df_fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_droped = df_fin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_droped.to_csv(\"analyse4.csv\")\n",
    "df_droped.to_excel(\"analyse4.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('adapterhub_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dff476688330005cfc33f1ee0f15c13ae533c265ccd041ab146cdb98ecc6219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
